,Parent Class,Sub Class,Reference
0,acceptance criterion,acceptance criterion,
1,activation function,activation function,
2,active constraint,active constraint,
3,adaboost,adaboost,
4,adaline,adaline,
5,adaptive rejection sampling,adaptive rejection sampling,
6,adf,adf,assumed density ﬁltering
7,aic,aic,akaike information criterion
8,akaike information criterion,akaike information criterion,
9,ancestral sampling,ancestral sampling,
10,annular ﬂow,annular ﬂow,
11,ar model,ar model,autoregressive model
12,arc,arc,
13,ard,ard,automatic relevance determination
14,arma,arma,autoregressive moving average
15,assumed density ﬁltering,assumed density ﬁltering,
16,autoassociative networks,autoassociative networks,
17,automatic relevance determination,automatic relevance determination,
18,autoregressive hidden markov model,autoregressive hidden markov model,
19,autoregressive model,autoregressive model,
20,autoregressive moving average,autoregressive moving average,
21,back-tracking,back-tracking,
22,backgammon,backgammon,
23,backpropagation,backpropagation,
24,bagging,bagging,
25,basis function,basis function,
26,batch training,batch training,
27,baum-welch algorithm,baum-welch algorithm,
28,bayes’ theorem,bayes’ theorem,
29,bayes,bayes,
30,bayesian analysis,bayesian analysis,
31,bayesian analysis,hierarchical,
32,bayesian analysis,model averaging,
33,bayesian information criterion,bayesian information criterion,
34,bayesian model comparison,bayesian model comparison,
35,bayesian network,bayesian network,
36,bayesian probability,bayesian probability,
37,belief propagation,belief propagation,
38,bernoulli distribution,bernoulli distribution,
39,bernoulli distribution,mixture model,
40,bernoulli,bernoulli,
41,beta distribution,beta distribution,
42,beta recursion,beta recursion,
43,between-class covariance,between-class covariance,
44,bias,bias,
45,bias parameter,bias parameter,
46,bias-variance trade-off,bias-variance trade-off,
47,bic,bic,bayesian information criterion
48,binary entropy,binary entropy,
49,binomial distribution,binomial distribution,
50,biological sequence,biological sequence,
51,bipartite graph,bipartite graph,
52,bits,bits,
53,blind source separation,blind source separation,
54,blocked path,blocked path,
55,boltzmann distribution,boltzmann distribution,
56,boltzmann,boltzmann,
57,boolean logic,boolean logic,
58,boosting,boosting,
59,bootstrap,bootstrap,
60,bootstrap ﬁlter,bootstrap ﬁlter,
61,box constraints,box constraints,
62,box-muller method,box-muller method,
63,calculus of variations,calculus of variations,
64,canonical correlation analysis,canonical correlation analysis,
65,canonical link function,canonical link function,
66,cart,cart,classiﬁcation and regression trees
67,cauchy distribution,cauchy distribution,
68,causality,causality,
69,cca,cca,canonical correlation analysis
70,central differences,central differences,
71,central limit theorem,central limit theorem,
72,chain graph,chain graph,
73,chaining,chaining,
74,chapman-kolmogorov equations,chapman-kolmogorov equations,
75,child node,child node,
76,cholesky decomposition,cholesky decomposition,
77,chunking,chunking,
78,circular normal,circular normal,von mises distribution
79,classical probability,classical probability,
80,classiﬁcation,classiﬁcation,
81,classiﬁcation and regression trees,classiﬁcation and regression trees,
82,clique,clique,
83,clustering,clustering,
84,clutter problem,clutter problem,
85,co-parents,co-parents,
86,code-book vectors,code-book vectors,
87,combining models,combining models,
88,committee,committee,
89,complete data set,complete data set,
90,completing the square,completing the square,
91,computational learning theory,computational learning theory,
92,concave function,concave function,
93,concentration parameter,concentration parameter,
94,condensation algorithm,condensation algorithm,
95,conditional entropy,conditional entropy,
96,conditional expectation,conditional expectation,
97,conditional independence,conditional independence,
98,conditional mixture model,conditional mixture model,mixture model
99,conditional probability,conditional probability,
100,conjugate prior,conjugate prior,
101,convex duality,convex duality,
102,convex function,convex function,
103,convolutional neural network,convolutional neural network,
104,correlation matrix,correlation matrix,
105,cost function,cost function,
106,covariance,covariance,
107,covariance,between-class,
108,covariance,within-class,
109,covariance matrix,covariance matrix,
110,covariance matrix,diagonal,
111,covariance matrix,isotropic,
112,covariance matrix,partitioned,
113,covariance matrix,positive deﬁnite,
114,cox’s axioms,cox’s axioms,
115,credit assignment,credit assignment,
116,cross-entropy error function,cross-entropy error function,
117,cross-validation,cross-validation,
118,cumulative distribution function,cumulative distribution function,
119,curse of dimensionality,curse of dimensionality,
120,curve ﬁtting,curve ﬁtting,
121,dag,dag,directed acyclic graph
122,dagsvm,dagsvm,
123,data augmentation,data augmentation,
124,data compression,data compression,
125,decision boundary,decision boundary,
126,decision region,decision region,
127,decision surface,decision surface,decision boundary
128,decision theory,decision theory,
129,decision tree,decision tree,
130,decomposition methods,decomposition methods,
131,degrees of freedom,degrees of freedom,
132,degrees-of-freedom parameter,degrees-of-freedom parameter,
133,density estimation,density estimation,
134,density network,density network,
135,dependency map,dependency map,
136,descendant node,descendant node,
137,design matrix,design matrix,
138,differential entropy,differential entropy,
139,digamma function,digamma function,
140,directed acyclic graph,directed acyclic graph,
141,directed cycle,directed cycle,
142,directed factorization,directed factorization,
143,dirichlet distribution,dirichlet distribution,
144,dirichlet,dirichlet,
145,discriminant function,discriminant function,
146,discriminative model,discriminative model,
147,distortion measure,distortion measure,
148,distributive law of multiplication,distributive law of multiplication,
149,dna,dna,
150,document retrieval,document retrieval,
151,dual representation,dual representation,
152,dual-energy gamma densitometry,dual-energy gamma densitometry,
153,dynamic programming,dynamic programming,
154,dynamical system,dynamical system,
155,early stopping,early stopping,
156,ecm,ecm,expectation conditional maximization
157,edge,edge,
158,effective number of observations,effective number of observations,
159,effective number of parameters,effective number of parameters,
160,elliptical k-means,elliptical k-means,
161,em,em,expectation maximization
162,emission probability,emission probability,
163,empirical bayes,empirical bayes,evidence approximation
164,energy function,energy function,
165,entropy,entropy,
166,entropy,conditional,
167,entropy,differential,
168,entropy,relative,
169,ep,ep,expectation propagation
170,equality constraint,equality constraint,
171,equivalent kernel,equivalent kernel,
172,erf function,erf function,
173,error backpropagation,error backpropagation,backpropagation
174,error function,error function,
175,error-correcting output codes,error-correcting output codes,
176,euler,euler,
177,euler-lagrange equations,euler-lagrange equations,
178,evidence approximation,evidence approximation,
179,evidence function,evidence function,
180,expectation,expectation,
181,expectation conditional maximization,expectation conditional maximization,
182,expectation maximization,expectation maximization,
183,expectation maximization,gaussian mixture,
184,expectation maximization,generalized,
185,expectation maximization,sampling methods,
186,expectation propagation,expectation propagation,
187,expectation step,expectation step,
188,explaining away,explaining away,
189,exploitation,exploitation,
190,exploration,exploration,
191,exponential distribution,exponential distribution,
192,exponential family,exponential family,
193,extensive variables,extensive variables,
194,face detection,face detection,
195,face tracking,face tracking,
196,factor analysis,factor analysis,
197,factor analysis,mixture model,
198,factor graph,factor graph,
199,factor loading,factor loading,
200,factorial hidden markov model,factorial hidden markov model,
201,factorized distribution,factorized distribution,
202,feature extraction,feature extraction,
203,feature map,feature map,
204,feature space,feature space,
205,fisher information matrix,fisher information matrix,
206,fisher kernel,fisher kernel,
207,fisher’s linear discriminant,fisher’s linear discriminant,
208,forward kinematics,forward kinematics,
209,forward problem,forward problem,
210,forward propagation,forward propagation,
211,forward-backward algorithm,forward-backward algorithm,
212,fractional belief propagation,fractional belief propagation,
213,frequentist probability,frequentist probability,
214,fuel system,fuel system,
215,function interpolation,function interpolation,
216,functional,functional,
217,functional,derivative,
218,gamma densitometry,gamma densitometry,
219,gamma distribution,gamma distribution,
220,gamma function,gamma function,
221,gating function,gating function,
222,gauss,gauss,
223,gaussian,gaussian,
224,gaussian,conditional,
225,gaussian,marginal,
226,gaussian,maximum likelihood,
227,gaussian,mixture,
228,gaussian,sequential estimation,
229,gaussian,sufﬁcient statistics,
230,gaussian,wrapped,
231,gaussian kernel,gaussian kernel,
232,gaussian process,gaussian process,
233,gaussian random ﬁeld,gaussian random ﬁeld,
234,gaussian-gamma distribution,gaussian-gamma distribution,
235,gaussian-wishart distribution,gaussian-wishart distribution,
236,gem,gem,expectation maximization
237,generalization,generalization,
238,generalized linear model,generalized linear model,
239,generalized maximum likelihood,generalized maximum likelihood,evidence approximation
240,generative model,generative model,
241,generative topographic mapping,generative topographic mapping,
242,generative topographic mapping,directional curvature,
243,generative topographic mapping,magniﬁcation factor,
244,geodesic distance,geodesic distance,
245,gibbs sampling,gibbs sampling,
246,gibbs sampling,blocking,
247,gibbs,gibbs,
248,gini index,gini index,
249,global minimum,global minimum,
250,gradient descent,gradient descent,
251,gram matrix,gram matrix,
252,graph-cut algorithm,graph-cut algorithm,
253,graphical model,graphical model,
254,graphical model,bipartite,
255,graphical model,directed,
256,graphical model,factorization,
257,graphical model,fully connected,
258,graphical model,inference,
259,graphical model,tree,
260,graphical model,treewidth,
261,graphical model,triangulated,
262,graphical model,undirected,
263,green’s function,green’s function,
264,gtm,gtm,generative topographic mapping
265,hamilton,hamilton,
266,hamiltonian dynamics,hamiltonian dynamics,
267,hamiltonian function,hamiltonian function,
268,hammersley-clifford theorem,hammersley-clifford theorem,
269,handwriting recognition,handwriting recognition,
270,handwritten digit,handwritten digit,
271,head-to-head path,head-to-head path,
272,head-to-tail path,head-to-tail path,
273,heaviside step function,heaviside step function,
274,hellinger distance,hellinger distance,
275,hessian matrix,hessian matrix,
276,hessian matrix,diagonal approximation,
277,hessian matrix,exact evaluation,
278,hessian matrix,fast multiplication,
279,hessian matrix,ﬁnite differences,
280,hessian matrix,inverse,
281,hessian matrix,outer product approximation,
282,heteroscedastic,heteroscedastic,
283,hidden markov model,hidden markov model,
284,hidden markov model,autoregressive,
285,hidden markov model,factorial,
286,hidden markov model,forward-backward algorithm,
287,hidden markov model,input-output,
288,hidden markov model,left-to-right,
289,hidden markov model,maximum likelihood,
290,hidden markov model,scaling factor,
291,hidden markov model,sum-product algorithm,
292,hidden markov model,switching,
293,hidden markov model,variational inference,
294,hidden unit,hidden unit,
295,hidden variable,hidden variable,
296,hierarchical bayesian model,hierarchical bayesian model,
297,hierarchical mixture of experts,hierarchical mixture of experts,
298,hinge error function,hinge error function,
299,hinton diagram,hinton diagram,
300,histogram density estimation,histogram density estimation,
301,hme,hme,hierarchical mixture of experts
302,hold-out set,hold-out set,
303,homogeneous ﬂow,homogeneous ﬂow,
304,homogeneous kernel,homogeneous kernel,
305,homogeneous markov chain,homogeneous markov chain,
306,hooke’s law,hooke’s law,
307,hybrid monte carlo,hybrid monte carlo,
308,hyperparameter,hyperparameter,
309,hyperprior,hyperprior,
310,i.i.d.,i.i.d.,independent identically distributed
311,ica,ica,independent component analysis
312,icm,icm,iterated conditional modes
313,id3,id3,
314,identiﬁability,identiﬁability,
315,image de-noising,image de-noising,
316,importance sampling,importance sampling,
317,importance weights,importance weights,
318,improper prior,improper prior,
319,imputation step,imputation step,
320,imputation-posterior algorithm,imputation-posterior algorithm,
321,inactive constraint,inactive constraint,
322,incomplete data set,incomplete data set,
323,independence map,independence map,
324,independent component analysis,independent component analysis,
325,independent factor analysis,independent factor analysis,
326,independent identically distributed,independent identically distributed,
327,independent variables,independent variables,
328,independent,independent,
329,induced factorization,induced factorization,
330,inequality constraint,inequality constraint,
331,inference,inference,
332,information criterion,information criterion,
333,information geometry,information geometry,
334,information theory,information theory,
335,input-output hidden markov model,input-output hidden markov model,
336,intensive variables,intensive variables,
337,intrinsic dimensionality,intrinsic dimensionality,
338,invariance,invariance,
339,inverse gamma distribution,inverse gamma distribution,
340,inverse kinematics,inverse kinematics,
341,inverse problem,inverse problem,
342,inverse wishart distribution,inverse wishart distribution,
343,ip algorithm,ip algorithm,imputation-posterior algorithm
344,irls,irls,iterative reweighted least squares
345,ising model,ising model,
346,isomap,isomap,
347,isometric feature map,isometric feature map,
348,iterated conditional modes,iterated conditional modes,
349,iterative reweighted least squares,iterative reweighted least squares,
350,jacobian matrix,jacobian matrix,
351,jensen’s inequality,jensen’s inequality,
352,join tree,join tree,
353,junction tree algorithm,junction tree algorithm,
354,k nearest neighbours,k nearest neighbours,
355,k-means clustering algorithm,k-means clustering algorithm,
356,k-medoids algorithm,k-medoids algorithm,
357,kalman ﬁlter,kalman ﬁlter,
358,kalman ﬁlter,extended,
359,kalman gain matrix,kalman gain matrix,
360,kalman smoother,kalman smoother,
361,karhunen-lo`eve transform,karhunen-lo`eve transform,
362,karush-kuhn-tucker conditions,karush-kuhn-tucker conditions,
363,kernel density estimator,kernel density estimator,
364,kernel function,kernel function,
365,kernel function,fisher,
366,kernel function,gaussian,
367,kernel function,homogeneous,
368,kernel function,nonvectorial inputs,
369,kernel function,stationary,
370,kernel pca,kernel pca,
371,kernel regression,kernel regression,
372,kernel substitution,kernel substitution,
373,kernel trick,kernel trick,
374,kinetic energy,kinetic energy,
375,kkt,kkt,karush-kuhn-tucker conditions
376,kl divergence,kl divergence,kullback-leibler divergence
377,kriging,kriging,gaussian process
378,kullback-leibler divergence,kullback-leibler divergence,
379,lagrange multiplier,lagrange multiplier,
380,lagrange,lagrange,
381,lagrangian,lagrangian,
382,laminar ﬂow,laminar ﬂow,
383,laplace approximation,laplace approximation,
384,laplace,laplace,
385,large margin,large margin,margin
386,lasso,lasso,
387,latent class analysis,latent class analysis,
388,latent trait model,latent trait model,
389,latent variable,latent variable,
390,lattice diagram,lattice diagram,
391,lds,lds,linear dynamical system
392,leapfrog discretization,leapfrog discretization,
393,learning,learning,
394,learning rate parameter,learning rate parameter,
395,least-mean-squares algorithm,least-mean-squares algorithm,
396,leave-one-out,leave-one-out,
397,likelihood function,likelihood function,
398,likelihood weighted sampling,likelihood weighted sampling,
399,linear discriminant,linear discriminant,
400,linear discriminant,fisher,
401,linear dynamical system,linear dynamical system,
402,linear dynamical system,inference,
403,linear independence,linear independence,
404,linear regression,linear regression,
405,linear regression,em,
406,linear regression,mixture model,
407,linear regression,variational,
408,linear smoother,linear smoother,
409,linear-gaussian model,linear-gaussian model,
410,linearly separable,linearly separable,
411,link,link,
412,link function,link function,
413,liouville’s theorem,liouville’s theorem,
414,lle,lle,locally linear embedding
415,lms algorithm,lms algorithm,least-mean-squares algorithm
416,local minimum,local minimum,
417,local receptive ﬁeld,local receptive ﬁeld,
418,locally linear embedding,locally linear embedding,
419,location parameter,location parameter,
420,log odds,log odds,
421,logic sampling,logic sampling,
422,logistic regression,logistic regression,
423,logistic regression,bayesian,
424,logistic regression,mixture model,
425,logistic regression,multiclass,
426,logistic sigmoid,logistic sigmoid,
427,logit function,logit function,
428,loopy belief propagation,loopy belief propagation,
429,loss function,loss function,
430,loss matrix,loss matrix,
431,lossless data compression,lossless data compression,
432,lossy data compression,lossy data compression,
433,lower bound,lower bound,
434,machine learning,machine learning,
435,macrostate,macrostate,
436,mahalanobis distance,mahalanobis distance,
437,manifold,manifold,
438,map,map,maximum posterior
439,margin,margin,
440,margin,error,
441,margin,soft,
442,marginal likelihood,marginal likelihood,
443,marginal probability,marginal probability,
444,markov blanket,markov blanket,
445,markov boundary,markov boundary,markov blanket
446,markov chain,markov chain,
447,markov chain,ﬁrst order,
448,markov chain,homogeneous,
449,markov chain,second order,
450,markov chain monte carlo,markov chain monte carlo,
451,markov model,markov model,
452,markov model,homogeneous,
453,markov network,markov network,markov random ﬁeld
454,markov random ﬁeld,markov random ﬁeld,
455,max-sum algorithm,max-sum algorithm,
456,maximal clique,maximal clique,
457,maximal spanning tree,maximal spanning tree,
458,maximization step,maximization step,
459,maximum likelihood,maximum likelihood,
460,maximum likelihood,gaussian mixture,
461,maximum likelihood,singularities,
462,maximum likelihood,type 2,evidence approximation
463,maximum margin,maximum margin,margin
464,maximum posterior,maximum posterior,
465,mcmc,mcmc,markov chain monte carlo
466,mdn,mdn,mixture density network
467,mds,mds,multidimensional scaling
468,mean,mean,
469,mean ﬁeld theory,mean ﬁeld theory,
470,mean value theorem,mean value theorem,
471,measure theory,measure theory,
472,memory-based methods,memory-based methods,
473,message passing,message passing,
474,message passing,pending message,
475,message passing,schedule,
476,message passing,variational,
477,metropolis algorithm,metropolis algorithm,
478,metropolis-hastings algorithm,metropolis-hastings algorithm,
479,microstate,microstate,
480,minimum risk,minimum risk,
481,minkowski loss,minkowski loss,
482,missing at random,missing at random,
483,missing data,missing data,
484,mixing coefﬁcient,mixing coefﬁcient,
485,mixture component,mixture component,
486,mixture density network,mixture density network,
487,mixture distribution,mixture distribution,mixture model
488,mixture model,mixture model,
489,mixture model,conditional,
490,mixture model,linear regression,
491,mixture model,logistic regression,
492,mixture model,symmetries,
493,mixture of experts,mixture of experts,
494,mixture of gaussians,mixture of gaussians,
495,mlp,mlp,multilayer perceptron
496,mnist data,mnist data,
497,model comparison,model comparison,
498,model evidence,model evidence,
499,model selection,model selection,
500,moment matching,moment matching,
501,momentum variable,momentum variable,
502,monte carlo em algorithm,monte carlo em algorithm,
503,monte carlo sampling,monte carlo sampling,
504,moore-penrose pseudo-inverse,moore-penrose pseudo-inverse,pseudo-inverse
505,moralization,moralization,
506,mrf,mrf,markov random ﬁeld
507,multidimensional scaling,multidimensional scaling,
508,multilayer perceptron,multilayer perceptron,
509,multimodality,multimodality,
510,multinomial distribution,multinomial distribution,
511,multiplicity,multiplicity,
512,mutual information,mutual information,
513,nadaraya-watson,nadaraya-watson,kernel regression
514,naive bayes model,naive bayes model,
515,nats,nats,
516,natural language modelling,natural language modelling,
517,natural parameters,natural parameters,
518,nearest-neighbour methods,nearest-neighbour methods,
519,neural network,neural network,
520,neural network,convolutional,
521,neural network,regularization,
522,neural network,relation to gaussian process,
523,newton-raphson,newton-raphson,
524,node,node,
525,noiseless coding theorem,noiseless coding theorem,
526,nonidentiﬁability,nonidentiﬁability,
527,noninformative prior,noninformative prior,
528,nonparametric methods,nonparametric methods,
529,normal distribution,normal distribution,gaussian
530,normal equations,normal equations,
531,normal-gamma distribution,normal-gamma distribution,
532,normal-wishart distribution,normal-wishart distribution,
533,normalized exponential,normalized exponential,softmax function
534,novelty detection,novelty detection,
535,ν-svm,ν-svm,
536,object recognition,object recognition,
537,observed variable,observed variable,
538,occam factor,occam factor,
539,oil ﬂow data,oil ﬂow data,
540,old faithful data,old faithful data,
541,on-line learning,on-line learning,sequential learning
542,one-versus-one classiﬁer,one-versus-one classiﬁer,
543,one-versus-the-rest classiﬁer,one-versus-the-rest classiﬁer,
544,ordered over-relaxation,ordered over-relaxation,
545,ornstein-uhlenbeck process,ornstein-uhlenbeck process,
546,orthogonal least squares,orthogonal least squares,
547,outlier,outlier,
548,outliers,outliers,
549,over-ﬁtting,over-ﬁtting,
550,over-relaxation,over-relaxation,
551,pac learning,pac learning,probably approximately correct
552,pac-bayesian framework,pac-bayesian framework,
553,parameter shrinkage,parameter shrinkage,
554,parent node,parent node,
555,particle ﬁlter,particle ﬁlter,
556,partition function,partition function,
557,parzen estimator,parzen estimator,kernel density estimator
558,parzen window,parzen window,
559,pattern recognition,pattern recognition,
560,pca,pca,principal component analysis
561,pending message,pending message,
562,perceptron,perceptron,
563,perceptron,convergence theorem,
564,perceptron,hardware,
565,perceptron criterion,perceptron criterion,
566,perfect map,perfect map,
567,periodic variable,periodic variable,
568,phase space,phase space,
569,photon noise,photon noise,
570,plate,plate,
571,polynomial curve ﬁtting,polynomial curve ﬁtting,
572,polytree,polytree,
573,position variable,position variable,
574,positive deﬁnite covariance,positive deﬁnite covariance,
575,positive deﬁnite matrix,positive deﬁnite matrix,
576,positive semideﬁnite covariance,positive semideﬁnite covariance,
577,positive semideﬁnite matrix,positive semideﬁnite matrix,
578,posterior probability,posterior probability,
579,posterior step,posterior step,
580,potential energy,potential energy,
581,potential function,potential function,
582,power ep,power ep,
583,power method,power method,
584,precision matrix,precision matrix,
585,precision parameter,precision parameter,
586,predictive distribution,predictive distribution,
587,preprocessing,preprocessing,
588,principal component analysis,principal component analysis,
589,principal component analysis,bayesian,
590,principal component analysis,em algorithm,
591,principal component analysis,gibbs sampling,
592,principal component analysis,mixture distribution,
593,principal component analysis,physical analogy,
594,principal curve,principal curve,
595,principal subspace,principal subspace,
596,principal surface,principal surface,
597,prior,prior,
598,prior,conjugate,
599,prior,consistent,
600,prior,improper,
601,prior,noninformative,
602,probabilistic graphical model,probabilistic graphical model,graphical model
603,probabilistic pca,probabilistic pca,
604,probability,probability,
605,probability,bayesian,
606,probability,classical,
607,probability,density,
608,probability,frequentist,
609,probability,mass function,
610,probability,prior,
611,probability,product rule,
612,probability,sum rule,
613,probability,theory,
614,probably approximately correct,probably approximately correct,
615,probit function,probit function,
616,probit regression,probit regression,
617,product rule of probability,product rule of probability,
618,proposal distribution,proposal distribution,
619,protected conjugate gradients,protected conjugate gradients,
620,protein sequence,protein sequence,
621,pseudo-inverse,pseudo-inverse,
622,pseudo-random numbers,pseudo-random numbers,
623,quadratic discriminant,quadratic discriminant,
624,quality parameter,quality parameter,
625,radial basis function,radial basis function,
626,rauch-tung-striebel equations,rauch-tung-striebel equations,
627,regression,regression,
628,regression function,regression function,
629,regularization,regularization,
630,regularization,tikhonov,
631,regularized least squares,regularized least squares,
632,reinforcement learning,reinforcement learning,
633,reject option,reject option,
634,rejection sampling,rejection sampling,
635,relative entropy,relative entropy,
636,relevance vector,relevance vector,
637,relevance vector machine,relevance vector machine,
638,responsibility,responsibility,
639,ridge regression,ridge regression,
640,rms error,rms error,root-mean-square error
641,robbins-monro algorithm,robbins-monro algorithm,
642,robot arm,robot arm,
643,robustness,robustness,
644,root node,root node,
645,root-mean-square error,root-mean-square error,
646,rosenblatt,rosenblatt,
647,rotation invariance,rotation invariance,
648,rts equations,rts equations,rauch-tung-striebel equations
649,running intersection property,running intersection property,
650,rvm,rvm,relevance vector machine
651,sample mean,sample mean,
652,sample variance,sample variance,
653,sampling-importance-resampling,sampling-importance-resampling,
654,scale invariance,scale invariance,
655,scale parameter,scale parameter,
656,scaling factor,scaling factor,
657,schwarz criterion,schwarz criterion,bayesian information criterion
658,self-organizing map,self-organizing map,
659,sequential data,sequential data,
660,sequential estimation,sequential estimation,
661,sequential gradient descent,sequential gradient descent,
662,sequential learning,sequential learning,
663,sequential minimal optimization,sequential minimal optimization,
664,serial message passing schedule,serial message passing schedule,
665,shannon,shannon,
666,shared parameters,shared parameters,
667,shrinkage,shrinkage,
668,shur complement,shur complement,
669,sigmoid,sigmoid,logistic sigmoid
670,simplex,simplex,
671,single-class support vector machine,single-class support vector machine,
672,singular value decomposition,singular value decomposition,
673,sinusoidal data,sinusoidal data,
674,sir,sir,sampling-importance-resampling
675,skip-layer connection,skip-layer connection,
676,slack variable,slack variable,
677,slice sampling,slice sampling,
678,smo,smo,sequential minimal optimization
679,smoother matrix,smoother matrix,
680,smoothing parameter,smoothing parameter,
681,soft margin,soft margin,
682,soft weight sharing,soft weight sharing,
683,softmax function,softmax function,
684,som,som,self-organizing map
685,sparsity,sparsity,
686,sparsity parameter,sparsity parameter,
687,spectrogram,spectrogram,
688,speech recognition,speech recognition,
689,sphereing,sphereing,
690,spline functions,spline functions,
691,standard deviation,standard deviation,
692,standardizing,standardizing,
693,state space model,state space model,
694,state space model,switching,
695,stationary kernel,stationary kernel,
696,statistical bias,statistical bias,bias
697,statistical independence,statistical independence,independent variables
698,statistical learning theory,statistical learning theory,computational learning theory
699,steepest descent,steepest descent,
700,stirling’s approximation,stirling’s approximation,
701,stochastic,stochastic,
702,stochastic em,stochastic em,
703,stochastic gradient descent,stochastic gradient descent,
704,stochastic process,stochastic process,
705,stratiﬁed ﬂow,stratiﬁed ﬂow,
706,student’s t-distribution,student’s t-distribution,
707,subsampling,subsampling,
708,sufﬁcient statistics,sufﬁcient statistics,
709,sum rule of probability,sum rule of probability,
710,sum-of-squares error,sum-of-squares error,
711,sum-product algorithm,sum-product algorithm,
712,sum-product algorithm,for hidden markov model,
713,supervised learning,supervised learning,
714,support vector,support vector,
715,support vector machine,support vector machine,
716,support vector machine,for regression,
717,support vector machine,multiclass,
718,survival of the ﬁttest,survival of the ﬁttest,
719,svd,svd,singular value decomposition
720,svm,svm,support vector machine
721,switching hidden markov model,switching hidden markov model,
722,switching state space model,switching state space model,
723,synthetic data sets,synthetic data sets,
724,tail-to-tail path,tail-to-tail path,
725,tangent distance,tangent distance,
726,tangent propagation,tangent propagation,
727,tapped delay line,tapped delay line,
728,target vector,target vector,
729,test set,test set,
730,threshold parameter,threshold parameter,
731,tied parameters,tied parameters,
732,tikhonov regularization,tikhonov regularization,
733,time warping,time warping,
734,tomography,tomography,
735,training,training,
736,training set,training set,
737,transition probability,transition probability,
738,translation invariance,translation invariance,
739,tree-reweighted message passing,tree-reweighted message passing,
740,treewidth,treewidth,
741,trellis diagram,trellis diagram,lattice diagram
742,triangulated graph,triangulated graph,
743,type 2 maximum likelihood,type 2 maximum likelihood,evidence approximation
744,undetermined multiplier,undetermined multiplier,lagrange multiplier
745,undirected graph,undirected graph,markov random ﬁeld
746,uniform distribution,uniform distribution,
747,uniform sampling,uniform sampling,
748,uniquenesses,uniquenesses,
749,unobserved variable,unobserved variable,latent variable
750,unsupervised learning,unsupervised learning,
751,utility function,utility function,
752,validation set,validation set,
753,vapnik-chervonenkis dimension,vapnik-chervonenkis dimension,
754,variance,variance,
755,variational inference,variational inference,
756,variational inference,for gaussian mixture,
757,variational inference,for hidden markov model,
758,variational inference,local,
759,vc dimension,vc dimension,vapnik-chervonenkis dimension
760,vc dimension,vector quantization,
761,vc dimension,vertex,node
762,vc dimension,visualization,
763,vc dimension,viterbi algorithm,
764,vc dimension,von mises distribution,
765,vc dimension,wavelets,
766,vc dimension,weak learner,
767,vc dimension,weight decay,
768,vc dimension,weight parameter,
769,vc dimension,weight sharing,
770,soft,soft,
771,soft,weight vector,
772,soft,weight-space symmetry,
773,soft,weighted least squares,
774,soft,well-determined parameters,
775,soft,whitening,
776,soft,wishart distribution,
777,soft,within-class covariance,
778,soft,woodbury identity,
779,soft,wrapped distribution,
780,soft,yellowstone national park,
