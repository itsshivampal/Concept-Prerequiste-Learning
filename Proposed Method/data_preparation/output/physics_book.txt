file_data: 1|What is Physics?|3
Physics is the study of the world around us. In a sense we are more qualified to do physics
than any other science. From the day we are born we study the things around us in an effort to
understand how they work and relate to each other. Learning how to catch or throw a ball is a
physics undertaking for example.
In the field of study we refer to as physics we just try to make the things everyone has been
studying more clear. We attempt to describe them through simple rules and mathematics.
Mathematics is merely the language we use.
The best approach to physics is to relate everything you learn to things you have already noticed
in your everyday life. Sometimes when you look at things closely you discover things you had
overlooked intially.
It is the continued scrutiny of everything we know about the world around us that leads people
to the lifelong study of physics. You can start with asking a simple question like ”Why is the sky
blue?” which could lead you to electromagnetic waves which in turn could lead you wave particle
duality and to energy levels of atoms and before long you are studying quantum mechanics or
the structure of the universe.
In the sections that follow notice that we will try to describe how we will communicate the things
we are dealing with. This is our langauge. Once this is done we can begin the adventure of
looking more closely at the world we live in.
/ntsDescriptions relating to these questions must be included: What is meant by a theory?
How does a hypothesis become part of a law?
(a) Define the term ”laboratory.” (b) How does your school’s physics laboratory fit this definition?
Distinguish between science and technology.

file_data: 2|Units|9


file_data: 2.1|Introduction|9
Imagine you had to make curtains and needed to buy fabric. The shop assistant would need
to know how much fabric you needed. Telling her you need fabric 2 wide and 6 long would be
insufficient — you have to specify the unit (i.e. 2 metres wide and 6 metres long). Without
the unit the information is incomplete and the shop assistant would have to guess. If you were
making curtains for a doll’s house the dimensions might be 2 centimetres wide and 6 centimetres
long!
It is not just lengths that have units, all physical quantities have units (e.g. time, temperature,
distance, etc.).
Definition: Physical Quantity
A physical quantity is anything that you can measure. For example, length, temperature,
distance and time are physical quantities.

file_data: 2.2|Unit Systems|9


file_data: 2.2.1|SI Units|9
We will be using the SI units in this course. SI units are the internationally agreed upon units.
Historically these units are based on the metric system which was developed in France at the
time of the French Revolution.
Definition: SI Units
The name SI units comes from the French Syst`eme International d’Unit´es, which means
international system of units.
There are seven base SI units. These are listed in Table 2.1. All physical quantities have units
which can be built from these seven base units. These seven units were defined to be the base
units. So, it is possible to create a different set of units by defining a different set of base units.
These seven units are called base units because none of them can be expressed as combinations
of the other six. This is identical to bricks and concrete being the base units of a building. You
can build different things using different combinations of bricks and concrete. The 26 letters of
the alphabet are the base units for a language like English. Many different words can be formed
by using these letters.

file_data: 2.2.2|The Other Systems of Units|10
The SI Units are not the only units available, but they are most widely used. In Science there
are three other sets of units that can also be used. These are mentioned here for interest only.
c.g.s Units
In the c.g.s. system, the metre is replaced by the centimetre and the kilogram is replaced by the
gram. This is a simple change but it means that all units derived from these two are changed.
For example, the units of force and work are different. These units are used most often in
astrophysics and atomic physics.
Imperial Units
Imperial units arose when kings and queens decided the measures that were to be used in the
land. All the imperial base units, except for the measure of time, are different to those of SI
units. This is the unit system you are most likely to encounter if SI units are not used. Examples
of imperial units are pounds, miles, gallons and yards. These units are used by the Americans
and British. As you can imagine, having different units in use from place to place makes scientific
communication very difficult. This was the motivation for adopting a set of internationally agreed
upon units.
Natural Units
This is the most sophisticated choice of units. Here the most fundamental discovered quantities
(such as the speed of light) are set equal to 1. The argument for this choice is that all other
quantities should be built from these fundamental units. This system of units is used in high
energy physics and quantum mechanics.

file_data: 2.3|Writing Units as Words or Symbols|10
Unit names are always written with a lowercase first letter, for example, we write metre and litre.
The symbols or abbreviations of units are also written with lowercase initials, for example m for
metre and ℓ for litre. The exception to this rule is if the unit is named after a person, then the
symbol is a capital letter. For example, the kelvin was named after Lord Kelvin and its symbol is
K. If the abbreviation of the unit that is named after a person has two letters, the second letter
is lowercase, for example Hz for hertz.

file_data: 2.4|Combinations of SI Base Units|12
To make working with units easier, some combinations of the base units are given special names,
but it is always correct to reduce everything to the base units. Table 2.2 lists some examples
of combinations of SI base units that are assigned special names. Do not be concerned if the
formulae look unfamiliar at this stage - we will deal with each in detail in the chapters ahead (as
well as many others)!
It is very important that you are able to recognise the units correctly. For instance, the new-
ton (N) is another name for the kilogram metre per second squared (kg·m·s−2), while the
kilogram metre squared per second squared (kg·m2 ·s−2) is called the joule (J).
Important: When writing combinations of base SI units, place a dot (·) between the units
to indicate that different base units are used. For example, the symbol for metres per second
is correctly written as m·s−1, and not as ms−1 or m/s.

file_data: 2.5|Rounding, Scientific Notation and Significant Figures|12


file_data: 2.5.1|Rounding Off|12
Certain numbers may take an infinite amount of paper and ink to write out. Not only is
that impossible, but writing numbers out to a high accuracy (many decimal places) is very
inconvenient and rarely gives better answers. For this reason we often estimate the number to a
certain number of decimal places. Rounding off or approximating a decimal number to a given
number of decimal places is the quickest way to approximate a number. For example, if you
wanted to round-off 2,6525272 to three decimal places then you would first count three places
after the decimal.
2,652|5272
All numbers to the right of | are ignored after you determine whether the number in the third
decimal place must be rounded up or rounded down. You round up the final digit (make the
digit one more) if the first digit after the | was greater or equal to 5 and round down (leave the
digit alone) otherwise. So, since the first digit after the | is a 5, we must round up the digit in
the third decimal place to a 3 and the final answer of 2,6525272 rounded to three decimal places
is 2,653.

file_data: 2.5.2|Error Margins|13
In a calculation that has many steps, it is best to leave the rounding off right until the end. For
example, Jack and Jill walks to school. They walk 0,9 kilometers to get to school and it takes
them 17 minutes. We can calculate their speed in the following two ways.
You will see that we get two different answers. In Method 1 no rounding was done, but in Method
2, the time was rounded to 2 decimal places. This made a big difference to the answer. The
answer in Method 1 is more accurate because rounded numbers were not used in the calculation.
Always only round off your final answer.

file_data: 2.5.3|Scientific Notation|13
In Science one often needs to work with very large or very small numbers. These can be written
more easily in scientific notation, in the general form
d × 10e
where d is a decimal number between 0 and 10 that is rounded off to a few decimal places. e is
known as the exponent and is an integer. If e > 0 it represents how many times the decimal
place in d should be moved to the right. If e < 0, then it represents how many times the decimal
place in d should be moved to the left. For example 3,24 × 103 represents 3240 (the decimal
moved three places to the right) and 3,24 × 10−3 represents 0,00324 (the decimal moved three
places to the left).
If a number must be converted into scientific notation, we need to work out how many times
the number must be multiplied or divided by 10 to make it into a number between 1 and 10
(i.e. the value of e) and what this number between 1 and 10 is (the value of d). We do this by
counting the number of decimal places the decimal comma must move.
For example, write the speed of light in scientific notation, to two decimal places. The speed of
light is 299 792 458 m·s−1. First, find where the decimal comma must go for two decimal places
(to find d) and then count how many places there are after the decimal comma to determine e.
In this example, the decimal comma must go after the first 2, but since the number after the 9
is 7, d = 3,00. e = 8 because there are 8 digits left after the decimal comma. So the speed of
light in scientific notation, to two decimal places is 3,00 × 108 m·s−1.

file_data: 2.5.4|Significant Figures|15
In a number, each non-zero digit is a significant figure. Zeroes are only counted if they are
between two non-zero digits or are at the end of the decimal part. For example, the number
2000 has 1 significant figure (the 2), but 2000,0 has 5 significant figures. You estimate a number
like this by removing significant figures from the number (starting from the right) until you have
the desired number of significant figures, rounding as you go. For example 6,827 has 4 significant
figures, but if you wish to write it to 3 significant figures it would mean removing the 7 and
rounding up, so it would be 6,83.

file_data: 2.6|Prefixes of Base Units|15
Now that you know how to write numbers in scientific notation, another important aspect of
units is the prefixes that are used with the units.
Definition: Prefix
A prefix is a group of letters that are placed in front of a word. The effect of the prefix is to
change meaning of the word. For example, the prefix un is often added to a word to mean
not, as in unnecessary which means not necessary.
In the case of units, the prefixes have a special use. The kilogram (kg) is a simple example.
1 kg is equal to 1 000 g or 1 × 103 g. Grouping the 103 and the g together we can replace the
103 with the prefix k (kilo). Therefore the k takes the place of the 103.
The kilogram is unique in that it is the only SI base unit containing a prefix.
In Science, all the prefixes used with units are some power of 10. Table 2.4 lists some of
these prefixes. You will not use most of these prefixes, but those prefixes listed in bold should
be learnt. The case of the prefix symbol is very important. Where a letter features twice in the
table, it is written in uppercase for exponents bigger than one and in lowercase for exponents
less than one. For example M means mega (106) and m means milli (10−3).

file_data: 2.7|The Importance of Units|17
Without units much of our work as scientists would be meaningless. We need to express our
thoughts clearly and units give meaning to the numbers we measure and calculate. Depending
on which units we use, the numbers are different. For example if you have 12 water, it means
nothing. You could have 12 ml of water, 12 litres of water, or even 12 bottles of water. Units
are an essential part of the language we use. Units must be specified when expressing physical
quantities. Imagine that you are baking a cake, but the units, like grams and millilitres, for the
flour, milk, sugar and baking powder are not specified!

file_data: 2.8|How to Change Units|17
It is very important that you are aware that different systems of units exist. Furthermore, you
must be able to convert between units. Being able to change between units (for example,
converting from millimetres to metres) is a useful skill in Science.
If you want to change millimetre to metre, you divide by 1000 (follow the arrow from mm to m);
or if you want to change kilometre to millimetre, you multiply by 1000×1000.

file_data: 2.8.1|Two other useful conversions|19
Very often in Science you need to convert speed and temperature. The following two rules will
help you do this:
Converting speed
When converting km·h−1 to m·s−1you divide by 3,6. For example 72 km·h−1 ÷ 3,6 = 20 m·s−1.
When converting m·s−1to km·h−1, you multiply by 3,6. For example 30 m·s−1×3,6 = 108 km·h−1.
Converting temperature
Converting between the kelvin and celsius temperature scales is easy. To convert from celsius
to kelvin add 273. To convert from kelvin to celsius subtract 273. Representing the kelvin
temperature by TK and the celsius temperature by ToC,

file_data: 2.9|A sanity test|19
A sanity test is a method of checking whether an answer makes sense. All we have to do is to
take a careful look at our answer and ask the question Does the answer make sense?
Imagine you were calculating the number of people in a classroom. If the answer you got was
1 000 000 people you would know it was wrong — it is not possible to have that many people
in a classroom. That is all a sanity test is — is your answer insane or not?
It is useful to have an idea of some numbers before we start. For example, let us consider masses.
An average person has a mass around 70 kg, while the heaviest person in medical history had a
mass of 635 kg. If you ever have to calculate a person’s mass and you get 7 000 kg, this should
fail your sanity check — your answer is insane and you must have made a mistake somewhere.
In the same way an answer of 0.01 kg should fail your sanity test.
The only problem with a sanity check is that you must know what typical values for things are.
For example, finding the number of learners in a classroom you need to know that there are
usually 20–50 people in a classroom. If you get and answer of 2500, you should realise that it is
wrong.

file_data: 2.10|Summary|19


file_data: 2.11|End of Chapter Exercises|21


file_data: 3|Motion in One Dimension - Grade 10|23


file_data: 3.1|Introduction|23
This chapter is about how things move in a straight line or more scientifically how things move in
one dimension. This is useful for learning how to describe the movement of cars along a straight
road or of trains along straight railway tracks. If you want to understand how any object moves,
for example a car on the freeway, a soccer ball being kicked towards the goal or your dog chasing
the neighbour’s cat, then you have to understand three basic ideas about what it means when
something is moving. These three ideas describe different parts of exactly how an object moves.
They are:
1. position or displacement which tells us exactly where the object is,
2. speed or velocity which tells us exactly how fast the object’s position is changing or more
familiarly, how fast the object is moving, and
3. acceleration which tells us exactly how fast the object’s velocity is changing.
You will also learn how to use position, displacement, speed, velocity and acceleration to describe
the motion of simple objects. You will learn how to read and draw graphs that summarise the
motion of a moving object. You will also learn about the equations that can be used to describe
motion and how to apply these equations to objects moving in one dimension.

file_data: 3.2|Reference Point, Frame of Reference and Position|23
The most important idea when studying motion, is you have to know where you are. The
word position describes your location (where you are). However, saying that you are here is
meaningless, and you have to specify your position relative to a known reference point. For
example, if you are 2 m from the doorway, inside your classroom then your reference point is
the doorway. This defines your position inside the classroom. Notice that you need a reference
point (the doorway) and a direction (inside) to define your location.

file_data: 3.2.1|Frames of Reference|23
Definition: Frame of Reference
A frame of reference is a reference point combined with a set of directions.
A frame of reference is similar to the idea of a reference point. A frame of reference is defined
as a reference point combined with a set of directions. For example, a boy is standing still inside a train as it pulls out of a station. You are standing on the platform watching the train move
from left to right. To you it looks as if the boy is moving from left to right, because relative
to where you are standing (the platform), he is moving. According to the boy, and his frame of
reference (the train), he is not moving.
A frame of reference must have an origin (where you are standing on the platform) and at least
a positive direction. The train was moving from left to right, making to your right positive and
to your left negative. If someone else was looking at the same boy, his frame of reference will
be different. For example, if he was standing on the other side of the platform, the boy will be
moving from right to left.

file_data: 3.2.2|Position|25
Definition: Position
Position is a measurement of a location, with reference to an origin.
A position is a measurement of a location, with reference to an origin. Positions can therefore be
negative or positive. The symbol x is used to indicate position. x has units of length for example
cm, m or km. Figure 3.2.2 shows the position of a school. Depending on what reference point
we choose, we can say that the school is 300 m from Joan’s house (with Joan’s house as the
reference point or origin) or 500 m from Joel’s house (with Joel’s house as the reference point
or origin).
The shop is also 300 m from Joan’s house, but in the opposite direction as the school. When
we choose a reference point, we have a positive direction and a negative direction. If we choose the direction towards the school as positive, then the direction towards the shop is negative. A
negative direction is always opposite to the direction chosen as positive.

file_data: 3.3|Displacement and Distance|28
Definition: Displacement
Displacement is the change in an object’s position.
The displacement of an object is defined as its change in position (final position minus initial
position). Displacement has a magnitude and direction and is therefore a vector. For example,
if the initial position of a car is xi and it moves to a final position of xf , then the displacement
is:
However, subtracting an initial quantity from a final quantity happens often in Physics, so we
use the shortcut to mean final - initial. Therefore, displacement can be written:
Important: The words initial and final will be used very often in Physics. Initial will always
refer to something that happened earlier in time and final will always refer to something
that happened later in time. It will often happen that the final value is smaller than the
initial value, such that the difference is negative. This is ok!
Displacement does not depend on the path travelled, but only on the initial and final positions
(Figure 3.4). We use the word distance to describe how far an object travels along a particular
path. Distance is the actual distance that was covered. Distance (symbol d) does not have a
direction, so it is a scalar. Displacement is the shortest distance from the starting point to the
endpoint – from the school to the shop in the figure. Displacement has direction and is therefore
a vector.
Figure 3.2.2 shows the five houses we discussed earlier. Jack walks to school, but instead of
walking straight to school, he decided to walk to his friend Joel’s house first to fetch him so that
they can walk to school together. Jack covers a distance of 400 m to Joel’s house and another
500 m to school. He covers a distance of 900 m. His displacement, however, is only 100 m
towards the school. This is because displacement only looks at the starting position (his house)
and the end position (the school). It does not depend on the path he travelled.
To calculate his distance and displacement, we need to choose a reference point and a direction.
Let’s choose Jack’s house as the reference point, and towards Joel’s house as the positive direc-
tion (which means that towards the school is negative). We would do the calculations as follows:
It is possible to have a displacement of 0 m and a distance that is not 0 m. This happens
when an object completes a round trip back to its original position, like an athlete running
around a track.

file_data: 3.3.1|Interpreting Direction|29
Very often in calculations you will get a negative answer. For example, Jack’s displacement in
the example above, is calculated as -100 m. The minus sign in front of the answer means that
his displacement is 100 m in the opposite direction (opposite to the direction chosen as positive
in the beginning of the question). When we start a calculation we choose a frame of reference
and a positive direction. In the first example above, the reference point is Jack’s house and the
positive direction is towards Joel’s house. Therefore Jack’s displacement is 100 m towards the
school. Notice that distance has no direction, but displacement has.


file_data: 3.3.2|Differences between Distance and Displacement|29
Definition: Vectors and Scalars
A vector is a physical quantity with magnitude (size) and direction. A scalar is a physical
quantity with magnitude (size) only.


file_data: 3.4|Speed, Average Velocity and Instantaneous Velocity|31
Definition: Velocity
Velocity is the rate of change of position.
Definition: Instantaneous velocity
Instantaneous velocity is the velocity of an accelerating body at a specific instant in time.
Definition: Average velocity
Average velocity is the total displacement of a body over a time interval.
Velocity is the rate of change of position. It tells us how much an object’s position changes in
time. This is the same as the displacement divided by the time taken. Since displacement is a
vector and time taken is a scalar, velocity is also a vector. We use the symbol v for velocity. If
we have a displacement of x and a time taken of t, v is then defined as:
Velocity can be positive or negative. Positive values of velocity mean that the object is moving
away from the reference point or origin and negative values mean that the object is moving
towards the reference point or origin.
Important: An instant in time is different from the time taken or the time interval. It
is therefore useful to use the symbol t for an instant in time (for example during the 4th
second) and the symbol t for the time taken (for example during the first 5 seconds of
the motion).
Average velocity (symbol v) is the displacement for the whole motion divided by the time taken
for the whole motion. Instantaneous velocity is the velocity at a specific instant in time.
(Average) Speed (symbol s) is the distance travelled (d) divided by the time taken (t) for
the journey. Distance and time are scalars and therefore speed will also be a scalar. Speed is
calculated as follows:
Instantaneous speed is the magnitude of instantaneous velocity. It has the same value, but no
direction.


file_data: 3.4.1|Differences between Speed and Velocity|35
The differences between speed and velocity can be summarised as:
Speed
1. depends on the path taken 
2. always positive 
3. is a scalar 
4. no dependence on direction and
so is only positive

Velocity
1. independent of path taken
2. can be positive or negative
3. is a vector
4. direction can be guessed from the sign (i.e. positive or negative)
Additionally, an object that makes a round trip, i.e. travels away from its starting point and then
returns to the same point has zero velocity but travels a non-zero speed.


file_data: 3.5|Acceleration|38
Definition: Acceleration
Acceleration is the rate of change of velocity.
Acceleration (symbol a) is the rate of change of velocity. It is a measure of how fast the velocity
of an object changes in time. If we have a change in velocity (v) over a time interval (t),
then the acceleration (a) is defined as:
Since velocity is a vector, acceleration is also a vector. Acceleration does not provide any infor-
mation about a motion, but only about how the motion changes. It is not possible to tell how
fast an object is moving or in which direction from the acceleration.
Like velocity, acceleration can be negative or positive. We see that when the sign of the acceler-
ation and the velocity are the same, the object is speeding up. If both velocity and acceleration
are positive, the object is speeding up in a positive direction. If both velocity and acceleration
are negative, the object is speeding up in a negative direction. If velocity is positive and accel-
eration is negative, then the object is slowing down. Similarly, if the velocity is negative and the
acceleration is positive the object is slowing down. This is illustrated in the following worked
example.
Important: Acceleration does not tell us about the direction of the motion. Acceleration
only tells us how the velocity changes.
Important: Deceleration
Avoid the use of the word deceleration to refer to a negative acceleration. This word usually
means slowing down and it is possible for an object to slow down with both a positive and
negative acceleration, because the sign of the velocity of the object must also be taken into
account to determine whether the body is slowing down or not.


file_data: 3.6|Description of Motion|39
The purpose of this chapter is to describe motion, and now that we understand the definitions of
displacement, distance, velocity, speed and acceleration, we are ready to start using these ideas
to describe how an object is moving. There are many ways of describing motion:
1. words
2. diagrams
3. graphs
These methods will be described in this section.
We will consider three types of motion: when the object is not moving (stationary object), when
the object is moving at a constant velocity (uniform motion) and when the object is moving at
a constant acceleration (motion at constant acceleration).


file_data: 3.6.1|Stationary Object|40
The simplest motion that we can come across is that of a stationary object. A stationary object
does not move and so its position does not change, for as long as it is standing still. An example
of this situation is when someone is waiting for something without moving. The person remains
in the same position.
Lesedi is waiting for a taxi. He is standing two metres from a stop street at t = 0 s. After
one minute, at t = 60 s, he is still 2 metres from the stop street and after two minutes, at
t = 120 s, also 2 metres from the stop street. His position has not changed. His displacement
is zero (because his position is the same), his velocity is zero (because his displacement is zero)
and his acceleration is also zero (because his velocity is not changing).
We can now draw graphs of position vs.time (x vs. t), velocity vs.time (v vs. t) and acceleration
vs.time (a vs. t) for a stationary object. The graphs are shown in Figure 3.5. Lesedi’s position
is 2 metres from the stop street. If the stop street is taken as the reference point, his position
remains at 2 metres for 120 seconds. The graph is a horisontal line at 2 m. The velocity and
acceleration graphs are also shown. They are both horisontal lines on the x-axis. Since his
position is not changing, his velocity is 0 m·s−1and since velocity is not changing acceleration is
0 m·s−2.
Definition: Gradient
The gradient of a line can be calculated by dividing the change in the y-value by the change
in the x-value.
m = y
x
Since we know that velocity is the rate of change of position, we can confirm the value for the
velocity vs. time graph, by calculating the gradient of the x vs. t graph.

file_data: 3.6.2|Motion at Constant Velocity|41
Motion at a constant velocity or uniform motion means that the position of the object is changing
at the same rate.
Assume that Lesedi takes 100 s to walk the 100 m to the taxi-stop every morning. If we assume
that Lesedi’s house is the origin, then Lesedi’s velocity is:
Lesedi’s velocity is 1 m·s−1. This means that he walked 1 m in the first second, another metre
in the second second, and another in the third second, and so on. For example, after 50 s he
will be 50 m from home. His position increases by 1 m every 1 s. A diagram of Lesedi’s position
is shown in Figure 3.6.
We can now draw graphs of position vs.time (x vs. t), velocity vs.time (v vs. t) and acceleration
vs.time (a vs. t) for Lesedi moving at a constant velocity. The graphs are shown in Figure 3.7.
In the evening Lesedi walks 100 m from the bus stop to his house in 100 s. Assume that Lesedi’s
house is the origin. The following graphs can be drawn to describe the motion.
We see that the v vs. t graph is a horisontal line. If the velocity vs. time graph is a horisontal
line, it means that the velocity is constant (not changing). Motion at a constant velocity is
known as uniform motion.
We can use the x vs. t to calculate the velocity by finding the gradient of the line.
Lesedi has a velocity of -1 m·s−1, or 1 m·s−1towards his house. You will notice that the v vs. t
graph is a horisontal line corresponding to a velocity of -1 m·s−1. The horisontal line means that
the velocity stays the same (remains constant) during the motion. This is uniform velocity.



file_data: 3.6.3|Motion at Constant Acceleration|46
The final situation we will be studying is motion at constant acceleration. We know that
acceleration is the rate of change of velocity. So, if we have a constant acceleration, this
means that the velocity changes at a constant rate.
Let’s look at our first example of Lesedi waiting at the taxi stop again. A taxi arrived and Lesedi
got in. The taxi stopped at the stop street and then accelerated as follows: After 1 s the taxi
covered a distance of 2,5 m, after 2 s it covered 10 m, after 3 seconds it covered 22,5 m and
after 4 s it covered 40 m. The taxi is covering a larger distance every second. This means that
it is accelerating.
The acceleration does not change during the motion (the gradient stays constant). This is
motion at constant or uniform acceleration.
The graphs for this situation are shown in Figure 3.9.
Velocity from Acceleration vs. Time Graphs
Just as we used velocity vs. time graphs to find displacement, we can use acceleration vs. time
graphs to find the velocity of an object at a given moment in time. We simply calculate the
area under the acceleration vs. time graph, at a given time. In the graph below, showing an
object at a constant positive acceleration, the increase in velocity of the object after 2 seconds
corresponds to the shaded portion.
The velocity of the object at t = 2 s is therefore 10 m·s−1. This corresponds with the values
obtained in Figure 3.9.

file_data: 3.7|Summary of Graphs|48
Important: Often you will be required to describe the motion of an object that is presented
as a graph of either position, velocity or acceleration as functions of time. The description
of the motion represented by a graph should include the following (where possible):
1. whether the object is moving in the positive or negative direction
2. whether the object is at rest, moving at constant velocity or moving at constant
positive acceleration (speeding up) or constant negative acceleration (slowing down)
You will also often be required to draw graphs based on a description of the motion in words
or from a diagram. Remember that these are just different methods of presenting the same
information. If you keep in mind the general shapes of the graphs for the different types of
motion, there should not be any difficulty with explaining what is happening.


file_data: 3.8|Worked Examples|49


file_data: 3.9|Equations of Motion|54
In this chapter we will look at the third way to describe motion. We have looked at describing
motion in terms of graphs and words. In this section we examine equations that can be used to
describe motion.
This section is about solving problems relating to uniformly accelerated motion. In other words,
motion at constant acceleration.
The questions can vary a lot, but the following method for answering them will always work.
Use this when attempting a question that involves motion with constant acceleration. You need
any three known quantities (vi, vf , x, t or a) to be able to calculate the fourth one.
1. Read the question carefully to identify the quantities that are given. Write them down.
2. Identify the equation to use. Write it down!!!
3. Ensure that all the values are in the correct unit and fill them in your equation.
4. Calculate the answer and fill in its unit.
Galileo Galilei of Pisa, Italy, was the first to determined the correct mathematical
law for acceleration: the total distance covered, starting from rest, is proportional
to the square of the time. He also concluded that objects retain their velocity
unless a force – often friction – acts upon them, refuting the accepted Aristotelian
hypothesis that objects ”naturally” slow down and stop unless a force acts upon
them. This principle was incorporated into Newton’s laws of motion (1st law).


file_data: 3.9.1|Finding the Equations of Motion|54


file_data: 3.10|Applications in the Real-World|59
What we have learnt in this chapter can be directly applied to road safety. We can analyse the
relationship between speed and stopping distance. The following worked example illustrates this
application.


file_data: 3.11|Summary|61


file_data: 3.12|End of Chapter Exercises: Motion in One Dimension|62





file_data: 4|Gravity and Mechanical Energy - Grade 10|67


file_data: 4.1|Weight|67
Weight is the gravitational force that the Earth exerts on any object. The weight of an objects
gives you an indication of how strongly the Earth attracts that body towards its centre. Weight
is calculated as follows:
Weight = mg
where m = mass of the object (in kg)
and g = the acceleration due to gravity (9,8 m·s−2)
Important: Weight is sometimes abbreviated as Fg which refers to the force of gravity. Do
not use the abbreviation ’W’ for weight as it refers to ’Work’.
Now, we have said that the value of g is approximately 9,8 m·s−2on the surface of the Earth.
The actual value varies slightly over the surface of the Earth. Each planet in our Solar System
has its own value for g. These values are listed as multiples of g on Earth in Table 4.1


file_data: 4.1.1|Differences between Mass and Weight|68
Mass is measured in kilograms (kg) and is the amount of matter in an object. An object’s mass
does not change unless matter is added or removed from the object.
The differences between mass and weight can be summarised in the following table:
Mass 
1. is a measure of how many molecules there are in an object.
2. is measured in kilograms. 
3. is the same on any planet. 
4. is a scalar. 
Weight
1. is the force with which the Earth attracts an object.
2. is measured in newtons
3. is different on different planets.
4. is a vector.

file_data: 4.2|Acceleration due to Gravity|69


file_data: 4.2.1|Gravitational Fields|69
A field is a region of space in which a mass experiences a force. Therefore, a gravitational field
is a region of space in which a mass experiences a gravitational force.

file_data: 4.2.2|Free fall|69
Important: Free fall is motion in the Earth’s gravitational field when no other forces act
on the object.
Free fall is the term used to describe a special kind of motion in the Earth’s gravitational field.
Free fall is motion in the Earth’s gravitational field when no other forces act on the object. It
is basically an ideal situation, since in reality, there is always some air friction which slows down
the motion.
If a metal ball and tennis ball (of the same size) were dropped from the same height, both would
reach the ground at the same time. It does not matter that the one ball is heavier than the
other. The acceleration of an object due to gravity is independent of the mass of the object. It
does not matter what the mass of the object is.
The shape of the object, however, is important. The sheet of paper took much longer to reach
the ground than the tennis ball. This is because the effect of air friction on the paper was much
greater than the air friction on the tennis ball.
If we lived in a world where there was no air resistance, the A4 sheet of paper and the tennis
ball would reach the ground at the same time. This happens in outer space or in a vaccuum.
Galileo Galilei, an Italian scientist, studied the motion of objects. The following case study will
tell you more about one of his investigations.


file_data: 4.3|Potential Energy|73
The potential energy of an object is generally defined as the energy an object has because of
its position relative to other objects that it interacts with. There are different kinds of potential
energy such as gravitional potential energy, chemical potential energy, electrical potential energy,
to name a few. In this section we will be looking at gravitational potential energy.
Definition: Potential energy
Potential energy is the energy an object has due to its position or state.
Gravitational potential energy is the energy of an object due to its position above the surface of
the Earth. The symbol PE is used to refer to gravitational potential energy. You will often find
that the words potential energy are used where gravitational potential energy is meant. We can
define potential energy (or gravitational potential energy, if you like) as:
PE = mgh (4.5)
where PE = potential energy measured in joules (J)
m = mass of the object (measured in kg)
g = gravitational acceleration (9,8 m·s−2)
h = perpendicular height from the reference point (measured in m)
A suitcase, with a mass of 1 kg, is placed at the top of a 2 m high cupboard. By lifting the
suitcase against the force of gravity, we give the suitcase potential energy. This potential energy
can be calculated using equation 4.5.
If the suitcase falls off the cupboard, it will lose its potential energy. Halfway down the cupboard,
the suitcase will have lost half its potential energy and will have only 9,8 J left. At the bottom
of the cupboard the suitcase will have lost all it’s potential energy and it’s potential energy will
be equal to zero.
Objects have maximum potential energy at a maximum height and will lose their potential
energy as they fall.


file_data: 4.4|Kinetic Energy|75
Definition: Kinetic Energy
Kinetic energy is the energy an object has due to its motion.
Kinetic energy is the energy an object has because of its motion. This means that any moving
object has kinetic energy. The faster it moves, the more kinetic energy it has. Kinetic energy
(KE) is therefore dependent on the velocity of the object. The mass of the object also plays a role. A truck of 2000 kg, moving at 100 km·hr−1, will have more kinetic energy than a car of
500 kg, also moving at 100 km·hr−1. Kinetic energy is defined as:
Consider the 1 kg suitcase on the cupboard that was discussed earlier. When the suitcase falls, it
will gain velocity (fall faster), until it reaches the ground with a maximum velocity. The suitcase
will not have any kinetic energy when it is on top of the cupboard because it is not moving.
Once it starts to fall it will gain kinetic energy, because it gains velocity. Its kinetic energy will
increase until it is a maximum when the suitcase reaches the ground.

file_data: 4.4.1|Checking units|77
According to the equation for kinetic energy, the unit should be kg·m2 ·s−2. We can prove that
this unit is equal to the joule, the unit for energy.


file_data: 4.5|Mechanical Energy|78
Important: Mechanical energy is the sum of the gravitational potential energy and the
kinetic energy.
Mechanical energy, U, is simply the sum of gravitational potential energy (PE) and the kinetic
energy (KE). Mechanical energy is defined as:


file_data: 4.5.1|Conservation of Mechanical Energy|78
The Law of Conservation of Energy states:
Energy cannot be created or destroyed, but is merely changed from one form into
another.
Definition: Conservation of Energy
The Law of Conservation of Energy: Energy cannot be created or destroyed, but is merely
changed from one form into another.
So far we have looked at two types of energy: gravitational potential energy and kinetic energy.
The sum of the gravitational potential energy and kinetic energy is called the mechanical energy.
In a closed system, one where there are no external forces acting, the mechanical energy will
remain constant. In other words, it will not change (become more or less). This is called the
Law of Conservation of Mechanical Energy and it states:
The total amount of mechanical energy in a closed system remains constant.
Definition: Conservation of Mechanical Energy
Law of Conservation of Mechanical Energy: The total amount of mechanical energy in a
closed system remains constant.
This means that potential energy can become kinetic energy, or vise versa, but energy cannot
’dissappear’. The mechanical energy of an object moving in the Earth’s gravitational field (or
accelerating as a result of gravity) is constant or conserved, unless external forces, like air
resistance, acts on the object.
We can now use the conservation of mechanical energy to calculate the velocity of a body in
freefall and show that the velocity is independent of mass.
Important: In problems involving the use of conservation of energy, the path taken by
the object can be ignored. The only important quantities are the object’s velocity (which
gives its kinetic energy) and height above the reference point (which gives its gravitational
potential energy).
Important: In the absence of friction, mechanical energy is conserved and
Ubefore = Uafter
In the presence of friction, mechanical energy is not conserved. The mechanical energy lost
is equal to the work done against friction.
U = Ubefore − Uafter = work done against friction
In general mechanical energy is conserved in the absence of external forces. Examples of external
forces are: applied forces, frictional forces, air resistance, tension, normal forces.
In the presence of internal forces like the force due to gravity or the force in a spring, mechanical
energy is conserved.

file_data: 4.5.2|Using the Law of Conservation of Energy|79
Mechanical energy is conserved (in the absence of friction). Therefore we can say that the sum
of the PE and the KE anywhere during the motion must be equal to the sum of the PE and
the KE anywhere else in the motion.
We can now apply this to the example of the suitcase on the cupboard. Consider the mechanical
energy of the suitcase at the top and at the bottom. We can say:
The suitcase will strike the ground with a velocity of 6,26 m·s−1.
From this we see that when an object is lifted, like the suitcase in our example, it gains potential
energy. As it falls back to the ground, it will lose this potential energy, but gain kinetic en-
ergy. We know that energy cannot be created or destroyed, but only changed from one form into
another. In our example, the potential energy that the suitcase loses is changed to kinetic energy.
The suitcase will have maximum potential energy at the top of the cupboard and maximum
kinetic energy at the bottom of the cupboard. Halfway down it will have half kinetic energy and
half potential energy. As it moves down, the potential energy will be converted (changed) into
kinetic energy until all the potential energy is gone and only kinetic energy is left. The 19,6 J of
potential energy at the top will become 19,6 J of kinetic energy at the bottom.


file_data: 4.6|Energy graphs|82
Let us consider our example of the suitcase on the cupboard, once more.
Let’s look at each of these quantities and draw a graph for each. We will look at how each
quantity changes as the suitcase falls from the top to the bottom of the cupboard.
• Potential energy: The potential energy starts off at a maximum and decreases until it
reaches zero at the bottom of the cupboard. It had fallen a distance of 2 metres.
Kinetic energy: The kinetic energy is zero at the start of the fall. When the suitcase
reaches the ground, the kinetic energy is a miximum. We also use distance on the x-axis.
Mechanical energy: The mechanical energy is constant throughout the motion and is
always a maximum. At any point in time, when we add the potential energy and the
kinetic energy, we will get the same number.

file_data: 4.7|Summary|83


file_data: 4.8|End of Chapter Exercises: Gravity and Mechanical Energy|84


file_data: 5|Transverse Pulses - Grade 10|87


file_data: 5.1|Introduction|87
This chapter forms the basis of the discussion into mechanical waves. Waves are all around us,
even though most of us are not aware of it. The most common waves are waves in the sea, but
waves can be created in any container of water, ranging from an ocean to a tea-cup. Simply, a
wave is moving energy.

file_data: 5.2|What is a medium?|87
In this chapter, as well as in the following chapters, we will speak about waves moving in a
medium. A medium is just the substance or material through which waves move. In other words
the medium carries the wave from one place to another. The medium does not create the wave
and the medium is not the wave. Air is a medium for sound waves, water is a medium for water
waves and rock is a medium for earthquakes (which are also a type of wave). Air, water and
rock are therefore examples of media (media is the plural of medium).
Definition: Medium
A medium is the substance or material in which a wave will move.
In each medium, the atoms that make up the medium are moved temporarily from their rest
position. In order for a wave to travel, the different parts of the medium must be able to interact
with each other.

file_data: 5.3|What is a pulse?|87
In the activity, we created a pulse. A pulse is a single disturbance that moves through a
medium. A transverse pulse moves perpendicular to the medium. Figure 5.1 shows an example
of a transverse pulse. In the activity, the rope or spring was held horizontally and the pulse
moved the rope up and down. This was an example of a transverse pulse.
Definition: Pulse
A pulse is a single disturbance that moves through a medium.


file_data: 5.3.1|Pulse Length and Amplitude|88
The amplitude of a pulse is a measurement of how far the medium is displaced from a position
of rest. The pulse length is a measurement of how long the pulse is. Both these quantities are
shown in Figure 5.1.
Definition: Amplitude
The amplitude of a pulse is a measurement of how far the medium is displaced from rest.
In the activity, we found that the values for how high the pulse (a) is and how wide the pulse
(p) is the same at different times. Pulse length and amplitude are two important quantities of
a pulse.

file_data: 5.3.2|Pulse Speed|89
Definition: Pulse Speed
Pulse speed is the distance a pulse travels in a specific time.
In Chapter 3 we saw that speed was defined as the distance travelled in a specified time. We
can use the same definition of speed to calculate how fast a pulse travels. If the pulse travels a
distance d in a time t, then the pulse speed v is:
Important: The pulse speed depends on the properties of the medium and not on the
amplitude or pulse length of the pulse.


file_data: 5.4|Graphs of Position and Velocity|90
When a pulse moves through a medium, there are two different motions: the motion of the
particles of the medium and the motion of the pulse. These two motions are at right angles to
each other when the pulse is transverse. Each motion will be discussed.
Consider the situation shown in Figure ??. The dot represents one particle of the medium. We
see that as the pulse moves to the right the particle only moves up and down.


file_data: 5.4.1|Motion of a Particle of the Medium|90
First we consider the motion of a particle of the medium when a pulse moves through the
medium. For the explanation we will zoom into the medium so that we are looking at the atoms
of the medium. These atoms are connected to each other as shown in Figure 5.2.
When a pulse moves through the medium, the particles in the medium only move up and down.
We can see this in the figure below which shows the motion of a single particle as a pulse moves
through the medium.
Important: A particle in the medium only moves up and down when a transverse pulse
moves through the medium. The pulse moves from left to right (or right to left). The
motion of the particle is perpendicular to the motion of a transverse pulse.
If you consider the motion of the particle as a function of time, you can draw a graph of position
vs. time and velocity vs. time.

file_data: 5.4.2|Motion of the Pulse|92
The motion of the pulse is much simpler than the motion of a particle in the medium.
Important: A point on a transverse pulse, eg. the peak, only moves in the direction of the
motion of the pulse.

file_data: 5.5|Transmission and Reflection of a Pulse at a Boundary|96
What happens when a pulse travelling in one medium finds that medium is joined to another?
When a pulse meets a boundary between two media, part of the pulse is reflected and part of it
is transmitted. You will see that in the thin rope the pulse moves back (is reflected). The pulse
is also passed on (transmitted) to the thick rope and it moves away from the boundary.
When a pulse is transmitted from one medium to another, like from a thin rope to a thicker one,
the pulse will change where it meets the boundary of the two mediums (for example where the
ropes are joined). When a pulse moves from a thin rope to a thicker one, the speed of the pulse
will decrease. The pulse will move slower and the pulse length will increase.
When a pulse moves from a thick rope to a thinner one, the opposite happens. The pulse speed
will increase and the pulse length will decrease.
When the speed of the pulse increases, the pulse length will decrease. If the speed decreases,
the pulse length will increase. The incident pulse is the one that arrives at the boundary. The
reflected pulse is the one that moves back, away from the boundary. The transmitted pulse
is the one that moves into the new medium, away from the boundary.


file_data: 5.6|Reflection of a Pulse from Fixed and Free Ends|97
Let us now consider what happens to a pulse when it reaches the end of a medium. The medium
can be fixed, like a rope tied to a wall, or it can be free, like a rope tied loosely to a pole.


file_data: 5.6.1|Reflection of a Pulse from a Fixed End|97
When the end of the medium is fixed, for example a rope tied to a wall, a pulse reflects from
the fixed end, but the pulse is inverted (i.e. it is upside-down). This is shown in Figure 5.9.

file_data: 5.6.2|Reflection of a Pulse from a Free End|98
When the end of the medium is free, for example a rope tied loosely to a pole, a pulse reflects
from the free end, but the pulse is not inverted. This is shown in Figure 5.10. We draw the
free end as a ring around the pole. The ring will move up and down the pole, while the pulse is
reflected away from the pole.
Important: The fixed and free ends that were discussed in this section are examples of
boundary conditions. You will see more of boundary conditions as you progress in the
Physics syllabus.


file_data: 5.7|Superposition of Pulses|99
Two or more pulses can pass through the same medium at that same time. The resulting pulse
is obtained by using the principle of superposition. The principle of superposition states that the
effect of the pulses is the sum of their individual effects. After pulses pass through each other,
each pulse continues along its original direction of travel, and their original amplitudes remain
unchanged.
Constructive interference takes place when two pulses meet each other to create a larger pulse.
The amplitude of the resulting pulse is the sum of the amplitudes of the two initial pulses. This
is shown in Figure 5.11.
Definition: Constructive interference is when two pulses meet, resulting in a bigger
pulse.
Destructive interference takes place when two pulses meet and cancel each other. The amplitude
of the resulting pulse is the sum of the amplitudes of the two initial pulses, but the one amplitude
will be a negative number. This is shown in Figure 5.12. In general, amplitudes of individual
pulses add together to give the amplitude of the resultant pulse.
Definition: Destructive interference is when two pulses meet, resulting in a smaller
pulse.

file_data: 5.8|Exercises - Transverse Pulses|102




file_data: 6|Transverse Waves - Grade 10|105


file_data: 6.1|Introduction|105
Waves occur frequently in nature. The most obvious examples are waves in water, on a dam, in
the ocean, or in a bucket. We are most interested in the properties that waves have. All waves
have the same properties, so if we study waves in water, then we can transfer our knowledge to
predict how other examples of waves will behave.

file_data: 6.2|What is a transverse wave?|105
We have studied pulses in Chapter 5, and know that a pulse is a single disturbance that travels
through a medium. A wave is a periodic, continuous disturbance that consists of a train of
pulses.
Definition: Wave
A wave is a periodic, continuous disturbance that consists of a train of pulses.
Definition: Transverse wave
A transverse wave is a wave where the movement of the particles of the medium is perpen-
dicular to the direction of propagation of the wave.
In the Activity, you have created waves. The medium through which these waves propagated
was the rope, which is obviously made up of a very large number of particles (atoms). From the
activity, you would have noticed that the wave travelled from left to right, but the particles (the
ribbon) moved only up and down.
When the particles of a medium move at right angles to the direction of propagation of a wave,
the wave is called transverse. For waves, there is no net displacement of the particles (they
return to their equilibrium position), but there is a net displacement of the wave. There are thus
two different motions: the motion of the particles of the medium and the motion of the wave.

file_data: 6.2.1|Peaks and Troughs|106
Waves consist of moving peaks (or crests) and troughs. A peak is the highest point the medium
rises to and a trough is the lowest point the medium sinks to.
Peaks and troughs on a transverse wave are shown in Figure 6.2.
Definition: Peaks and troughs
A peak is a point on the wave where the displacement of the medium is at a maximum.
A point on the wave is a trough if the displacement of the medium at that point is at a
minimum.

file_data: 6.2.2|Amplitude and Wavelength|107
There are a few properties that we saw with pulses that also apply to waves. These are amplitude
and wavelength (we called this pulse length).
Definition: Amplitude
The amplitude is the maximum displacement of a particle from its equilibrium position.
As we have seen in the activity on amplitude, the distance between the peak and the equilibrium
position is equal to the distance between the trough and the equilibrium position. This distance
is known as the amplitude of the wave, and is the characteristic height of wave, above or below
the equilibrium position. Normally the symbol A is used to represent the amplitude of a wave.
The SI unit of amplitude is the metre (m).
As we have seen in the activity on wavelength, the distance between two adjacent peaks is the
same no matter which two adjacent peaks you choose. There is a fixed distance between the
peaks. Similarly, we have seen that there is a fixed distance between the troughs, no matter
which two troughs you look at. More importantly, the distance between two adjacent peaks is
the same as the distance between two adjacent troughs. This distance is call the wavelength of
the wave.
The symbol for the wavelength is λ (the Greek letter lambda) and wavelength is measured in
metres (m).

file_data: 6.2.3|Points in Phase|109
In the activity the distance between the indicated points was the same. These points are then
said to be in phase. Two points in phase are separate by an integer (0,1,2,3,...) number of
complete wave cycles. They do not have to be peaks or troughs, but they must be separated by
a complete number of wavelengths.
We then have an alternate definition of the wavelength as the distance between any two adjacent
points which are in phase.
Definition: Wavelength of wave
The wavelength of a wave is the distance between any two adjacent points that are in phase.
Points that are not in phase, those that are not separated by a complete number of wavelengths,
are called out of phase. Examples of points like these would be A and C, or D and E, or B and
H in the Activity.

file_data: 6.2.4|Period and Frequency|110
Imagine you are sitting next to a pond and you watch the waves going past you. First one peak
arrives, then a trough, and then another peak. Suppose you measure the time taken between
one peak arriving and then the next. This time will be the same for any two successive peaks
passing you. We call this time the period, and it is a characteristic of the wave.
The symbol T is used to represent the period. The period is measured in seconds (s).
Definition: The period (T) is the time taken for two successive peaks (or troughs)
to pass a fixed point.
Imagine the pond again. Just as a peak passes you, you start your stopwatch and count each
peak going past. After 1 second you stop the clock and stop counting. The number of peaks
that you have counted in the 1 second is the frequency of the wave.
Definition: The frequency is the number of successive peaks (or troughs) passing a
given point in 1 second.
The frequency and the period are related to each other. As the period is the time taken for
1 peak to pass, then the number of peaks passing the point in 1 second is 1
T . But this is the
frequency. So


file_data: 6.2.5|Speed of a Transverse Wave|111
In Chapter 3, we saw that speed was defined as
speed =
distance travelled
time taken
.
The distance between two successive peaks is 1 wavelength, λ. Thus in a time of 1 period, the
wave will travel 1 wavelength in distance. Thus the speed of the wave, v, is:
v =
distance travelled
time taken
=
λ
T
.
However, f = 1
T . Therefore, we can also write:
v =
λ
T
= λ ·
1
T
= λ · f
We call this equation the wave equation. To summarise, we have that v = λ · f where


file_data: 6.3|Graphs of Particle Motion|115
In Chapter 5, we saw that when a pulse moves through a medium, there are two different motions:
the motion of the particles of the medium and the motion of the pulse. These two motions are
at right angles to each other when the pulse is transverse. Since a transverse wave is a series of
transverse pulses, the particle in the medium and the wave move in exactly the same way as for
the pulse.
When a transverse wave moves through the medium, the particles in the medium only move up
and down. We can see this in the figure below, which shows the motion of a single particle as a
transverse wave moves through the medium.
As in Chapter 3, we can draw a graph of the particles’ position as a function of time. For the
wave shown in the above figure, we can draw the graph shown below.
The graph of the particle’s velocity as a function of time is obtained by taking the gradient of
the position vs. time graph. The graph of velocity vs. time for the position vs. time graph
above, is shown in the graph below.
The graph of the particle’s acceleration as a function of time is obtained by taking the gradient
of the velocity vs. time graph. The graph of acceleration vs. time for the position vs. time
graph shown above, is shown below.
As for motion in one dimension, these graphs can be used to describe the motion of the particle.
This is illustrated in the worked examples below.



file_data: 6.4|Standing Waves and Boundary Conditions|118


file_data: 6.4.1|Reflection of a Transverse Wave from a Fixed End|118
We have seen that when a pulse meets a fixed endpoint, the pulse is reflected, but it is inverted.
Since a transverse wave is a series of pulses, a transverse wave meeting a fixed endpoint is also
reflected and the reflected wave is inverted. That means that the peaks and troughs are swapped
around.

file_data: 6.4.2|Reflection of a Transverse Wave from a Free End|118
If transverse waves are reflected from an end, which is free to move, the waves sent down the
string are reflected but do not suffer a phase shift as shown in Figure 6.4.

file_data: 6.4.3|Standing Waves|118
What happens when a reflected transverse wave meets an incident transverse wave? When two
waves move in opposite directions, through each other, interference takes place. If the two waves
have the same frequency and wavelength then standing waves are generated.
Standing waves are so-called because they appear to be standing still.
We can now look closely how standing waves are formed. Figure 6.5 shows a reflected wave
meeting an incident wave.
When they touch, both waves have an amplitude of zero:
Figure 6.6: A reflected wave (solid line) meets the incident wave (dashed line).
If we wait for a short time the ends of the two waves move past each other and the waves
overlap. To find the resultant wave, we add the two together.
Figure 6.7: A reflected wave (solid line) overlaps slightly with the incident wave (dashed line).
In this picture, we show the two waves as dotted lines and the sum of the two in the overlap
region is shown as a solid line:
The important thing to note in this case is that there are some points where the two waves
always destructively interfere to zero. If we let the two waves move a little further we get the
picture below:
Again we have to add the two waves together in the overlap region to see what the sum of the
waves looks like.
In this case the two waves have moved half a cycle past each other but because they are out of
phase they cancel out completely.
When the waves have moved past each other so that they are overlapping for a large region
the situation looks like a wave oscillating in place. The following sequence of diagrams show
what the resulting wave will look like. To make it clearer, the arrows at the top of the picture
show peaks where maximum positive constructive interference is taking place. The arrows at
the bottom of the picture show places where maximum negative interference is taking place.
As time goes by the peaks become smaller and the troughs become shallower but they do not
move.
For an instant the entire region will look completely flat.
The various points continue their motion in the same manner.
Eventually the picture looks like the complete reflection through the x-axis of what we started
with:
Then all the points begin to move back. Each point on the line is oscillating up and down with
a different amplitude.
If we look at the overall result, we get a standing wave.
Figure 6.8: A standing wave
If we superimpose the two cases where the peaks were at a maximum and the case where the
same waves were at a minimum we can see the lines that the points oscillate between. We call
this the envelope of the standing wave as it contains all the oscillations of the individual points.
To make the concept of the envelope clearer let us draw arrows describing the motion of points
along the line.
Every point in the medium containing a standing wave oscillates up and down and the amplitude
of the oscillations depends on the location of the point. It is convenient to draw the envelope
for the oscillations to describe the motion. We cannot draw the up and down arrows for every
single point!
Interesting Fact
Standing waves can be a problem in for example indoor concerts where the
dimensions of the concert venue coincide with particular wavelengths. Standing
waves can appear as ‘feedback’, which would occur if the standing wave was
picked up by the microphones on stage and amplified.

file_data: 6.4.4|Nodes and anti-nodes|122
A node is a point on a wave where no displacement takes place. In a standing wave, a node
is a place where the two waves cancel out completely as two waves destructively interfere in
the same place. A fixed end of a rope is a node. An anti-node is a point on a wave where
maximum displacement takes place. In a standing wave, an anti-node is a place where the two
waves constructively interfere. A free end of a rope is an anti-node.
Definition: Node
A node is a point on a wave where no displacement takes place. In a standing wave, a node
is a place where the two waves cancel out completely as two waves destructively interfere
in the same place. A fixed end of a rope is a node.
Definition: Anti-Node
An anti-node is a point on a wave where maximum displacement takes place. In a standing
wave, an anti-node is a place where the two waves constructively interfere. A free end of a
rope is an anti-node.
Important: The distance between two anti-nodes is only 1
2λ because it is the distance
from a peak to a trough in one of the waves forming the standing wave. It is the same as
the distance between two adjacent nodes. This will be important when we work out the
allowed wavelengths in tubes later. We can take this further because half-way between any
two anti-nodes is a node. Then the distance from the node to the anti-node is half the
distance between two anti-nodes. This is half of half a wavelength which is one quarter of
a wavelength

file_data: 6.4.5|Wavelengths of Standing Waves with Fixed and Free Ends|122
There are many applications which make use of the properties of waves and the use of fixed and
free ends. Most musical instruments rely on the basic picture that we have presented to create
specific sounds, either through standing pressure waves or standing vibratory waves in strings.
The key is to understand that a standing wave must be created in the medium that is oscillating.
There are restrictions as to what wavelengths can form standing waves in a medium.
For example, if we consider a rope that can move in a pipe such that it can have
• both ends free to move (Case 1)
• one end free and one end fixed (Case 2)
• both ends fixed (Case 3).
Each of these cases is slightly different because the free or fixed end determines whether a node or
anti-node will form when a standing wave is created in the rope. These are the main restrictions
when we determine the wavelengths of potential standing waves. These restrictions are known
as boundary conditions and must be met.
In the diagram below you can see the three different cases. It is possible to create standing
waves with different frequencies and wavelengths as long as the end criteria are met.
The longer the wavelength the less the number of anti-nodes in the standing waves. We cannot
have a standing wave with no anti-nodes because then there would be no oscillations. We use n
to number the anti-nodes. If all of the tubes have a length L and we know the end constraints
we can find the wavelength, λ, for a specific number of anti-nodes.
One Node
Let’s work out the longest wavelength we can have in each tube, i.e. the case for n = 1
Case 1: In the first tube, both ends must be nodes, so we can place one anti-node in the middle
of the tube. We know the distance from one node to another is 1
2λ and we also know this
distance is L. So we can equate the two and solve for the wavelength:
Case 2: In the second tube, one end must be a node and the other must be an anti-node. We
are looking at the case with one anti-node we are forced to have it at the end. We know the
distance from one node to another is 1
2λ but we only have half this distance contained in the
tube. So :
Case 3: Here both ends are closed and so we must have two nodes so it is impossible to construct
a case with only one node.
Two Nodes
Next we determine which wavelengths could be formed if we had two nodes. Remember that we
are dividing the tube up into smaller and smaller segments by having more nodes so we expect
the wavelengths to get shorter.
n = 2
λ = L λ = 4
3L λ = 2L
Case 1: Both ends are open and so they must be anti-nodes. We can have two nodes inside
the tube only if we have one anti-node contained inside the tube and one on each end. This
means we have 3 anti-nodes in the tube. The distance between any two anti-nodes is half
a wavelength. This means there is half wavelength between the left side and the middle and
another half wavelength between the middle and the right side so there must be one wavelength
inside the tube. The safest thing to do is work out how many half wavelengths there are and
equate this to the length of the tube L and then solve for λ.
Case 2: We want to have two nodes inside the tube. The left end must be a node and the right
end must be an anti-node. We can have one node inside the tube as drawn above. Again we can
count the number of distances between adjacent nodes or anti-nodes. If we start from the left
end we have one half wavelength between the end and the node inside the tube. The distance
from the node inside the tube to the right end which is an anti-node is half of the distance to
another node. So it is half of half a wavelength. Together these add up to the length of the
tube:
1
2
λ +
1
2
(
1
2
λ) = L
2
4
λ +
1
4
λ = L
3
4
λ = L
λ =
4
3
L
Case 3: In this case both ends have to be nodes. This means that the length of the tube is one
half wavelength: So we can equate the two and solve for the wavelength:
1
2
λ = L
λ = 2L
Important: If you ever calculate a longer wavelength for more nodes you have made a
mistake. Remember to check if your answers make sense!
Three Nodes
To see the complete pattern for all cases we need to check what the next step for case 3 is when
we have an additional node. Below is the diagram for the case where n = 3.
n = 3
λ = 2
3L λ = 4
5L λ = L
Case 1: Both ends are open and so they must be anti-nodes. We can have three nodes inside
the tube only if we have two anti-nodes contained inside the tube and one on each end. This
means we have 4 anti-nodes in the tube. The distance between any two anti-nodes is half a
wavelength. This means there is half wavelength between every adjacent pair of anti-nodes.
We count how many gaps there are between adjacent anti-nodes to determine how many half
wavelengths there are and equate this to the length of the tube L and then solve for λ.
we can count the number of distances between adjacent nodes or anti-nodes, together these add
up to the length of the tube. Remember that the distance between the node and an adjacent
anti-node is only half the distance between adjacent nodes. So starting from the left end we
count 3 nodes, so 2 half wavelength intervals and then only a node to anti-node distance:
2(
1
2
λ) +
1
2
(
1
2
λ) = L
λ +
1
4
λ = L
5
4
λ = L
λ =
4
5
L
Case 3: In this case both ends have to be nodes. With one node in between there are two
sets of adjacent nodes. This means that the length of the tube consists of two half wavelength
sections:

file_data: 6.4.6|Superposition and Interference|125
If two waves meet interesting things can happen. Waves are basically collective motion of
particles. So when two waves meet they both try to impose their collective motion on the
particles. This can have quite different results.
If two identical (same wavelength, amplitude and frequency) waves are both trying to form a
peak then they are able to achieve the sum of their efforts. The resulting motion will be a peak
which has a height which is the sum of the heights of the two waves. If two waves are both
trying to form a trough in the same place then a deeper trough is formed, the depth of which is
the sum of the depths of the two waves. Now in this case, the two waves have been trying to
do the same thing, and so add together constructively. This is called constructive interference.
If one wave is trying to form a peak and the other is trying to form a trough, then they are
competing to do different things. In this case, they can cancel out. The amplitude of the
resulting wave will depend on the amplitudes of the two waves that are interfering. If the depth
of the trough is the same as the height of the peak nothing will happen. If the height of the
peak is bigger than the depth of the trough, a smaller peak will appear. And if the trough is
deeper then a less deep trough will appear. This is destructive interference.


file_data: 6.5|Summary|127


file_data: 6.6|Exercises|127




file_data: 7|Geometrical Optics - Grade 10|129


file_data: 7.1|Introduction|129
You are indoors on a sunny day. A beam of sunlight through a window lights up a section of
the floor. How would you draw this sunbeam? You might draw a series of parallel lines showing
the path of the sunlight from the window to the floor. This is not exactly accurate – no matter
how hard you look, you will not find unique lines of light in the sunbeam! However, this is a
good way to draw light. It is also a good way to model light geometrically, as we will see in this
chapter.
We will call these narrow, imaginary lines of light light rays. Since light is an electromagnetic
wave, you could think of a light ray as the path of a point on the crest of a wave. Or, you could
think of a light ray as the path taken by a miniscule particle that carries light. We will always
draw them the same way: as straight lines between objects, images, and optical devices.
We can use light rays to model mirrors, lenses, telescopes, microscopes, and prisms. The study
of how light interacts with materials is optics. When dealing with light rays, we are usually
interested in the shape of a material and the angles at which light rays hit it. From these angles,
we can work out, for example, the distance between an object and its reflection. We therefore
refer to this kind of optics as geometrical optics.

file_data: 7.2|Light Rays|129
In physics we use the idea of a light ray to indicate the direction that light travels. Light rays
are lines with arrows and are used to show the path that light travels. In Figure 7.1, the light
rays from the object enters the eye and the eye sees the object.
The most important thing to remember is that we can only see an object when light from the
object enters our eyes. The object must be a source of light (for example a light bulb) or else it
must reflect light from a source (for example the moon), and the reflected light enters our eyes.
Important: We cannot see an object unless light from that object enters our eyes.
Definition: Light ray
Light rays are straight lines with arrows to show the path of light.
Important: Light rays are not real. They are merely used to show the path that light
travels.


file_data: 7.2.1|Shadows|132
Objects cast shadows when light shines on them. This is more evidence that light travels in
straight lines. The picture below shows how shadows are formed.

file_data: 7.2.2|Ray Diagrams|132
A ray diagram is a drawing that shows the path of light rays. Light rays are drawn using straight
lines and arrow heads. The figure below shows some examples of ray diagrams.

file_data: 7.3|Reflection|132
When you smile into a mirror, you see your own face smiling back at you. This is caused by the
reflection of light rays on the mirror. Reflection occurs when a light ray bounces off a surface.

file_data: 7.3.1|Terminology|133
In Chapters 5 and 6 we saw that when a pulse or wave strikes a surface it is reflected. This means
that waves bounce off things. Sound waves bounce off walls, light waves bounce off mirrors,
radar waves bounce off aeroplanes and it can explain how bats can fly at night and avoid things
as thin as telephone wires. The phenomenon of reflection is a very important and useful one.
We will use the following terminology. The incoming light ray is called the incident ray. The
light ray moving away from the surface is the reflected ray. The most important characteristic
of these rays is their angles in relation to the reflecting surface. These angles are measured
with respect to the normal of the surface. The normal is an imaginary line perpendicular to
the surface. The angle of incidence, θi is measured between the incident ray and the surface
normal. The angle of reflection, θr is measured between the reflected ray and the surface
normal. This is shown in Figure 7.4.
When a ray of light is reflected, the reflected ray lies in the same plane as the incident ray and
the normal. This plane is called the plane of incidence and is shown in Figure 7.5.

file_data: 7.3.2|Law of Reflection|133
The Law of Reflection states that the angles of incidence and reflection are always equal and
that the reflected ray always lies in the plane of incidence.
Definition: Law of Reflection
The Law of Reflection states that the angle of incidence is equal to the angle of reflection.
θi = θr
The simplest example of the law of incidence is if the angle of incidence is 0◦. In this case, the
angle of reflection is also 0◦. You see this when you look straight into a mirror.
Figure 7.6: When a wave strikes a surface at right angles to the surface, then the wave is reflected
directly back.
If the angle of incidence is not 0◦, then the angle of reflection is also not 0◦. For example, if a
light strikes a surface at 60◦ to the surface normal, then the angle that the reflected ray makes
with the surface normal is also 60◦ as shown in Figure 7.7.
Figure 7.7: Ray diagram showing angle of incidence and angle of reflection. The Law of Reflection
states that when a light ray reflects off a surface, the angle of reflection θr is the same as the
angle of incidence θi.

file_data: 7.3.3|Types of Reflection|135
The Law of Reflection is true for any surface. Does this mean that when parallel rays approach
a surface, the reflected rays will also be parallel? This depends on the texture of the reflecting
surface.
Specular Reflection
Figure 7.8(a) shows a surface that is flat and even. Parallel incident light rays hit the smooth
surface and parallel reflected light rays leave the surface. This type of reflection is called specular
reflection. Specular reflection occurs when rays are reflected from a smooth, shiny surface. The
normal to the surface is the same at every point on the surface. Parallel incident rays become
parallel reflected rays. When you look in a mirror, the image you see is formed by specular
reflection.
Diffuse Reflection
Figure 7.8(b) shows a surface with bumps and curves. When multiple rays hit this uneven
surface, diffuse reflection occurs. The incident rays are parallel but the reflected rays are not.
Each point on the surface has a different normal. This means the angle of incidence is different
at each point. Then according to the Law of Reflection, each angle of reflection is different.
Diffuse reflection occurs when light rays are reflected from bumpy surfaces. You can still see a
reflection as long as the surface is not too bumpy. Diffuse reflection enables us to see all objects
that are not sources of light.

file_data: 7.4|Refraction|137
In the previous sections we studied light reflecting off various surfaces. What happens when light
passes through a medium? Like all waves, the speed of light is dependent on the medium in
which it is travelling. When light moves from one medium into another (for example, from air
to glass), the speed of light changes. The effect is that the light ray passing into a new medium
is refracted, or bent. Refraction is therefore the bending of light as it moves from one optical
medium to another.
Definition: Refraction
Refraction is the bending of light that occurs because light travels at different speeds in
different materials.
When light travels from one medium to another, it will be bent away from its original path.
When it travels from an optically dense medium like water or glass to a less dense medium like
air, it will be refracted away from the normal (Figure 7.9). Whereas, if it travels from a less
dense medium to a denser one, it will be refracted towards the normal (Figure 7.10).
Just as we defined an angle of reflection in the previous section, we can similarly define an angle
of refraction as the angle between the surface normal and the refracted ray. This is shown in
Figure 7.11.
Figure 7.9: Light is moving from an optically dense medium to an optically less dense medium.
Light is refracted away from the normal.
Figure 7.10: Light is moving from an optically less dense medium to an optically denser medium.
Light is refracted towards the normal.
Figure 7.11: Light moving from one medium to another bends towards or away from the surface
normal. The angle of refraction θ is shown.

file_data: 7.4.1|Refractive Index|139
Which is easier to travel through, air or water? People usually travel faster through air. So
does light! The speed of light and therefore the degree of bending of the light depends on the
refractive index of material through which the light passes. The refractive index (symbol n) is
the ratio of the speed of light in a vacuum to its speed in the material. You can think of the
refractive index as a measure of how difficult it is for light to get through a material.
Definition: Refractive Index
The refractive index of a material is the ratio of the speed of light in a vacuum to its speed
in the medium.
The symbol c is used to represent the speed of light in a vacuum.
c = 299 792 485m· s−1
For purposes of calculation, we use 3 × 108m · s−1. A vacuum is a region with
no matter in it, not even air. However, the speed of light in air is very close to
that in a vacuum.
Definition: Refractive Index
The refractive index (symbol n) of a material is the ratio of the speed of light in a vacuum
to its speed in the material and gives an indication of how difficult it is for light to get
through the material.
n =
c
v
where
n = refractive index (no unit)
c = speed of light in a vacuum (3,00 × 108m · s−1)
v = speed of light in a given medium (m · s−1)
Extension: Refractive Index and Speed of Light
Using
n =
c
v
we can also examine how the speed of light changes in different media, because the
speed of light in a vacuum (c) is constant.
If the refractive index n increases, the speed of light in the material v must
decrease. Light therefore travels slowly through materials of high n.
Table 7.4.1 shows refractive indices for various materials. Light travels slower in any material
than it does in a vacuum, so all values for n are greater than 1.

file_data: 7.4.2|Snell's Law|139
Now that we know that the degree of bending, or the angle of refraction, is dependent on the
refractive index of a medium, how do we calculate the angle of refraction?
The angles of incidence and refraction when light travels from one medium to another can be
calculated using Snell’s Law.
Table 7.1: Refractive indices of some materials. nair is calculated at STP and all values are
determined for yellow sodium light which has a wavelength of 589,3 nm.
Definition: Snell’s Law
n1 sin θ1 = n2 sin θ2
where
n1 = Refractive index of material 1
n2 = Refractive index of material 2
θ1 = Angle of incidence
θ2 = Angle of refraction
Remember that angles of incidence and refraction are measured from the normal, which is an
imaginary line perpendicular to the surface.
Suppose we have two media with refractive indices n1 and n2. A light ray is incident on the
surface between these materials with an angle of incidence θ1. The refracted ray that passes
through the second medium will have an angle of refraction θ2.
If
n2 > n1
then from Snell’s Law,
sin θ1 > sin θ2.
For angles smaller than 90◦, sin θ increases as θ increases. Therefore,
θ1 > θ2.
This means that the angle of incidence is greater than the angle of refraction and the light ray
is bent toward the normal.
Similarly, if
n2 < n1
then from Snell’s Law,
sin θ1 < sin θ2.
For angles smaller than 90◦, sin θ increases as θ increases. Therefore,
θ1 < θ2.
This means that the angle of incidence is less than the angle of refraction and the light ray is
away toward the normal.
Both these situations can be seen in Figure 7.12.
Figure 7.12: Refraction of two light rays. (a) A ray travels from a medium of low refractive
index to one of high refractive index. The ray is bent towards the normal. (b) A ray travels from
a medium with a high refractive index to one with a low refractive index. The ray is bent away
from the normal.
What happens to a ray that lies along the normal line? In this case, the angle of incidence is 0◦
and
sin θ2 =
n1
n2
sin θ1
= 0
∴ θ2 = 0.
This shows that if the light ray is incident at 0◦, then the angle of refraction is also 0◦. The ray
passes through the surface unchanged, i.e. no refraction occurs.




file_data: 7.4.3|Apparent Depth|143
Imagine a coin on the bottom of a shallow pool of water. If you reach for the coin, you will miss
it because the light rays from the coin are refracted at the water’s surface.
Consider a light ray that travels from an underwater object to your eye. The ray is refracted at
the water surface and then reaches your eye. Your eye does not know Snell’s Law; it assumes
light rays travel in straight lines. Your eye therefore sees the image of the at coin shallower
location. This shallower location is known as the apparent depth.
The refractive index of a medium can also be expressed as


file_data: 7.5|Mirrors|146
A mirror is a highly reflective surface. The most common mirrors are flat and are known as
plane mirrors. Household mirrors are plane mirrors. They are made of a flat piece of glass with
a thin layer of silver nitrate or aluminium on the back. However, other mirrors are curved and
are either convex mirrors or are concave mirrors. The reflecting properties of all three types
of mirrors will be discussed in this section.

file_data: 7.5.1|Image Formation|146
Definition: Image
An image is a representation of an object formed by a mirror or lens. Light from the image
is seen.
If you place a candle in front of a mirror, you now see two candles. The actual, physical candle
is called the object and the picture you see in the mirror is called the image. The object is the
source of the incident rays. The image is the picture that is formed by the reflected rays.
The object could be an actual source that emits light, such as a light bulb or a candle. More
commonly, the object reflects light from another source. When you look at your face in the
mirror, your face does not emit light. Instead, light from a light bulb or from the sun reflects off
your face and then hits the mirror. However, in working with light rays, it is easiest to pretend
the light is coming from the object.
An image formed by reflection may be real or virtual. A real image occurs when light rays
actually intersect at the image. A real image is inverted, or upside down. A virtual image occurs
when light rays do not actually meet at the image. Instead, you ”see” the image because your
eye projects light rays backward. You are fooled into seeing an image! A virtual image is erect,
or right side up (upright).
You can tell the two types apart by putting a screen at the location of the image. A real image
can be formed on the screen because the light rays actually meet there. A virtual image cannot
be seen on a screen, since it is not really there.
To describe objects and images, we need to know their locations and their sizes. The distance
from the mirror to the object is the object distance, do.
The distance from the mirror to the image is the image distance, di.

file_data: 7.5.2|Plane Mirrors|147
When you look into a mirror, you see an image of yourself.
The image created in the mirror has the following properties:
1. The image is virtual.
2. The image is the same distance behind the mirror as the object is in front of the mirror.
3. The image is laterally inverted. This means that the image is inverted from side to side.
4. The image is the same size as the object.
5. The image is upright.
Virtual images are images formed in places where light does not really reach. Light does not
really pass through the mirror to create the image; it only appears to an observer as though the
light were coming from behind the mirror. Whenever a mirror creates an image which is virtual,
the image will always be located behind the mirror where light does not really pass.
Definition: Virtual Image
A virtual image is upright, on the opposite side of the mirror as the object, and light does
not actually reach it.

file_data: 7.5.3|Ray Diagrams|148
We draw ray diagrams to predict the image that is formed by a plane mirror. A ray diagram is
a geometrical picture that is used for analyzing the images formed by mirrors and lenses. We
draw a few characteristic rays from the object to the mirror. We then follow ray-tracing rules to
find the path of the rays and locate the image.
Important: A mirror obeys the Law of Reflection.
The ray diagram for the image formed by a plane mirror is the simplest possible ray diagram.
Figure 7.15 shows an object placed in front of a plane mirror. It is convenient to have a central
line that runs perpendicular to the mirror. This imaginary line is called the principal axis.
Important: Ray diagrams
The following should be remembered when drawing ray diagrams:
1. Objects are represented by arrows. The length of the arrow represents the height of
the object.
2. If the arrow points upwards, then the object is described as upright or erect. If the
arrow points downwards then the object is described as inverted.
3. If the object is real, then the arrow is drawn with a solid line. If the object is virtual,
then the arrow is drawn with a dashed line.
Method: Ray Diagrams for Plane Mirrors
Ray diagrams are used to find the position and size and whether the image is real or virtual.
1. Draw the plane mirror as a straight line on a principal axis.
2. Draw the object as an arrow in front of the mirror.
3. Draw the image of the object, by using the principle that the image is placed at the same
distance behind the mirror that the object is in front of the mirror. The image size is also
the same as the object size.
4. Place a dot at the point the eye is located.
5. Pick one point on the image and draw the reflected ray that travels to the eye as it sees
this point. Remember to add an arrowhead.
6. Draw the incident ray for light traveling from the corresponding point on the object to the
mirror, such that the law of reflection is obeyed.
7. Continue for other extreme points on the object.
Suppose a light ray leaves the top of the object traveling parallel to the principal axis. The ray
will hit the mirror at an angle of incidence of 0 degrees. We say that the ray hits the mirror
normally. According to the law of reflection, the ray will be reflected at 0 degrees. The ray then
bounces back in the same direction. We also project the ray back behind the mirror because this
is what your eye does.
Another light ray leaves the top of the object and hits the mirror at its centre. This ray will be
reflected at the same angle as its angle of incidence, as shown. If we project the ray backward
behind the mirror, it will eventually cross the projection of the first ray we drew. We have found
the location of the image! It is a virtual image since it appears in an area that light cannot
actually reach (behind the mirror). You can see from the diagram that the image is erect and is
the same size as the object. This is exactly as we expected.
We use a dashed line to indicate that the image is virtual.


file_data: 7.5.4|Spherical Mirrors|150
The second class of mirrors that we will look at are spherical mirrors. These mirrors are called
spherical mirrors because if you take a sphere and cut it as shown in Figure 7.16 and then polish
the inside of one and the outside of the other, you will get a concave mirror and convex mirror
as shown. These two mirrors will be studied in detail.
The centre of curvature is the point at the centre of the sphere and describes how big the sphere
is.


file_data: 7.5.5|Concave Mirrors|150
The first type of curved mirror we will study are concave mirrors. Concave mirrors have the shape
shown in Figure 7.17. As with a plane mirror, the principal axis is a line that is perpendicular to
the centre of the mirror.
If you think of light reflecting off a concave mirror, you will immediately see that things will look
very different compared to a plane mirror. The easiest way to understand what will happen is
to draw a ray diagram and work out where the images will form. Once we have done that it is
easy to see what properties the image has.
First we need to define a very important characteristic of the mirror. We have seen that the
centre of curvature is the centre of the sphere from which the mirror is cut. We then define that a distance that is half-way between the centre of curvature and the mirror on the principal axis.
This point is known as the focal point and the distance from the focal point to the mirror is
known as the focal length (symbol f). Since the focal point is the midpoint of the line segment
joining the vertex and the center of curvature, the focal length would be one-half the radius of
curvature. This fact can come in very handy, remember if you know one then you know the
other!
Definition: Focal Point
The focal point of a mirror is the midpoint of a line segment joining the vertex and the
centre of curvature. It is the position at which all parallel rays are focussed.
Why are we making such a big deal about this point we call the focal point? It has an important
property we will use often. A ray parallel to the principal axis hitting the mirror will always be
reflected through the focal point. The focal point is the position at which all parallel rays are
focussed.
Figure 7.19: A concave mirror with three rays drawn to locate the image. Each incident ray
is reflected according to the Law of Reflection. The intersection of the reflected rays gives the
location of the image. Here the image is real and inverted.
From Figure 7.19, we see that the image created by a concave mirror is real and inverted, as
compared to the virtual and erect image created by a plane mirror.
Definition: Real Image
A real image can be cast on a screen; it is inverted, and on the same side of the mirror as
the object.

file_data: 7.5.6|Convex Mirrors|153
The second type of curved mirror we will study are convex mirrors. Convex mirrors have the shape
shown in Figure 7.20. As with a plane mirror, the principal axis is a line that is perpendicular to
the centre of the mirror.
We have defined the focal point as that point that is half-way along the principal axis between
the centre of curvature and the mirror. Now for a convex mirror, this point is behind the mirror.
A convex mirror has a negative focal length because the focal point is behind the mirror.
Figure 7.20: Convex mirror with principle axis, focal point (F) and centre of curvature (C). The
centre of the mirror is the optical centre (O).
To determine what the image from a convex mirror looks like and where the image is located,
we need to remember that a mirror obeys the laws of reflection and that light appears to come
from the image. The image created by a convex mirror is shown in Figure 7.21.
Figure 7.21: A convex mirror with three rays drawn to locate the image. Each incident ray is
reflected according to the Law of Reflection. The reflected rays diverge. If the reflected rays are
extended behind the mirror, then their intersection gives the location of the image behind the
mirror. For a convex mirror, the image is virtual and upright.
From Figure 7.21, we see that the image created by a convex mirror is virtual and upright, as
compared to the real and inverted image created by a concave mirror.
Extension: Divergence
A convex mirror is also known as a diverging mirror. Light rays appear to diverge
from the focal point of a convex mirror.


file_data: 7.5.7|Summary of Properties of Mirrors|154


file_data: 7.5.8|Magnification|154
In Figures 7.19 and 7.21, the height of the object and image arrows were different. In any optical
system where images are formed from objects, the ratio of the image height, hi, to the object
height, ho is known as the magnification, m.
m =
hi
ho
This is true for the mirror examples we showed above and will also be true for lenses, which will
be introduced in the next sections. For a plane mirror, the height of the image is the same as the
height of the object, so the magnification is simply m = hi
ho
= 1. If the magnification is greater
than 1, the image is larger than the object and is said to be magnified. If the magnification is
less than 1, the image is smaller than the object so the image is said to be diminished.


file_data: 7.6|Total Internal Reflection and Fibre Optics|156


file_data: 7.6.1|Total Internal Reflection|156
When we increase the angle of incidence, we reach a point where the angle of refraction is 90◦
and the refracted ray runs along the surface of the medium. This angle of incidence is called the
critical angle.
Definition: Critical Angle
The critical angle is the angle of incidence where the angle of reflection is 90◦. The light
must shine from a dense to a less dense medium.
If the angle of incidence is bigger than this critical angle, the refracted ray will not emerge from
the medium, but will be reflected back into the medium. This is called total internal reflection.
Total internal reflection takes place when
• light shines from an optically denser medium to an optically less dense medium.
• the angle of incidence is greater than the critical angle.
Definition: Total Internal Reflection
Total internal reflection takes place when light is reflected back into the medium because
the angle of incidence is greater than the critical angle.
Each medium has its own unique critical angle. For example, the critical angle for glass is 42◦,
and that of water is 48,8◦. We can calculate the critical angle for any medium.
Calculating the Critical Angle
Now we shall learn how to derive the value of the critical angle for two given media. The process
is fairly simple and involves just the use of Snell’s Law that we have already studied. To recap,
Snell’s Law states:
n1 sin θ1 = n2 sin θ2
where n1 is the refractive index of material 1, n2 is the refractive index of material 2, θ1 is the
angle of incidence and θ2 is the angle of refraction. For total internal reflection we know that
the angle of incidence is the critical angle. So,
θ1 = θc.
However, we also know that the angle of refraction at the critical angle is 90◦. So we have:
θ2 = 90◦.
We can then write Snell’s Law as:
n1 sin θc = n2 sin 90◦
Solving for θc gives:
n1 sin θc = n2 sin 90◦
sin θc =
n2
n1
(1)
∴ θc = sin−1 (
n2
n1
)
Important: Take care that for total internal reflection the incident ray is always in the
denser medium.



file_data: 7.6.2|Fibre Optics|161
Total internal reflection is a powerful tool since it can be used to confine light. One of the
most common applications of total internal reflection is in fibre optics. An optical fibre is a thin,
transparent fibre, usually made of glass or plastic, for transmitting light. Optical fibres are usually
thinner than a human hair! The construction of a single optical fibre is shown in Figure 7.23.
The basic functional structure of an optical fibre consists of an outer protective cladding and an
inner core through which light pulses travel. The overall diameter of the fibre is about 125 μm
(125×10−6m) and that of the core is just about 10 μm (10×10−6m). The mode of operation
of the optical fibres, as mentioned above, depends on the phenomenon of total internal reflection.
The difference in refractive index of the cladding and the core allows total internal reflection in
the same way as happens at an air-water surface. If light is incident on a cable end with an
angle of incidence greater than the critical angle then the light will remain trapped inside the
glass strand. In this way, light travels very quickly down the length of the cable.
Fibre Optics in Telecommunications
Optical fibres are most common in telecommunications, because information can be transported
over long distances, with minimal loss of data. The minimised loss of data gives optical fibres
an advantage over conventional cables.
Data is transmitted from one end of the fibre to another in the form of laser pulses. A single strand
is capable of handling over 3000 simultaneous transmissions which is a huge improvement over
the conventional co-axial cables. Multiple signal transmission is achieved by sending individual
light pulses at slightly different angles. For example if one of the pulses makes a 72,23◦ angle
of incidence then a separate pulse can be sent at an angle of 72,26◦! The transmitted data is
received almost instantaneously at the other end of the cable since the information coded onto
the laser travels at the speed of light! During transmission over long distances repeater stations
are used to amplify the signal which has weakened somewhat by the time it reaches the station.
The amplified signals are then relayed towards their destination and may encounter several other
repeater stations on the way.
Fibre Optics in Medicine
Optic fibres are used in medicine in endoscopes.
The main part of an endoscope is the optical fibre. Light is shone down the optical fibre and a
medical doctor can use the endoscope to look inside a patient. Endoscopes are used to examine
the inside of a patient’s stomach, by inserting the endoscope down the patient’s throat.
Endoscopes allow minimally invasive surgery. This means that a person can be diagnosed and
treated through a small incision. This has advantages over open surgery because endoscopy is
quicker and cheaper and the patient recovers more quickly. The alternative is open surgery which
is expensive, requires more time and is more traumatic for the patient.
Endoscopy means to look inside and refers to looking inside the human body for
diagnosing medical conditions.



file_data: 7.7|Summary|163


file_data: 7.8|Exercises|164






file_data: 8|Magnetism - Grade 10|167

file_data: 8.1|Introduction|167
Magnetism is the force that a magnetic object exerts, through its magnetic field, on another
object. The two objects do not have to physically touch each other for the force to be exerted.
Object 2 feels the magnetic force from Object 1 because of Object 1’s surrounding magnetic
field.
Humans have known about magnetism for many thousands of years. For example, lodestone is
a magnetised form of the iron oxide mineral magnetite. It has the property of attracting iron
objects. It is referred to in old European and Asian historical records; from around 800 BCE in
Europe and around 2 600 BCE in Asia.
The root of the English word magnet is from the Greek word magnes, probably
from Magnesia in Asia Minor, once an important source of lodestone.

file_data: 8.2|Magnetic fields|167
A magnetic field is a region in space where a magnet or object made of ferromagnetic material
will experience a non-contact force.
Electrons moving inside any object have magnetic fields associated with them. In most materials
these fields point in all directions, so the net magnetic field is zero. For example, in the plastic ball
below, the directions of the magnetic fields of the electrons (shown by the arrows) are pointing
in different directions and cancel each other out. Therefore the plastic ball is not magnetic and
has no magnetic field.
In some materials (e.g. iron), called ferromagnetic materials, there are regions called domains,
where these magnetic fields line up. All the atoms in each domain group together so that the
magnetic fields from their electrons point the same way. The picture shows a piece of an iron
needle zoomed in to show the domains with the electric fields lined up inside them.
In permanent magnets, many domains are lined up, resulting in a net magnetic field. Objects
made from ferromagnetic materials can be magnetised, for example by rubbing a magnet along
the object in one direction. This causes the magnetic fields of most, or all, of the domains to line
up and cause the object to have a magnetic field and be magnetic. Once a ferromagnetic object
has been magnetised, it can stay magnetic without another magnet being nearby (i.e. without
being in another magnetic field). In the picture below, the needle has been magnetised because
the magnetic fields in all the domains are pointing in the same direction.

file_data: 8.3|Permanent magnets|169


file_data: 8.3.1|The poles of permanent magnets|169
Because the domains in a permanent magnet all line up in a particular direction, the magnet
has a pair of opposite poles, called north (usually shortened to N) and south (usually shortened
to S). Even if the magnet is cut into tiny pieces, each piece will still have both a N and a S
pole. These poles always occur in pairs. In nature we never find a north magnetic pole or south
magnetic pole on its own.
Magnetic fields are different to gravitational and electric fields. In nature, positive and negative
electric charges can be found on their own, but you never find just a north magnetic pole or
south magnetic pole on its own. On the very small scale, zooming in to the size of atoms,
magnetic fields are caused by moving charges (i.e. the negatively charged electrons).

file_data: 8.3.2|Magnetic attraction and repulsion|169
Like poles of magnets repel one another whilst unlike poles attract. This means that two N poles
or two S poles will push away from each other while a N pole and a S pole will be drawn towards
each other.
Definition: Attraction and Repulsion
Like poles of magnets repel each other whilst unlike poles attract each other.

file_data: 8.3.3|Representing magnetic fields|170
Magnetic fields can be represented using magnetic field lines. Although the magnetic field of
a permanent magnet is everywhere surrounding the magnet (in all 3 dimensions), we draw only
some of the field lines to represent the field (usually only 2 dimensions are shown in drawings).
In areas where the magnetic field is strong, the field lines are closer together. Where the field is
weaker, the field lines are drawn further apart. The strength of a magnetic field is referred to as
the magnetic flux
Important:
1. Field lines never cross.
2. Arrows drawn on the field lines indicate the direction of the field.
3. A magnetic field points from the north to the south pole of a magnet.
As the activity shows, one can map the magnetic field of a magnet by placing it underneath a
piece of paper and sprinkling iron filings on top. The iron filings line themselves up parallel to
the magnetic field.
Another tool one can use to find the direction of a magnetic field is a compass. The compass
arrow points in the direction of the field.
As already said, opposite poles of a magnet attract each other and bringing them together causes
their magnetic field lines to converge (come together). Like poles of a magnet repel each other
and bringing them together causes their magnetic field lines to diverge (bend out from each
other).
Extension: Ferromagnetism and Retentivity
Ferromagnetism is a phenomenon shown by materials like iron, nickel or cobalt.
These materials can form permanent magnets. They always magnetise so as to
be attracted to a magnet, no matter which magnetic pole is brought toward the
unmagnetised iron/nickel/cobalt.
The ability of a ferromagnetic material to retain its magnetisation after an external
field is removed is called its retentivity.
Paramagnetic materials are materials like aluminium or platinum, which become
magnetised in an external magnetic field in a similar way to ferromagnetic materials.
However, they lose their magnetism when the external magnetic field is removed.
Diamagnetism is shown by materials like copper or bismuth, which become mag-
netised in a magnetic field with a polarity opposite to the external magnetic field.
Unlike iron, they are slightly repelled by a magnet.

file_data: 8.4|The compass and the earth's magnetic field|173
A compass is an instrument which is used to find the direction of a magnetic field. It can do
this because a compass consists of a small metal needle which is magnetised itself and which is
free to turn in any direction. Therefore, when in the presence of a magnetic field, the needle is
able to line up in the same direction as the field.
Lodestone, a magnetised form of iron-oxide, was found to orientate itself in a
north-south direction if left free to rotate by suspension on a string or on a float
in water. Lodestone was therefore used as an early navigational compass.
Compasses are mainly used in navigation to find direction on the earth. This works because the
earth itself has a magnetic field which is similar to that of a bar magnet (see the picture below).
The compass needle aligns with the magnetic field direction and points north (or south). Once
you know where north is, you can figure out any other direction. A picture of a compass is shown
below:
Some animals can detect magnetic fields, which helps them orientate themselves and find di-
rection. Animals which can do this include pigeons, bees, Monarch butterflies, sea turtles and
fish.


file_data: 8.4.1|The earth's magnetic field|175
In the picture below, you can see a representation of the earth’s magnetic field which is very
similar to the magnetic field of a giant bar magnet like the one on the right of the picture. So
the earth has two sets of north poles and south poles: geographic poles and magnetic poles.
The earth’s magnetic field is thought to be caused by churning liquid metals in the core which
causes electric currents and a magnetic field. From the picture you can see that the direction
of magnetic north and true north are not identical. The geographic north pole, which is the
point through which the earth’s rotation axis goes, is about 11,5o away from the direction of
the magnetic north pole (which is where a compass will point). However, the magnetic poles
shift slightly all the time.
Another interesting thing to note is that if we think of the earth as a big bar magnet, and we
know that magnetic field lines always point from north to south, then the compass tells us that
what we call the magnetic north pole is actually the south pole of the bar magnet!
The direction of the earth’s magnetic field flips direction about once every
200 000 years! You can picture this as a bar magnet whose north and south pole
periodically switch sides. The reason for this is still not fully understood.
The earth’s magnetic field is very important for humans and other animals on earth because it
stops charged particles emitted by the sun from hitting the earth and us. Charged particles can
also damage and cause interference with telecommunications (such as cell phones). Charged
particles (mainly protons and electrons) are emitted by the sun in what is called the solar wind,
and travel towards the earth. These particles spiral in the earth’s magnetic field towards the
poles. If they collide with other particles in the earth’s atmosphere they sometimes cause red or
green lights or a glow in the sky which is called the aurora. This happens close to the north and
south pole and so we cannot see the aurora from South Africa.

file_data: 8.5|Summary|175


file_data: 8.6|End of chapter exercises|176






file_data: 9|Electrostatics - Grade 10|177


file_data: 9.1|Introduction|177
Electrostatics is the study of electric charge which is static (not moving).


file_data: 9.2|Two kinds of charge|177
All objects surrounding us (including people!) contain large amounts of electric charge. There
are two types of electric charge: positive charge and negative charge. If the same amounts
of negative and positive charge are brought together, they neutralise each other and there is
no net charge. Neutral objects are objects which contain positive and negative charges, but in
equal numbers. However, if there is a little bit more of one type of charge than the other on the
object then the object is said to be electrically charged. The picture below shows what the
distribution of charges might look like for a neutral, positively charged and negatively charged
object.
There are:
6 positive charges and
6 negative charges
6 + (-6) = 0
There is zero net charge:
The object is neutral
8 positive charges and
6 negative charges
8 + (-6) = 2
The net charge is +2
The object is positively charged
6 positive charges and
9 negative charges
6 + (-9) = -3
The net charge is -3
The object is negatively charged


file_data: 9.3|Unit of charge|177
Charge is measured in units called coulombs (C). A coulomb of charge is a very large charge.
In electrostatics we therefore often work with charge in microcoulombs (1 μC = 1 × 10−6 C)
and nanocoulombs (1 nC = 1 × 10−9 C).

file_data: 9.4|Conservation of charge|177
Objects can become charged by contact or by rubbing them. This means that they can gain
extra negative or positive charge. Charging happens when you, for example, rub your feet against
the carpet. When you then touch something metallic or another person, you will feel a shock as the excess charge that you have collected is discharged.
Important: Charge, just like energy, cannot be created or destroyed. We say that charge
is conserved.
When you rub your feet against the carpet, negative charge is transferred to you from the carpet.
The carpet will then become positively charged by the same amount.
Another example is to take two neutral objects such as a plastic ruler and a cotton cloth
(handkerchief). To begin, the two objects are neutral (i.e. have the same amounts of positive
and negative charge.)
- + - +- +- +- +- + -+- +- +
+
+
+
+
+
-
-
-
-
-
The ruler has 9 postive charges and
The neutral cotton cloth has
5 positive charges and
5 negative charges
The total number of charges is:
(9+5)=14 positive charges
(9+5)=14 negative charges
9 negative charges
BEFORE rubbing:
Now, if the cotton cloth is used to rub the ruler, negative charge is transferred from the cloth to
the ruler. The ruler is now negatively charged and the cloth is positively charged. If you count
up all the positive and negative charges at the beginning and the end, there are still the same
amount. i.e. total charge has been conserved!
- + - +- +- +- +- + -+- +- +
+
+
+
+
+
-
-
-
-
-
The ruler has 9 postive charges and
The cotton cloth has
5 positive charges and
2 negative charges.
The total number of charges is:
(9+5)=14 positive charges
(12+2)=14 negative charges
12 negative charges
AFTER rubbing:
It is now positively charged.


file_data: 9.5|Force between Charges|178
The force exerted by non-moving (static) charges on each other is called the electrostatic force.
The electrostatic force between:
• like charges is repulsive
• opposite (unlike) charges is attractive.
In other words, like charges repel each other while opposite charges attract each other. This is
different to the gravitational force which is only attractive.
F F
- +
attractive force
F F
- -
repulsive force
F F
+ +
repulsive force
The closer together the charges are, the stronger the electrostatic force between them.
weaker repulsive force
F F
+ + stronger repulsive force
F F
+ +
(shorter distance between charges)
(longer distance between charges)
Extension: Electrostatic Force
The electrostatic force determines the arrangement of charge on the surface of con-
ductors. When we place a charge on a spherical conductor the repulsive forces
between the individual like charges cause them to spread uniformly over the sur-
face of the sphere. However, for conductors with non-regular shapes, there is a
concentration of charge near the point or points of the object.

This collection of charge can actually allow charge to leak off the conductor if the
point is sharp enough. It is for this reason that buildings often have a lightning rod
on the roof to remove any charge the building has collected. This minimises the
possibility of the building being struck by lightning. This “spreading out” of charge
would not occur if we were to place the charge on an insulator since charge cannot
move in insulators.

The word ‘electron’ comes from the Greek word for amber. The ancient Greeks
observed that if you rubbed a piece of amber, you could use it to pick up bits of
straw.


file_data: 9.6|Conductors and insulators|181
All atoms are electrically neutral i.e. they have the same amounts of negative and positive charge
inside them. By convention, the electrons carry negative charge and the protons carry positive
charge. The basic unit of charge, called the elementary charge, e, is the amount of charge carried
by one electron.
All the matter and materials on earth are made up of atoms. Some materials allow electrons to
move relatively freely through them (e.g. most metals, the human body). These materials are
called conductors.
Other materials do not allow the charge carriers, the electrons, to move through them (e.g.
plastic, glass). The electrons are bound to the atoms in the material. These materials are called
non-conductors or insulators.
If an excess of charge is placed on an insulator, it will stay where it is put and there will be a
concentration of charge in that area of the object. However, if an excess of charge is placed on
a conductor, the like charges will repel each other and spread out over the surface of the object.
When two conductors are made to touch, the total charge on them is shared between the two.
If the two conductors are identical, then each conductor will be left with half of the total charge.
Extension: Charge and electrons
The basic unit of charge, namely the elementary charge is carried by the electron
(equal to 1.602×10−19 C!). In a conducting material (e.g. copper), when the atoms
bond to form the material, some of the outermost, loosely bound electrons become
detached from the individual atoms and so become free to move around. The charge
carried by these electrons can move around in the material. In insulators, there are
very few, if any, free electrons and so the charge cannot move around in the material.



file_data: 9.6.1|The electroscope|182
The electroscope is a very sensitive instrument which can be used to detect electric charge. A
diagram of a gold leaf electroscope is shown the figure below. The electroscope consists of a
glass container with a metal rod inside which has 2 thin pieces of gold foil attached. The other
end of the metal rod has a metal plate attached to it outside the glass container.
The electroscope detects charge in the following way: A charged object, like the positively
charged rod in the picture, is brought close to (but not touching) the neutral metal plate of
the electroscope. This causes negative charge in the gold foil, metal rod, and metal plate, to
be attracted to the positive rod. Because the metal (gold is a metal too!) is a conductor, the
charge can move freely from the foil up the metal rod and onto the metal plate. There is now
more negative charge on the plate and more positive charge on the gold foil leaves. This is
called inducing a charge on the metal plate. It is important to remember that the electroscope
is still neutral (the total positive and negative charges are the same), the charges have just been
induced to move to different parts of the instrument! The induced positive charge on the gold
leaves forces them apart since like charges repel! This is how we can tell that the rod is charged.
If the rod is now moved away from the metal plate, the charge in the electroscope will spread
itself out evenly again and the leaves will fall down again because there will no longer be an
induced charge on them.
Grounding
If you were to bring the charged rod close to the uncharged electroscope, and then you touched
the metal plate with your finger at the same time, this would cause charge to flow up from the
ground (the earth), through your body onto the metal plate. This is called grounding. The
charge flowing onto the plate is opposite to the charge on the rod, since it is attracted to the
rod. Therefore, for our picture, the charge flowing onto the plate would be negative. Now
charge has been added to the electroscope. It is no longer neutral, but has an excess of negative
charge. Now if we move the rod away, the leaves will remain apart because they have an excess
of negative charge and they repel each other.


file_data: 9.7|Attraction between charged and uncharged objects|183


file_data: 9.7.1|Polarisation of Insulators|183
Unlike conductors, the electrons in insulators (non-conductors) are bound to the atoms of the
insulator and cannot move around freely in the material. However, a charged object can still
exert a force on a neutral insulator through the concept of polarisation.
If a positively charged rod is brought close to a neutral insulator such as polystyrene, it can
attract the bound electrons to move round to the side of the atoms which is closest to the rod
and cause the positive nuclei to move slightly to the opposite side of the atoms. This process is
called polarisation. Although it is a very small (microscopic) effect, if there are many atoms and
the polarised object is light (e.g. a small polystyrene ball), it can add up to enough force to be
attracted onto the charged rod. Remember, that the polystyrene is only polarised, not charged.
The polystyrene ball is still neutral since no charge was added or removed from it. The picture
shows a not-to-scale view of the polarised atoms in the polystyrene ball:
Some materials are made up of molecules which are already polarised. These are molecules which
have a more positive and a more negative side but are still neutral overall. Just as a polarised
polystyrene ball can be attracted to a charged rod, these materials are also affected if brought
close to a charged object.
Water is an example of a substance which is made of polarised molecules. If a positively charged
rod is brought close to a stream of water, the molecules can rotate so that the negative sides all
line up towards the rod. The stream of water will then be attracted to the rod since opposite
charges attract.

file_data: 9.8|Summary|184


file_data: 9.9|End of chapter exercise|184





file_data: 10|Electric Circuits - Grade 10|187


file_data: 10.1|Electric Circuits|187
In South Africa, people depend on electricity to provide power for most appliances in the home,
at work and out in the world in general. For example, flourescent lights, electric heating and
cooking (on electric stoves), all depend on electricity to work. To realise just how big an impact
electricity has on our daily lives, just think about what happens when there is a power failure or
load shedding.
Important: Safety Warning: We believe in experimenting and learning about physics at
every opportunity, BUT playing with electricity can be EXTREMELY DANGEROUS! Do
not try to build home made circuits alone. Make sure you have someone with you who knows
if what you are doing is safe. Normal electrical outlets are dangerous. Treat electricity with
respect in your everyday life.

file_data: 10.1.1|Closed circuits|187
In the experiment above, you will have seen that the light bulb only glows when there is a closed
circuit i.e. there are no gaps in the circuit and all the circuit elements are connected in a closed
loop. Therefore, in order for charges to flow, a closed circuit and an energy source (in this case
the battery) are needed. (Note: you do not have to have a lightbulb in the circuit! We used this
as a check that charge was flowing.)
Definition: Electric circuit
An electric circuit is a closed path (with no breaks or gaps) along which electrical charges
(electrons) flow powered by an energy source.

file_data: 10.1.2|Representing electric circuits|188
Components of electrical circuits
Some common elements (components) which can be found in electrical circuits include light
bulbs, batteries, connecting leads, switches, resistors, voltmeters and ammeters. You will learn
more about these items in later sections, but it is important to know what their symbols are and
how to represent them in circuit diagrams. Below is a table with the items and their symbols:
Circuit diagrams
Definition: Representing circuits
A physical circuit is the electric circuit you create with real components.
A circuit diagram is a drawing which uses symbols to represent the different components
in the physical circuit.
We use circuit diagrams to represent circuits because they are much simpler and more general
than drawing the physical circuit because they only show the workings of the electrical compo-
nents. You can see this in the two pictures below. The first picture shows the physical circuit
for an electric torch. You can see the light bulb, the batteries, the switch and the outside plastic
casing of the torch. The picture is actually a cross-section of the torch so that we can see inside
it.
Figure 10.1: Physical components of an electric torch. The dotted line shows the path of the
electrical circuit.
Below is the circuit diagram for the electric torch. Now the light bulb is represented by its
symbol, as are the batteries, the switch and the connecting wires. It is not necessary to show
the plastic casing of the torch since it has nothing to do with the electric workings of the torch.
You can see that the circuit diagram is much simpler than the physical circuit drawing!
Series and parallel circuits
There are two ways to connect electrical components in a circuit: in series or in parallel.
Definition: Series circuit
In a series circuit, the charge has a single path from the battery, returning to the battery.
Definition: Parallel circuit
In a parallel circuit, the charge has multiple paths from the battery, returning to the battery.
The picture below shows a circuit with three resistors connected in series on the left and a circuit
with three resistors connected in parallel on the right:

file_data: 10.2|Potential Difference|192


file_data: 10.2.1|Potential Difference|192
When a circuit is connected and is a complete circuit charge can move through the circuit.
Charge will not move unless there is a reason, a force. Think of it as though charge is at rest
and something has to push it along. This means that work needs to be done to make charge
move. A force acts on the charges, doing work, to make them move. The force is provided by
the battery in the circuit.
We call the moving charge ”current” and we will talk about this later.
The position of the charge in the circuit tells you how much potential energy it has because of
the force being exerted on it. This is like the force from gravity, the higher an object is above
the ground (position) the more potential energy it has.
The amount of work to move a charge from one point to another point is how much the potential
energy has changed. This is the difference in potential energy, called potential difference. Notice
that it is a difference between the value of potential energy at two points so we say that potential
difference is measured between or across two points. We do not say potential difference through
something.
Definition: Potential Difference
Electrical potential difference as the difference in electrical potential energy per unit charge
between two points. The units of potential difference are the volt (V).
The units are volt (V), which is the same as joule per coulomb, the amount of work done per
unit charge. Electrical potential difference is also called voltage.


file_data: 10.2.2|Potential Difference and Parallel Resistors|193
When resistors are connected in parallel the start and end points for all the resistors are the same.
These points have the same potential energy and so the potential difference between them is the
same no matter what is put in between them. You can have one, two or many resistors between
the two points, the potential difference will not change. You can ignore whatever components
are between two points in a circuit when calculating the difference between the two points.
Look at the following circuit diagrams. The battery is the same in all cases, all that changes is
more resistors are added between the points marked by the black dots. If we were to measure
the potential difference between the two dots in these circuits we would get the same answer for
all three cases.
Lets look at two resistors in parallel more closely. When you construct a circuit you use wires and
you might think that measuring the voltage in different places on the wires will make a difference.
This is not true. The potential difference or voltage measurement will only be different if you
measure a different set of components. All points on the wires that have no circuit components
between them will give you the same measurements.
All three of the measurements shown in the picture below will give you the same voltages. The
different measurement points on the left have no components between them so there is no change
in potential energy. Exactly the same applies to the different points on the right. When you
measure the potential difference between the points on the left and right you will get the same
answer.



file_data: 10.2.3|Potential Difference and Series Resistors|194
When resistors are in series, one after the other, there is a potential difference across each
resistor. The total potential difference across a set of resistors in series is the sum of the
potential differences across each of the resistors in the set. This is the same as falling a large
distance under gravity or falling that same distance (difference) in many smaller steps. The total
distance (difference) is the same.
Look at the circuits below. If we measured the potential difference between the black dots in
all of these circuits it would be the same just like we saw above. So we now know the total
potential difference is the same across one, two or three resistors. We also know that some work
is required to make charge flow through each one, each is a step down in potential energy. These
steps add up to the total drop which we know is the difference between the two dots.
b
Let us look at this in a bit more detail. In the picture below you can see what the different
measurements for 3 identical resistors in series could look like. The total voltage across all three
resistors is the sum of the voltages across the individual resistors.

file_data: 10.2.4|Ohm's Law|194
The voltage is the change in potential energy or work done when charge moves between two
points in the circuit. The greater the resistance to charge moving the more work that needs to
be done. The work done or voltage thus depends on the resistance. The potential difference is
proportional to the resistance.
Definition: Ohm’s Law
Voltage across a circuit component is proportional to the resistance of the component.
Use the fact that voltage is proportional to resistance to calculate what proportion of the total
voltage of a circuit will be found across each circuit element.
We know that the total voltage is equal to V1 in the first circuit, to V1 + V2 in the second
circuit and V1 + V2 + V3 in the third circuit.
We know that the potential energy lost across a resistor is proportional to the resistance of the
component. The total potential difference is shared evenly across the total resistance of the
circuit. This means that the potential difference per unit of resistance is
Then the voltage across a resistor is just the resistance times the potential difference per unit of
resistance

file_data: 10.2.5|EMF|195
When you measure the potential difference across (or between) the terminals of a battery you
are measuring the ”electromotive force” (emf) of the battery. This is how much potential energy
the battery has to make charges move through the circuit. This driving potential energy is equal
to the total potential energy drops in the circuit. This means that the voltage across the battery
is equal to the sum of the voltages in the circuit.
We can use this information to solve problems in which the voltages across elements in a circuit
add up to the emf.
EMF = Vtotal


file_data: 10.3|Current|198


file_data: 10.3.1|Flow of Charge|198
We have been talking about moving charge. We need to be able to deal with numbers, how
much charge is moving, how fast is it moving? The concept that gives us this information is
called current. Current allows us to quantify the movement of charge.
When we talk about current we talk about how much charge moves past a fixed point in circuit
in one second. Think of charges being pushed around the circuit by the battery, there are charges
in the wires but unless there is a battery they won’t move. When one charge moves the charges
next to it also move. They keep their spacing. If you had a tube of marbles like in this picture.
marble marble
If you push one marble into the tube one must come out the other side. If you look at any point
in the tube and push one marble into the tube, one marble will move past the point you are
looking at. This is similar to charges in the wires of a circuit.
If a charge moves they all move and the same number move at every point in the circuit.



file_data: 10.3.2|Current|198
Now that we’ve thought about the moving charges and visualised what is happening we need
to get back to quantifying moving charge. I’ve already told you that we use current but we still
need to define it.
Definition: Current
Current is the rate at which charges moves past a fixed point in a circuit. We use the
symbol I to show current and it is measured in amperes (A). One ampere is one coulomb
of charge moving in one second.
I =
Q
t
When current flows in a circuit we show this on a diagram by adding arrows. The arrows show
the direction of flow in a circuit. By convention we say that charge flows from the positive
terminal on a battery to the negative terminal.


file_data: 10.3.3|Series Circuits|199
In a series circuit, the charge has a single path from the battery, returning to the battery.
The arrows in this picture show you the direction that charge will flow in the circuit. They don’t
show you much charge will flow, only the direction.
Benjamin Franklin made a guess about the direction of charge flow when rubbing
smooth wax with rough wool. He thought that the charges flowed from the wax to
the wool (i.e. from positive to negative) which was opposite to the real direction.
Due to this, electrons are said to have a negative charge and so objects which Ben
Franklin called “negative” (meaning a shortage of charge) really have an excess
of electrons. By the time the true direction of electron flow was discovered, the
convention of “positive” and “negative” had already been so well accepted in the
scientific world that no effort was made to change it.
Important: A cell does not produce the same amount of current no matter what is
connected to it. While the voltage produced by a cell is constant, the amount of current
supplied depends on what is in the circuit.
How does the current through the battery in a circuit with several resistors in series compare to
the current in a circuit with a single resistor?


file_data: 10.3.4|Parallel Circuits|200
How does the current through the battery in a circuit with several resistors in parallel compare
to the current in a circuit with a single resistor?
Why is this the case? Why do more resistors make it easier for charge to flow in the circuit?
It is because they are in parallel so there are more paths for charge to take to move. You can
think of it like a highway with more lanes, or the tube of marbles splitting into multiple parallel
tubes. The more branches there are, the easier it is for charge to flow. You will learn more about
the total resistance of parallel resistors later but always remember that more resistors in parallel
mean more pathways. In series the pathways come one after the other so it does not make it
easier for charge to flow.



file_data: 10.4|Resistance|202


file_data: 10.4.1|What causes resistance?|202
We have spoken about resistors that slow down the flow of charge in a conductor. On a
microscopic level, electrons moving through the conductor collide with the particles of which
the conductor (metal) is made. When they collide, they transfer kinetic energy. The electrons
therefore lose kinetic energy and slow down. This leads to resistance. The transferred energy
causes the conductor to heat up. You can feel this directly if you touch a cellphone charger when
you are charging a cell phone - the charger gets warm!
Definition: Resistance
Resistance slows down the flow of charge in a circuit. We use the symbol R to show
resistance and it is measured in units called Ohms with the symbol 
.
1 Ohm = 1
Volt
Ampere
.
All conductors have some resistance. For example, a piece of wire has less resistance than a light
bulb, but both have resistance. The high resistance of the filament (small wire) in a lightbulb
causes the electrons to transfer a lot of their kinetic energy in the form of heat. The heat energy
is enough to cause the filament to glow white-hot which produces light. The wires connecting
the lamp to the cell or battery hardly even get warm while conducting the same amount of
current. This is because of their much lower resistance due to their larger cross-section (they
are thicker).
An important effect of a resistor is that it converts electrical energy into other forms of energy,
such as heat and light.
There is a special type of conductor, called a superconductor that has no
resistance, but the materials that make up superconductors only start supercon-
ducting at very low temperatures (approximately -170◦C).
Why do batteries go flat?
A battery stores chemical potential energy. When it is connected in a circuit, a chemical reaction
takes place inside the battery which converts chemical potential energy to electrical energy
which powers the electrons to move through the circuit. All the circuit elements (such as the
conducting leads, resistors and lightbulbs) have some resistance to the flow of charge and convert
the electrical energy to heat and/or light. The battery goes flat when all its chemical potential
energy has been converted into other forms of energy.


file_data: 10.4.2|Resistors in electric circuits|202
It is important to understand what effect adding resistors to a circuit has on the total resistance
of a circuit and on the current that can flow in the circuit.
Resistors in series
When we add resistors in series to a circuit, we increase the resistance to the flow of current.
There is only one path that the current can flow down and the current is the same at all places
in the series circuit. Take a look at the diagram below: On the left there is a circuit with a single
resistor and a battery. No matter where we measure the current, it is the same in a series circuit.
On the right, we have added a second resistor in series to the circuit. The total resistance of
the circuit has increased and you can see from the reading on the ammeter that the current in
the circuit has decreased.
Resistors in parallel
In contrast to the series case, when we add resistors in parallel, we create more paths along
which current can flow. By doing this we decrease the total resistance of the circuit!
Take a look at the diagram below. On the left we have the same circuit as in the previous
diagram with a battery and a resistor. The ammeter shows a current of 1 ampere. On the right
we have added a second resistor in parallel to the first resistor. This has increased the number
of paths (branches) the charge can take through the circuit - the total resistance has decreased.
You can see that the current in the circuit has increased. Also notice that the current in the
different branches can be different.



file_data: 10.5|Instruments to Measure voltage, current and resistance|204
As we have seen in previous sections, an electric circuit is made up of a number of different
components such as batteries, resistors and light bulbs. There are devices to measure the
properties of these components. These devices are called meters.
For example, one may be interested in measuring the amount of current flowing through a circuit
using an ammeter or measuring the voltage provided by a battery using a voltmeter. In this
section we will discuss the practical usage of voltmeters, ammeters, and ohmmeters.

file_data: 10.5.1|Voltmeter|204
A voltmeter is an instrument for measuring the voltage between two points in an electric circuit.
In analogy with a water circuit, a voltmeter is like a meter designed to measure pressure difference.
Since one is interested in measuring the voltage between two points in a circuit, a voltmeter
must be connected in parallel with the portion of the circuit on which the measurement is made.
V
Figure 10.3: A voltmeter should be connected in parallel in a circuit.
Figure 10.3 shows a voltmeter connected in parallel with a battery. One lead of the voltmeter is
connected to one end of the battery and the other lead is connected to the opposite end. The
voltmeter may also be used to measure the voltage across a resistor or any other component of
a circuit that has a voltage drop.

file_data: 10.5.2|Ammeter|204
An ammeter is an instrument used to measure the flow of electric current in a circuit. Since one
is interested in measuring the current flowing through a circuit component, the ammeter must
be connected in series with the measured circuit component (Figure 10.4).

file_data: 10.5.3|Ohmmeter|204
An ohmmeter is an instrument for measuring electrical resistance. The basic ohmmeter can
function much like an ammeter. The ohmmeter works by suppling a constant voltage to the
resistor and measuring the current flowing through it. The measured current is then converted
into a corresponding resistance reading through Ohm’s Law. Ohmmeters only function correctly
when measuring resistance that is not being powered by a voltage or current source. In other
words, you cannot measure the resistance of a component that is already connected to a circuit.
This is because the ohmmeter’s accurate indication depends only on its own source of voltage.
The presence of any other voltage across the measured circuit component interferes with the
ohmmeter’s operation. Figure 10.5 shows an ohmmeter connected with a resistor.

file_data: 10.5.4|Meters Impact on Circuit|205
A good quality meter used correctly will not significantly change the values it is used to measure.
This means that an ammeter has very low resistance to not slow down the flow of charge.
A voltmeter has a very high resistance so that it does not add another parallel pathway to the
circuit for the charge to flow along.

file_data: 10.6|Exercises - Electric circuits|205



file_data: 11|Vectors|211


file_data: 11.1|Introduction|211
This chapter focuses on vectors. We will learn what is a vector, how it differs from everyday
numbers, how to add, subtract and multiply them and where they appear in Physics.
Are vectors Physics? No, vectors themselves are not Physics. Physics is just a description of
the world around us. To describe something we need to use a language. The most common
language used to describe Physics is Mathematics. Vectors form a very important part of the
mathematical description of Physics, so much so that it is absolutely essential to master the use
of vectors.


file_data: 11.2|Scalars and Vectors|211
In Mathematics, you learned that a number is something that represents a quantity. For example
if you have 5 books, 6 apples and 1 bicycle, the 5, 6, and 1 represent how many of each item
you have.
These kinds of numbers are known as scalars.
Definition: Scalar
A scalar is a quantity that has only magnitude (size).
An extension to a scalar is a vector, which is a scalar with a direction. For example, if you travel
1 km down Main Road to school, the quantity 1 km down Main Road is a vector. The 1 km
is the quantity (or scalar) and the down Main Road gives a direction.
In Physics we use the word magnitude to refer to the scalar part of the vector.
Definition: Vectors
A vector is a quantity that has both magnitude and direction.
A vector should tell you how much and which way.
For example, a man is driving his car east along a freeway at 100 km·hr−1. What we have given
here is a vector – the velocity. The car is moving at 100 km·hr−1(this is the magnitude) and we
know where it is going – east (this is the direction). Thus, we know the speed and direction of
the car. These two quantities, a magnitude and a direction, form a vector we call velocity.

file_data: 11.3|Notation|211
Vectors are different to scalars and therefore has its own notation.

file_data: 11.3.1|Mathematical Representation|212
There are many ways of writing the symbol for a vector. Vectors are denoted by symbols with an
arrow pointing to the right above it. For example, ~a, ~v and ~F represent the vectors acceleration,
velocity and force, meaning they have both a magnitude and a direction.
Sometimes just the magnitude of a vector is needed. In this case, the arrow is omitted. In other
words, F denotes the magnitude of vector ~F. | ~F| is another way of representing the magnitude
of a vector.

file_data: 11.3.2|Graphical Representation|212
Vectors are drawn as arrows. An arrow has both a magnitude (how long it is) and a direction
(the direction in which it points). The starting point of a vector is known as the tail and the
end point is known as the head.

file_data: 11.4|Directions|212
There are many acceptable methods of writing vectors. As long as the vector has a magnitude
and a direction, it is most likely acceptable. These different methods come from the different
methods of expressing a direction for a vector.

file_data: 11.4.1|Relative Directions|212
The simplest method of expressing direction is relative directions: to the left, to the right,
forward, backward, up and down.

file_data: 11.4.2|Compass Directions|213
Another common method of expressing direc-
tions is to use the points of a compass: North,
South, East, and West.
If a vector does not point exactly in one
of the compass directions, then we use an angle.
For example, we can have a vector pointing 40◦
North of West. Start with the vector pointing
along the West direction:
Then rotate the vector towards the north
until there is a 40◦ angle between the vector
and the West.
The direction of this vector can also be described
as: W 40◦ N (West 40◦ North); or N 50◦ W
(North 50◦ West)

file_data: 11.4.3|Bearing|213
The final method of expressing direction is to use a bearing. A bearing is a direction relative to
a fixed point.
Given just an angle, the convention is to define the angle with respect to the North. So, a vector
with a direction of 110◦ has been rotated clockwise 110◦ relative to the North. A bearing is
always written as a three digit number, for example 275◦ or 080◦ (for 80◦).

file_data: 11.5|Drawing Vectors|214
In order to draw a vector accurately we must specify a scale and include a reference direction in
the diagram. A scale allows us to translate the length of the arrow into the vector’s magnitude.
For instance if one chose a scale of 1 cm = 2 N (1 cm represents 2 N), a force of 20 N towards
the East would be represented as an arrow 10 cm long. A reference direction may be a line
representing a horizontal surface or the points of a compass.
Method: Drawing Vectors
1. Decide upon a scale and write it down.
2. Determine the length of the arrow representing the vector, by using the scale.
3. Draw the vector as an arrow. Make sure that you fill in the arrow head.
4. Fill in the magnitude of the vector.

file_data: 11.6|Mathematical Properties of Vectors|215
Vectors are mathematical objects and we need to understand the mathematical properties of
vectors, like adding and subtracting.
For all the examples in this section, we will use displacement as our vector quantity. Displacement
was discussed in Chapter 3. Displacement is defined as the distance together with direction of
the straight line joining a final point to an initial point.
Remember that displacement is just one example of a vector. We could just as well have decided
to use forces or velocities to illustrate the properties of vectors.


file_data: 11.6.1|Adding Vectors|215
When vectors are added, we need to add both a magnitude and a direction. For example, take 2
steps in the forward direction, stop and then take another 3 steps in the forward direction. The
first 2 steps is a displacement vector and the second 3 steps is also a displacement vector. If we
did not stop after the first 2 steps, we would have taken 5 steps in the forward direction in total.
Therefore, if we add the displacement vectors for 2 steps and 3 steps, we should get a total of
5 steps in the forward direction. Graphically, this can be seen by first following the first vector
two steps forward and then following the second one three steps forward:
We add the second vector at the end of the first vector, since this is where we now are after
the first vector has acted. The vector from the tail of the first vector (the starting point) to the
head of the last (the end point) is then the sum of the vectors. This is the head-to-tail method
of vector addition.
As you can convince yourself, the order in which you add vectors does not matter. In the example
above, if you decided to first go 3 steps forward and then another 2 steps forward, the end result
would still be 5 steps forward.
The final answer when adding vectors is called the resultant. The resultant displacement in this
case will be 5 steps forward.
Definition: Resultant of Vectors
The resultant of a number of vectors is the single vector whose effect is the same as the
individual vectors acting together.
In other words, the individual vectors can be replaced by the resultant – the overall effect is the
same. If vectors ~a and ~b have a resultant ~R, this can be represented mathematically as,
Let us consider some more examples of vector addition using displacements. The arrows tell you
how far to move and in what direction. Arrows to the right correspond to steps forward, while
arrows to the left correspond to steps backward. Look at all of the examples below and check
them.
This example says 1 step forward and then another step forward is the same as an arrow twice
as long – two steps forward.
This examples says 1 step backward and then another step backward is the same as an arrow
twice as long – two steps backward.
It is sometimes possible that you end up back where you started. In this case the net result of
what you have done is that you have gone nowhere (your start and end points are at the same
place). In this case, your resultant displacement is a vector with length zero units. We use the
symbol ~0 to denote such a vector:
It is important to realise that the directions are not special– ‘forward and backwards’ or ‘left and
right’ are treated in the same way. The same is true of any set of parallel directions:
In the above examples the separate displacements were parallel to one another. However the
same head-to-tail technique of vector addition can be applied to vectors in any direction.
Now you have discovered one use for vectors; describing resultant displacement – how far and
in what direction you have travelled after a series of movements.
Although vector addition here has been demonstrated with displacements, all vectors behave in
exactly the same way. Thus, if given a number of forces acting on a body you can use the same
method to determine the resultant force acting on the body. We will return to vector addition
in more detail later.

file_data: 11.6.2|Subtracting Vectors|217
What does it mean to subtract a vector? Well this is really simple; if we have 5 apples and we
subtract 3 apples, we have only 2 apples left. Now lets work in steps; if we take 5 steps forward
and then subtract 3 steps forward we are left with only two steps forward:
What have we done? You originally took 5 steps forward but then you took 3 steps back. That
backward displacement would be represented by an arrow pointing to the left (backwards) with
length 3. The net result of adding these two vectors is 2 steps forward:
Thus, subtracting a vector from another is the same as adding a vector in the opposite direction
(i.e. subtracting 3 steps forwards is the same as adding 3 steps backwards).
Important: Subtracting a vector from another is the same as adding a vector in the opposite
direction.
This suggests that in this problem to the right was chosen as the positive direction. Arrows to
the right are positive and arrows to the left are negative. More generally, vectors in opposite
directions differ in sign (i.e. if we define up as positive, then vectors acting down are negative).
Thus, changing the sign of a vector simply reverses its direction:


file_data: 11.6.3|Scalar Multiplication|218
What happens when you multiply a vector by a scalar (an ordinary number)?
Going back to normal multiplication we know that 2 ×2 is just 2 groups of 2 added together to
give 4. We can adopt a similar approach to understand how vector multiplication works.

file_data: 11.7|Techniques of Vector Addition|218
Now that you have learned about the mathematical properties of vectors, we return to vector
addition in more detail. There are a number of techniques of vector addition. These techniques
fall into two main categories - graphical and algebraic techniques.

file_data: 11.7.1|Graphical Techniques|218
Graphical techniques involve drawing accurate scale diagrams to denote individual vectors and
their resultants. We next discuss the two primary graphical techniques, the head-to-tail technique
and the parallelogram method.
The Head-to-Tail Method
In describing the mathematical properties of vectors we used displacements and the head-to-tail
graphical method of vector addition as an illustration. The head-to-tail method of graphically
adding vectors is a standard method that must be understood.
Method: Head-to-Tail Method of Vector Addition
1. Choose a scale and include a reference direction.
2. Choose any of the vectors and draw it as an arrow in the correct direction and of the
correct length – remember to put an arrowhead on the end to denote its direction.
3. Take the next vector and draw it as an arrow starting from the arrowhead of the first vector
in the correct direction and of the correct length.
4. Continue until you have drawn each vector – each time starting from the head of the
previous vector. In this way, the vectors to be added are drawn one after the other head-
to-tail.
5. The resultant is then the vector drawn from the tail of the first vector to the head of the
last. Its magnitude can be determined from the length of its arrow using the scale. Its
direction too can be determined from the scale diagram.
The Parallelogram Method
The parallelogram method is another graphical technique of finding the resultant of two vectors.
Method: The Parallelogram Method
1. Choose a scale and a reference direction.
2. Choose either of the vectors to be added and draw it as an arrow of the correct length in
the correct direction.
3. Draw the second vector as an arrow of the correct length in the correct direction from the
tail of the first vector.
4. Complete the parallelogram formed by these two vectors.
5. The resultant is then the diagonal of the parallelogram. The magnitude can be determined
from the length of its arrow using the scale. The direction too can be determined from
the scale diagram.
The parallelogram method is restricted to the addition of just two vectors. However, it is arguably
the most intuitive way of adding two forces acting at a point.

file_data: 11.7.2|Algebraic Addition and Subtraction of Vectors|223
Vectors in a Straight Line
Whenever you are faced with adding vectors acting in a straight line (i.e. some directed left and
some right, or some acting up and others down) you can use a very simple algebraic technique:
Method: Addition/Subtraction of Vectors in a Straight Line
1. Choose a positive direction. As an example, for situations involving displacements in the
directions west and east, you might choose west as your positive direction. In that case,
displacements east are negative.
2. Next simply add (or subtract) the vectors using the appropriate signs.
3. As a final step the direction of the resultant should be included in words (positive answers
are in the positive direction, while negative resultants are in the negative direction).
In the previous example we were able to use simple trigonometry to calculate the resultant
displacement. This was possible since the directions of motion were perpendicular (north and
east). Algebraic techniques, however, are not limited to cases where the vectors to be combined
are along the same straight line or at right angles to one another. The following example
illustrates this.


file_data: 11.8|Components of Vectors|228
In the discussion of vector addition we saw that a number of vectors acting together can be
combined to give a single vector (the resultant). In much the same way a single vector can be
broken down into a number of vectors which when added give that original vector. These vectors
which sum to the original are called components of the original vector. The process of breaking
a vector into its components is called resolving into components.
While summing a given set of vectors gives just one answer (the resultant), a single vector can be
resolved into infinitely many sets of components. In the diagrams below the same black vector
is resolved into different pairs of components. These components are shown as dashed lines.
When added together the dashed vectors give the original black vector (i.e. the original vector
is the resultant of its components).
In practice it is most useful to resolve a vector into components which are at right angles to one
another, usually horizontal and vertical.
Any vector can be resolved into a horizontal and a vertical component. If ~A is a vector, then
the horizontal component of ~A is ~Ax and the vertical component is ~Ay.

file_data: 11.8.1|Vector addition using components|231
Components can also be used to find the resultant of vectors. This technique can be applied
to both graphical and algebraic methods of finding the resultant. The method is simple: make
a rough sketch of the problem, find the horizontal and vertical components of each vector, find
the sum of all horizontal components and the sum of all the vertical components and then use
them to find the resultant.
Consider the two vectors, ~A and ~B, in Figure 11.3, together with their resultant, ~ R.
Each vector in Figure 11.3 can be broken down into a component in the x-direction and one
in the y-direction. These components are two vectors which when added give you the original
vector as the resultant. This is shown in Figure 11.4 where we can see that:
In summary, addition of the x components of the two original vectors gives the x component of
the resultant. The same applies to the y components. So if we just added all the components
together we would get the same answer! This is another important property of vectors.


file_data: 11.8.2|Summary|235


file_data: 11.8.3|End of chapter exercises: Vectors|236


file_data: 11.8.4|End of chapter exercises: Vectors - Long questions|237





file_data: 12|Force, Momentum and Impulse - Grade 11|239


file_data: 12.1|Introduction|239
In Grade 10 we studied motion but not what caused the motion. In this chapter we will learn
that a net force is needed to cause motion. We recall what a force is and learn about how force
and motion are related. We are introduced to two new concepts, momentum and impulse, and
we learn more about turning forces and the force of gravity.


file_data: 12.2|Force|239


file_data: 12.2.1|What is a force?|239
A force is anything that can cause a change to objects. Forces can:
• change the shape of an object
• move or stop an object
• change the direction of a moving object.
A force can be classified as either a contact force or a non-contact force.
A contact force must touch or be in contact with an object to cause a change. Examples of
contact forces are:
• the force that is used to push or pull things, like on a door to open or close it
• the force that a sculptor uses to turn clay into a pot
• the force of the wind to turn a windmill
A non-contact force does not have to touch an object to cause a change. Examples of non-
contact forces are:
• the force due to gravity, like the Earth pulling the Moon towards itself
• the force due to electricity, like a proton and an electron attracting each other
• the force due to magnetism, like a magnet pulling a paper clip towards itself
The unit of force is the newton (symbol N). This unit is named after Sir Isaac Newton who
first defined force. Force is a vector quantity and has a magnitude and a direction. We use the
abbreviation F for force.
There is a popular story that while Sir Isaac Newton was sitting under an apple
tree, an apple fell on his head, and he suddenly thought of the Universal Law of
Gravitation. Coincidently, the weight of a small apple is approximately 1 N.
Force was first described by Archimedes of Syracuse (circa 287 BC - 212 BC).
Archimedes was a Greek mathematician, astronomer, philosopher, physicist and
engineer. He was killed by a Roman soldier during the sack of the city, despite
orders from the Roman general, Marcellus, that he was not to be harmed.
This chapter will often refer to the resultant force acting on an object. The resultant force is
simply the vector sum of all the forces acting on the object. It is very important to remember
that all the forces must be acting on the same object. The resultant force is the force that has
the same effect as all the other forces added together.


file_data: 12.2.2|Examples of Forces in Physics|240
Most of Physics revolves around forces. Although there are many different forces, all are handled
in the same way. All forces in Physics can be put into one of four groups. These are gravitational
forces, electromagnetic forces, strong nuclear force and weak nuclear force. You will mostly come
across gravitational or electromagnetic forces at school.
Gravitational Forces
Gravity is the attractive force between two objects due to the mass of the objects. When you
throw a ball in the air, its mass and the Earth’s mass attract each other, which leads to a force
between them. The ball falls back towards the Earth, and the Earth accelerates towards the ball.
The movement of the Earth towards the ball is, however, so small that you couldn’t possibly
measure it.
Electromagnetic Forces
Almost all of the forces that we experience in everyday life are electromagnetic in origin. They
have this unusual name because long ago people thought that electric forces and magnetic forces
were different things. After much work and experimentation, it has been realised that they are
actually different manifestations of the same underlying theory.
Electric or Electrostatic Forces
If we have objects carrying electrical charge, which are not moving, then we are dealing with
electrostatic forces (Coulomb’s Law). This force is actually much stronger than gravity. This may
seem strange, since gravity is obviously very powerful, and holding a balloon to the wall seems to
be the most impressive thing electrostatic forces have done, but if we think about it: for gravity
to be detectable, we need to have a very large mass nearby. But a balloon rubbed in someone’s
hair can stick to a wall with a force so strong that it overcomes the force of gravity—with just
the charges in the balloon and the wall!
Magnetic Forces
The magnetic force is a different manifestation of the electromagnetic force. It stems from the
interaction between moving charges as opposed to the fixed charges involved in Coulomb’s Law.
Examples of the magnetic force in action include magnets, compasses,car engines and computer
data storage. Magnets are also used in the wrecking industry to pick up cars and move them
around sites.
Friction
According to Newton’s First Law (we will discuss this later in the chapter) an object moving
without a force acting on it will keep on moving. Then why does a box sliding on a table stop?
The answer is friction. Friction arises from the interaction between the molecules on the bottom
of a box with the molecules on a table. This interaction is electromagnetic in origin, hence
friction is just another view of the electromagnetic force. Later in this chapter we will discuss
frictional forces a little more.
Drag Forces
This is the force an object experiences while travelling through a medium like an aeroplane flying
through air. When something travels through the air it needs to displace air as it travels and
because of this the air exerts a force on the object. This becomes an important force when you
move fast and a lot of thought is taken to try and reduce the amount of drag force a sports
car or an aeroplane experiences. The drag force is very useful for parachutists. They jump from
high altitudes and if there was no drag force, then they would continue accelerating all the way
to the ground. Parachutes are wide because the more surface area you show, the greater the
drag force and hence the slower you hit the ground.


file_data: 12.2.3|Systems and External Forces|241
The concepts of a system and an external forces are very important in Physics. A system is any
collection of objects. If one draws an imaginary box around such a system then an external force
is one that is applied by an object or person outside the box. Imagine for example a car pulling
two trailers.
If we draw a box around the two trailers they can be considered a closed system or unit. When
we look at the forces on this closed system the following forces will apply:
• The force of the car pulling the unit (trailer A and B)
• The force of friction between the wheels of the trailers and the road (opposite to the
direction of motion)
• The force of the Earth pulling downwards on the system (gravity)
• The force of the road pushing upwards on the system
These forces are called external forces to the system.
The following forces will not apply:
The force of A pulling B
• The force of B pulling A
• The force of friction between the wheels of the car and the road (opposite to the direction
of motion)
We can also draw a box around trailer A or B, in which case the forces will be different.
If we consider trailer A as a system, the following external forces will apply:
• The force of the car pulling on A (towards the right)
• The force of B pulling on A (towards the left)
• The force of the Earth pulling downwards on the trailer (gravity)
• The force of the road pushing upwards on the trailer


file_data: 12.2.4|Force Diagrams|242
If we look at the example above and draw a force diagram of all the forces acting on the
two-trailer-unit, the diagram would look like this:
It is important to keep the following in mind when you draw force diagrams:
• Make your drawing large and clear.
• You must use arrows and the direction of the arrow will show the direction of the force.
• The length of the arrow will indicate the size of the force, in other words, the longer arrows
in the diagram (F1 for example) indicates a bigger force than a shorter arrow (Ff ). Arrows
of the same length indicate forces of equal size (FN and Fg). Use ?little lines? like in
maths to show this.
• Draw neat lines using a ruler. The arrows must touch the system or object.
• All arrows must have labels. Use letters with a key on the side if you do not have enough
space on your drawing.
• The labels must indicate what is applying the force (the force of the car?) on what the
force is applied (?on the trailer?) and in which direction (to the right)
• If the values of the forces are known, these values can be added to the diagram or key.



file_data: 12.2.5|Free Body Diagrams|243
In a free-body diagram, the object of interest is drawn as a dot and all the forces acting on it
are drawn as arrows pointing away from the dot. A free body diagram for the two-trailer-system
will therefore look like this:



file_data: 12.2.6|Finding the Resultant Force|244
The easiest way to determine a resultant force is to draw a free body diagram. Remember from
Chapter ?? that we use the length of the arrow to indicate the vector’s magnitude and the
direction of the arrow to show which direction it acts in.
After we have done this, we have a diagram of vectors and we simply find the sum of the vectors
to get the resultant force.
Figure 12.1: (a) Force diagram of 2 forces acting on a box. (b) Free body diagram of the box.
For example, two people push on a box from opposite sides with forces of 4 N and 6 N respectively
as shown in Figure 12.1(a). The free body diagram in Figure 12.1(b) shows the object represented
by a dot and the two forces are represented by arrows with their tails on the dot.
As you can see, the arrows point in opposite directions and have different lengths. The resultant
force is 2 N to the left. This result can be obtained algebraically too, since the two forces act
along the same line. First, as in motion in one direction, choose a frame of reference. Secondly,
add the two vectors taking their directions into account.
For the example, assume that the positive direction is to the right, then:
FR = (+4N) + (−6N)
= −2N
= 2N to the left
Remember that a negative answer means that the force acts in the opposite direction to the one
that you chose to be positive. You can choose the positive direction to be any way you want,
but once you have chosen it you must keep it.
As you work with more force diagrams in which the forces exactly balance, you may notice that
you get a zero answer (e.g. 0 N). This simply means that the forces are balanced and that the
object will not move.
Once a force diagram has been drawn the techniques of vector addition introduced in Chapter ??
can be used. Depending on the situation you might choose to use a graphical technique such as
the tail-to-head method or the parallelogram method, or else an algebraic approach to determine
the resultant. Since force is a vector all of these methods apply.


file_data: 12.2.7|Exercise|246


file_data: 12.3|Newton's Laws|246
In grade 10 you learned about motion, but did not look at how things start to move. You have
also learned about forces. In this section we will look at the effect of forces on objects and how
we can make things move.




file_data: 12.3.1|Newton's First Law|247
Sir Isaac Newton was a scientist who lived in England (1642-1727). He was interested in the
reason why objects move. He suggested that objects that are stationary will remain stationary,
unless a force acts on them and objects that are moving will keep on moving, unless a force
slows them down, speeds them up or let them change direction. From this he formulated what
is known as Newton’s First Law of Motion:
Definition: Newton’s First Law of Motion
An object will remain in a state of rest or continue traveling at constant velocity, unless
acted upon by an unbalanced (net) force.
Let us consider the following situations:
An ice skater pushes herself away from the side of the ice rink and skates across the ice. She
will continue to move in a straight line across the ice unless something stops her. Objects are
also like that. If we kick a soccer ball across a soccer field, according to Newton’s First Law,
the soccer ball should keep on moving forever! However, in real life this does not happen. Is
Newton’s Law wrong? Not really. Newton’s First Law applies to situations where there aren’t
any external forces present. This means that friction is not present. In the case of the ice skater,
the friction between the skates and the ice is very little and she will continue moving for quite a
distance. In the case of the soccer ball, air resistance (friction between the air and the ball) and
friction between the grass and the ball is present and this will slow the ball down.
Newton’s First Law in action
We experience Newton’s First Law in every day life. Let us look at the following examples:
Rockets:
A spaceship is launched into space. The force of the exploding gases pushes the rocket through
the air into space. Once it is in space, the engines are switched off and it will keep on moving
at a constant velocity. If the astronauts want to change the direction of the spaceship they need
to fire an engine. This will then apply a force on the rocket and it will change its direction.
Seat belts:
We wear seat belts in cars. This is to protect us when the car is involved in an accident. If
a car is traveling at 120 km·hr−1, the passengers in the car is also traveling at 120 km·hr−1.
When the car suddenly stops a force is exerted on the car (making it slow down), but not on the
passengers. The passengers will carry on moving forward at 120 km·hr−1according to Newton
I. If they are wearing seat belts, the seat belts will stop them and therefore prevent them from
getting hurt.


file_data: 12.3.2|Newton's Second Law of Motion|249
According to Newton I, things ’like to keep on doing what they are doing’. In other words, if
an object is moving, it likes to keep on moving and if an object is stationary, it likes to stay
stationary. So how do objects start to move then?
Let us look at the example of a 10 kg box on a rough table. If we push lightly on the box as
indicated in the diagram, the box won’t move. Let’s say we applied a force of 100 N, yet the
box remains stationary. At this point a frictional force of 100 N is acting on the box, preventing
the box from moving. If we increase the force, lets say to 150 N and the box just about starts to
move, the frictional force is 150 N. To be able to move the box, we need to push hard enough to
overcome the friction and then move the box. If we therefore apply a force of 200 N remembering
that a frictional force of 150 N is present, the ’first’ 150 N will be used to overcome or ’cancel’
the friction and the other 50 N will be used to move (accelerate) the block. In order to accelerate
an object we must have a resultant force acting on the block.
Now, what do you think will happen if we pushed harder, lets say 300 N? Or, what do you
think will happen if the mass of the block was more, say 20 kg, or what if it was less? Let us
investigate how the motion of an object is affected by mass and force.
You will have noted in the investigation above that the heavier the trolley is, the slower it moved.
The acceleration is indirectly proportional to the mass. In mathematical terms: a ∝ 1
m
In a similar investigation where the mass is kept constant, but the applied force is varied, you
will find that the bigger the force is, the faster the object will move. The acceleration of the
trolley is therefore directly proportional to the resultant force. In mathematical terms: a ∝ F.
If we rearrange the above equations, we get a ∝ F
m OR F = ma
Newton formulated his second law as follows:
Definition: Newton’s Second Law of Motion
If a resultant force acts on a body, it will cause the body to accelerate in the direction of the
resultant force. The acceleration of the body will be directly proportional to the resultant
force and indirectly proportional to the mass of the body. The mathematical representation
is a ∝ F
m.
Applying Newton’s Second Law
Newton’s Second Law can be applied to a variety of situations. We will look at the main types
of examples that you need to study.
Object on an inclined plane
When we place an object on a slope the force of gravity (Fg) acts straight down and not
perpendicular to the slope. Due to gravity pulling straight down, the object will tend to slide down the slope with a force equal to the horizontal component of the force of gravity (Fg sin θ).
The object will ’stick’ to the slope due to the frictional force between the object and the surface.
As you increase the angle of the slope, the horizontal component will also increase until the
frictional force is overcome and the object starts to slide down the slope.
The force of gravity will also tend to push an object ’into’ the slope. This force is equal to the
vertical component of the force of gravity (Fg cos θ). There is no movement in this direction as
this force is balanced by the slope pushing up against the object. This ?pushing force? is called
the normal force (N) and is equal to the resultant force in the vertical direction, Fg sin θ in this
case, but opposite in direction.
Important: Do not use the abbreviation W for weight as it is used to abbreviate ’work’.
Rather use the force of gravity Fg for weight.
Lifts and rockets
So far we have looked at objects being pulled or pushed across a surface, in other words hori-
zontal motion. Here we only considered horizontal forces, but we can also lift objects up or let
them fall. This is vertical motion where only vertical forces are being considered.
Let us consider a 500 kg lift, with no passengers, hanging on a cable. The purpose of the
cable is to pull the lift upwards so that it can reach the next floor or to let go a little so that it
can move downwards to the floor below. We will look at five possible stages during the motion
of the lift.
Stage 1:
The 500 kg lift is stationary at the second floor of a tall building.
Because the lift is stationary (not moving) there is no resultant force acting on the lift. This
means that the upward forces must be balanced by the downward forces. The only force acting
down is the force of gravity which is equal to (500 x 9,8 = 4900 N) in this case. The cable must
therefore pull upwards with a force of 4900 N to keep the lift stationary at this point.
Stage 2:
The lift moves upwards at an acceleration of 1 m·s−2.
If the lift is accelerating, it means that there is a resultant force in the direction of the motion.
This means that the force acting upwards is now bigger than the force of gravity Fg (down). To
find the magnitude of the force applied by the cable (Fc) we can do the following calculation:
(Remember to choose a direction as positive. We have chosen upwards as positive.)
FR = ma
Fc + Fg = ma
Fc + (−4900) = (500)(1)
Fc = 5400 N upwards
The answer makes sense as we need a bigger force upwards to cancel the effect of gravity as well
as make the lift go faster.
Stage 3:
The lift moves at a constant velocity.
When the lift moves at a constant velocity, it means that all the forces are balanced and that
there is no resultant force. The acceleration is zero, therefore FR = 0. The force acting upwards
is equal to the force acting downwards, therefore Fc = 4900 N.
Stage 4:
The lift slow down at a rate of 2m·s−2.
As the lift is now slowing down there is a resultant force downwards. This means that the force
acting downwards is bigger than the force acting upwards. To find the magnitude of the force
applied by the cable (Fc) we can do the following calculation: Again we have chosen upwards as
positive, which means that the acceleration will be a negative number.
This makes sense as we need a smaller force upwards to ensure a resultant force down. The
force of gravity is now bigger than the upward pull of the cable and the lift will slow down.
Stage 5:
The cable snaps.
When the cable snaps, the force that used to be acting upwards is no longer present. The only
force that is present would be the force of gravity. The lift will freefall and its acceleration can
be calculated as follows:
Rockets
Like with lifts, rockets are also examples of objects in vertical motion. The force of gravity pulls
the rocket down while the thrust of the engine pushes the rocket upwards. The force that the
engine exerts must overcome the force of gravity so that the rocket can accelerate upwards. The
worked example below looks at the application of Newton’s Second Law in launching a rocket.



file_data: 12.3.3|Exercise|261


file_data: 12.3.4|Newton's Third Law of Motion|263
Newton’s Third Law of Motion deals with the interaction between pairs of objects. For example,
if you hold a book up against a wall you are exerting a force on the book (to keep it there) and
the book is exerting a force back at you (to keep you from falling through the book). This may
sound strange, but if the book was not pushing back at you, your hand will push through the
book! These two forces (the force of the hand on the book (F1) and the force of the book on
the hand (F2)) are called an action-reaction pair of forces. They have the same magnitude, but
act in opposite directions and act on different objects (the one force is onto the book and the
other is onto your hand).
There is another action-reaction pair of forces present in this situation. The book is pushing
against the wall (action force) and the wall is pushing back at the book (reaction). The force of
the book on the wall (F3) and the force of the wall on the book (F4) are shown in the diagram.
Definition: Newton’s Third Law of Motion
If body A exerts a force on body B, then body B exerts a force of equal magnitude on body
A, but in the opposite direction.
Newton’s action-reaction pairs can be found everywhere in life where two objects interact with
one another. The following worked examples will illustrate this:



file_data: 12.3.5|Exercise|267


file_data: 12.3.6|Different types of forces|268
Tension
Tension is the magnitude of the force that exists in objects like ropes, chains and struts that are
providing support. For example, there are tension forces in the ropes supporting a child’s swing
hanging from a tree.
Contact and non-contact forces
In this chapter we have come across a number of different types of forces, for example a push
or a pull, tension in a string, frictional forces and the normal. These are all examples of contact
forces where there is a physical point of contact between applying the force and the object.
Non-contact forces are forces that act over a distance, for example magnetic forces, electrostatic forces and gravitational forces.
When an object is placed on a surface, two types of surface forces can be identified. Fric-
tion is a force that acts between the surface and the object and parallel to the surface. The
normal force is a force that acts between the object and the surface and parallel to the surface.
The normal force
A 5 kg box is placed on a rough surface and a 10 N force is applied at an angle of 36,9◦ to
the horizontal. The box does not move. The normal force (N or FN) is the force between
the box and the surface acting in the vertical direction. If this force is not present the box
would fall through the surface because the force of gravity pulls it downwards. The normal force
therefore acts upwards. We can calculate the normal force by considering all the forces in the
vertical direction. All the forces in the vertical direction must add up to zero because there is
no movement in the vertical direction.
The most interesting and illustrative normal force question, that is often asked, has to do with
a scale in a lift. Using Newton’s third law we can solve these problems quite easily.
When you stand on a scale to measure your weight you are pulled down by gravity. There is no
acceleration downwards because there is a reaction force we call the normal force acting upwards
on you. This is the force that the scale would measure. If the gravitational force were less then
the reading on the scale would be less.
Now we are going to add things to exactly the same problem to show how things change slightly.
We will now move to a lift moving at constant velocity. Remember if velocity is constant then
acceleration is zero.
In the previous two examples we got exactly the same result because the net acceleration on the
man was zero! If the lift is accelerating downwards things are slightly different and now we will
get a more interesting answer!
Friction forces
When the surface of one object slides over the surface of another, each body exerts a frictional
force on the other. For example if a book slides across a table, the table exerts a frictional
force onto the book and the book exerts a frictional force onto the table (Newton’s Third Law).
Frictional forces act parallel to the surfaces.
A force is not always big enough to make an object move, for example a small applied force
might not be able to move a heavy crate. The frictional force opposing the motion of the crate
is equal to the applied force but acting in the opposite direction. This frictional force is called
static friction. When we increase the applied force (push harder), the frictional force will also
increase until the applied force overcomes it. This frictional force can vary from zero (when
no other forces are present and the object is stationary) to a maximum that depends on the
surfaces. When the applied force is greater than the frictional force and the crate will move.
The frictional force will now decrease to a new constant value which is also dependent on the
surfaces. This is called kinetic friction. In both cases the maximum frictional force is related to
the normal force and can be calculated as follows:
For static friction: Ff ≤ μs N
Where μs = the coefficient of static friction
and N = normal force
For kinetic friction: Ff = μk N
Where μk = the coefficient of kinetic friction
and N = normal force
Remember that static friction is present when the object is not moving and kinetic friction
while the object is moving. For example when you drive at constant velocity in a car on a tar
road you have to keep the accelerator pushed in slightly to overcome the kinetic friction between
the tar road and the wheels of the car. The higher the value for the coefficient of friction, the
more ’sticky’ the surface is and the lower the value, the more ’slippery’ the surface is.
The frictional force (Ff ) acts in the horizontal direction and can be calculated in a similar way
to the normal for as long as there is no movement. If we use the same example as in figure 12.12
and we choose to the right as positive,
We often think about friction in a negative way but very often friction is useful without us
realizing it. If there was no friction and you tried to prop a ladder up against a wall, it would
simply slide to the ground. Rock climbers use friction to maintain their grip on cliffs. The brakes
of cars would be useless if it wasn’t for friction!


file_data: 12.3.7|Exercise|275


file_data: 12.3.8|Forces in equilibrium|276
At the beginning of this chapter it was mentioned that resultant forces cause objects to accelerate
in a straight line. If an object is stationary or moving at constant velocity then either,
• no forces are acting on the object, or
• the forces acting on that object are exactly balanced.
In other words, for stationary objects or objects moving with constant velocity, the resultant
force acting on the object is zero. Additionally, if there is a perpendicular moment of force, then
the object will rotate. You will learn more about moments of force later in this chapter.
Therefore, in order for an object not to move or to be in equilibrium, the sum of the forces
(resultant force) must be zero and the sum of the moments of force must be zero.
Definition: Equilibrium
An object in equilibrium has both the sum of the forces acting on it and the sum of the
moments of the forces equal to zero.
If a resultant force acts on an object then that object can be brought into equilibrium by applying
an additional force that exactly balances this resultant. Such a force is called the equilibrant
and is equal in magnitude but opposite in direction to the original resultant force acting on the
object.
Definition: Equilibrant
The equilibrant of any number of forces is the single force required to produce equilibrium,
and is equal in magnitude but opposite in direction to the resultant force.
In the figure the resultant of F1 and F2 is shown. The equilibrant of F1 and F2 is then the
vector opposite in direction to this resultant with the same magnitude (i.e. F3).
• F1, F2 and F3 are in equilibrium
• F3 is the equilibrant of F1 and F2
• F1 and F2 are kept in equilibrium by F3
As an example of an object in equilibrium, consider an object held stationary by two ropes in the
arrangement below:
Let us draw a free body diagram for the object. In the free body diagram the object is drawn as
a dot and all forces acting on the object are drawn in the correct directions starting from that
dot. In this case, three forces are acting on the object.
Each rope exerts a force on the object in the direction of the rope away from the object. These
tension forces are represented by T1 and T2. Since the object has mass, it is attracted towards
the centre of the Earth. This weight is represented in the force diagram as Fg.
Since the object is stationary, the resultant force acting on the object is zero. In other words the
three force vectors drawn tail-to-head form a closed triangle:


file_data: 12.3.9|Exercise|279


file_data: 12.4|Forces between Masses|282
In Chapter ??, you saw that gravitational fields exert forces on masses in the field. A field is
a region of space in which an object experiences a force. The strength of a field is defined by
a field strength. For example, the gravitational field strength, g, on or near the surface of the
Earth has a value that is approximately 9,8 m·s−2.
The force exerted by a field of strength g on an object of mass m is given by:
F = m · g (12.1)
This can be re-written in terms of g as:
This means that g can be understood to be a measure of force exerted per unit mass.
The force defined in Equation 12.1 is known as weight.
Objects in a gravitational field exert forces on each other without touching. The gravitational
force is an example of a non-contact force.
Gravity is a force and therefore must be described by a vector - so remember magnitude and
direction.


file_data: 12.4.1|Newton's Law of Universal Gravitation|282
Definition: Newton’s Law of Universal Gravitation
Every point mass attracts every other point mass by a force directed along the line connecting
the two. This force is proportional to the product of the masses and inversely proportional
to the square of the distance between them.
The magnitude of the attractive gravitational force between the two point masses, F is given
by:
where: G is the gravitational constant, m1 is the mass of the first point mass, m2 is the mass
of the second point mass and r is the distance between the two point masses.
Assuming SI units, F is measured in newtons (N), m1 and m2 in kilograms (kg), r in meters
(m), and the constant G is approximately equal to 6,67×10−11N ·m2 · kg−2. Remember that
this is a force of attraction.
For example, consider a man of mass 80 kg standing 10 m from a woman with a mass of 65 kg.
As you can see, these forces are very small.
Now consider the gravitational force between the Earth and the Moon. The mass of the Earth is
5,98×1024 kg, the mass of the Moon is 7,35×1022 kg and the Earth and Moon are 0,38×109 m
apart. The gravitational force between the Earth and Moon is:
From this example you can see that the force is very large.
These two examples demonstrate that the bigger the masses, the greater the force between them.
The 1/r2 factor tells us that the distance between the two bodies plays a role as well. The closer
two bodies are, the stronger the gravitational force between them is. We feel the gravitational
attraction of the Earth most at the surface since that is the closest we can get to it, but if we
were in outer-space, we would barely even know the Earth’s gravity existed!
Remember that
which means that every object on Earth feels the same gravitational acceleration! That means
whether you drop a pen or a book (from the same height), they will both take the same length
of time to hit the ground... in fact they will be head to head for the entire fall if you drop them
at the same time. We can show this easily by using the two equations above (Equations 12.2
and 12.3). The force between the Earth (which has the mass me) and an object of mass mo is
Since it doesn’t matter what mo is, this tells us that the acceleration on a body (due to the
Earth’s gravity) does not depend on the mass of the body. Thus all objects experience the same
gravitational acceleration. The force on different bodies will be different but the acceleration will
be the same. Due to the fact that this acceleration caused by gravity is the same on all objects
we label it differently, instead of using a we use g which we call the gravitational acceleration.


file_data: 12.4.2|Comparative Problems|284
Comparative problems involve calculation of something in terms of something else that we know.
For example, if you weigh 490 N on Earth and the gravitational acceleration on Venus is 0,903
that of the gravitational acceleration on the Earth, then you would weigh 0,903 x 490 N = 442,5 N
on Venus.
Principles for answering comparative problems
• Write out equations and calculate all quantities for the given situation
• Write out all relationships between variable from first and second case
• Write out second case
• Substitute all first case variables into second case
• Write second case in terms of first case


file_data: 12.4.3|Exercise|286


file_data: 12.5|Momentum and Impulse|287
Momentum is a physical quantity which is closely related to forces. Momentum is a property
which applies to moving objects.
Definition: Momentum
Momentum is the tendency of an object to continue to move in its direction of travel.
Momentum is calculated from the product of the mass and velocity of an object.
The momentum (symbol p) of an object of mass m moving at velocity v is:
p = m · v
According to this equation, momentum is related to both the mass and velocity of an object. A
small car travelling at the same velocity as a big truck will have a smaller momentum than the
truck. The smaller the mass, the smaller the velocity.
A car travelling at 120 km·hr−1will have a bigger momentum than the same car travelling at
60 km·hr−1. Momentum is also related to velocity; the smaller the velocity, the smaller the
momentum.
Different objects can also have the same momentum, for example a car travelling slowly can have
the same momentum as a motor cycle travelling relatively fast. We can easily demonstrate this.
Consider a car of mass 1 000 kg with a velocity of 8 m·s−1(about 30 km·hr−1). The momentum
of the car is therefore
Now consider a motor cycle of mass 250 kg travelling at 32 m·s−1 (about 115 km·hr−1). The
momentum of the motor cycle is:
Even though the motor cycle is considerably lighter than the car, the fact that the motor cy-
cle is travelling much faster than the car means that the momentum of both vehicles is the same.
From the calculations above, you are able to derive the unit for momentum as kg·m·s−1.
Momentum is also vector quantity, because it is the product of a scalar (m) with a vector (v).
This means that whenever we calculate the momentum of an object, we need to include the
direction of the momentum.


file_data: 12.5.1|Vector Nature of Momentum|290
As we have said, momentum is a vector quantity. Since momentum is a vector, the techniques
of vector addition discussed in Chapter ?? must be used to calculate the total momentum of a
system.



file_data: 12.5.2|Exercise|291


file_data: 12.5.3|Change in Momentum|291
Let us consider a tennis ball (mass = 0,1 g) that is dropped at an initial velocity of 5 m·s−1and
bounces back at a final velocity of 3 m·s−1. As the ball approaches the floor it has a momentum
that we call the momentum before the collision. When it moves away from the floor it has a
different momentum called the momentum after the collision. The bounce on the floor can be
thought of as a collision taking place where the floor exerts a force on the tennis ball to change
its momentum.
The momentum before the bounce can be calculated as follows:
Because momentum and velocity are vectors, we have to choose a direction as positive. For
this example we choose the initial direction of motion as positive, in other words, downwards is
When the tennis ball bounces back it changes direction. The final velocity will thus have a
negative value. The momentum after the bounce can be calculated as follows:
pafter = m· vf
Now let us look at what happens to the momentum of the tennis ball. The momentum changes
during this bounce. We can calculate the change in momentum as follows:
Again we have to choose a direction as positive and we will stick to our initial choice as down-
wards is positive. This means that the final momentum will have a negative number.
You will notice that this number is bigger than the previous momenta calculated. This is should
be the case as the ball needed to be stopped and then given momentum to bounce back.


file_data: 12.5.4|Exercise|293


file_data: 12.5.5|Newton's Second Law revisited|293
You have learned about Newton’s Second Law of motion earlier in this chapter. Newton’s Second
Law describes the relationship between the motion of an object and the net force on the object.
We said that the motion of an object, and therefore its momentum, can only change when a
resultant force is acting on it. We can therefore say that because a net force causes an object
to move, it also causes its momentum to change. We can now define Newton’s Second Law of
motion in terms of momentum.
Definition: Newton’s Second Law of Motion (N2)
The net or resultant force acting on an object is equal to the rate of change of momentum.



file_data: 12.5.6|Impulse|294
Impulse is the product of the net force and the time interval for which the force acts. Impulse is
defined as:

However, from Newton’s Second Law, we know that
Impulse is equal to the change in momentum of an object. From this equation we see, that
for a given change in momentum, Fnett is fixed. Thus, if Fnet is reduced, t must be in-
creased (i.e. a smaller resultant force must be applied for longer to bring about the same change
in momentum). Alternatively if t is reduced (i.e. the resultant force is applied for a shorter
period) then the resultant force must be increased to bring about the same change in momentum.


file_data: 12.5.7|Exercise|296


file_data: 12.5.8|Conservation of Momentum|297
In the absence of an external force acting on a system, momentum is conserved.
Definition: Conservation of Linear Momentum
The total linear momentum of an isolated system is constant. An isolated system has no
forces acting on it from the outside.
This means that in an isolated system the total momentum before a collision or explosion is
equal to the total momentum after the collision or explosion.
Consider a simple collision of two billiard balls. The balls are rolling on a frictionless surface and
the system is isolated. So, we can apply conservation of momentum. The first ball has a mass
m1 and an initial velocity vi1. The second ball has a mass m2 and moves towards the first ball
with an initial velocity vi2. This situation is shown in Figure 12.14.
The total momentum of the system before the collision, pi is:
After the two balls collide and move away they each have a different momentum. If the first
ball has a final velocity of vf1 and the second ball has a final velocity of vf2 then we have the
situation shown in Figure 12.15.
This system of two balls is isolated since there are no external forces acting on the balls. There-
fore, by the principle of conservation of linear momentum, the total momentum before the
collision is equal to the total momentum after the collision. This gives the equation for the
conservation of momentum in a collision of two objects,


file_data: 12.5.9|Physics in Action: Impulse|300
A very important application of impulse is improving safety and reducing injuries. In many cases,
an object needs to be brought to rest from a certain initial velocity. This means there is a
certain specified change in momentum. If the time during which the momentum changes can
be increased then the force that must be applied will be less and so it will cause less damage.
This is the principle behind arrestor beds for trucks, airbags, and bending your knees when you
jump off a chair and land on the ground.
Air-Bags in Motor Vehicles
Air bags are used in motor vehicles because they are able to reduce the effect of the force
experienced by a person during an accident. Air bags extend the time required to stop the
momentum of the driver and passenger. During a collision, the motion of the driver and passenger
carries them towards the windshield which results in a large force exerted over a short time in
order to stop their momentum. If instead of hitting the windshield, the driver and passenger hit
an air bag, then the time of the impact is increased. Increasing the time of the impact results
in a decrease in the force.
Padding as Protection During Sports
The same principle explains why wicket keepers in cricket use padded gloves or why there are
padded mats in gymnastics. In cricket, when the wicket keeper catches the ball, the padding is
slightly compressible, thus reducing the effect of the force on the wicket keepers hands. Similarly,
if a gymnast falls, the padding compresses and reduces the effect of the force on the gymnast’s
body.
Arrestor Beds for Trucks
An arrestor bed is a patch of ground that is softer than the road. Trucks use these when they
have to make an emergency stop. When a trucks reaches an arrestor bed the time interval over
which the momentum is changed is increased. This decreases the force and causes the truck to
slow down.
Follow-Through in Sports
In sports where rackets and bats are used, like tennis, cricket, squash, badminton and baseball,
the hitter is often encouraged to follow-through when striking the ball. High speed films of the
collisions between bats/rackets and balls have shown that following through increases the time
over which the collision between the racket/bat and ball occurs. This increase in the time of
the collision causes an increase in the velocity change of the ball. This means that a hitter can
cause the ball to leave the racket/bat faster by following through. In these sports, returning the
ball with a higher velocity often increases the chances of success.
Crumple Zones in Cars
Another safety application of trying to reduce the force experienced is in crumple zones in cars.
When two cars have a collision, two things can happen:
1. the cars bounce off each other, or
2. the cars crumple together.
Which situation is more dangerous for the occupants of the cars? When cars bounce off each
other, or rebound, there is a larger change in momentum and therefore a larger impulse. A
larger impulse means that a greater force is experienced by the occupants of the cars. When
cars crumple together, there is a smaller change in momentum and therefore a smaller impulse.
The smaller impulse means that the occupants of the cars experience a smaller force. Car
manufacturers use this idea and design crumple zones into cars, such that the car has a greater
chance of crumpling than rebounding in a collision. Also, when the car crumples, the change in
the car’s momentum happens over a longer time. Both these effects result in a smaller force on
the occupants of the car, thereby increasing their chances of survival.


file_data: 12.5.10|Exercise|301


file_data: 12.6|Torque and Levers|302


file_data: 12.6.1|Torque|302
This chapter has dealt with forces and how they lead to motion in a straight line. In this section,
we examine how forces lead to rotational motion.
When an object is fixed or supported at one point and a force acts on it a distance away from
the support, it tends to make the object turn. The moment of force or torque (symbol, τ read
tau) is defined as the product of the distance from the support or pivot (r) and the component
of force perpendicular to the object, 
Torque can be seen as a rotational force. The unit of torque is N·m and torque is a vector
quantity. Some examples of where torque arises are shown in Figures 12.17, 12.18 and 12.19.
This shows that there is less torque when the force is applied closer to the bolt than further
away.
Important: Loosening a bolt
If you are trying to loosen (or tighten) a bolt, apply the force on the spanner further away from
the bolt, as this results in a greater torque to the bolt making it easier to loosen.
Important: Any component of a force exerted parallel to an object will not cause the object
to turn. Only perpendicular components cause turning.
Important: Torques
The direction of a torque is either clockwise or anticlockwise. When torques are added, choose
one direction as positive and the opposite direction as negative. If equal clockwise and anti-
clockwise torques are applied to an object, they will cancel out and there will be no net turning
effect.



file_data: 12.6.2|Mechanical Advantage and Levers|305
We can use our knowlegde about the moments of forces (torque) to determine whether situations
are balanced. For example two mass pieces are placed on a seesaw as shown in Figure 12.20.
The one mass is 3 kg and the other is 6 kg. The masses are placed a distance 2 m and 1
m, respectively from the pivot. By looking at the clockwise and anti-clockwise moments, we
can determine whether the seesaw will pivot (move) or not. If the sum of the clockwise and
anti-clockwise moments is zero, the seesaw is in equilibrium (i.e. balanced).
The resultant moment is zero as the clockwise and anti-clockwise moments of force are in op-
posite directions and therefore cancel each other.
As we see in Figure 12.20, we can use different distances away from a pivot to balance two
different forces. This principle is applied to a lever to make lifting a heavy object much easier.
Definition: Lever
A lever is a rigid object that is used with an appropriate fulcrum or pivot point to multiply
the mechanical force that can be applied to another object.
Archimedes reputedly said: Give me a lever long enough and a fulcrum on which
to place it, and I shall move the world.
The concept of getting out more than the effort is termed mechanical advantage, and is one
example of the principle of moments. The lever allows to do less effort but for a greater distance.
For instance to lift a certain unit of weight with a lever with an effort of half a unit we need a
distance from the fulcrum in the effort’s side to be twice the distance of the weight’s side. It
also means that to lift the weight 1 meter we need to push the lever for 2 meter. The amount of
work done is always the same and independent of the dimensions of the lever (in an ideal lever).
The lever only allows to trade effort for distance.
Ideally, this means that the mechanical advantage of a system is the ratio of the force that
performs the work (output or load) to the applied force (input or effort), assuming there is no
friction in the system. In reality, the mechanical advantage will be less than the ideal value by
an amount determined by the amount of friction.
For example, you want to raise an object of mass 100 kg. If the pivot is placed as shown in
Figure 12.22, what is the mechanical advantage of the lever?
In order to calculate mechanical advantage, we need to determine the load and effort.
Important: Effort is the input force and load is the output force.



file_data: 12.6.3|Classes of levers|307
Class 1 levers
In a class 1 lever the fulcrum is between the effort and the load. Examples of class 1 levers are
the seesaw, crowbar and equal-arm balance. The mechanical advantage of a class 1 lever can be
increased by moving the fulcrum closer to the load.
Class 2 levers
In class 2 levers the fulcrum is at the one end of the bar, with the load closer to the fulcrum and the effort on the other end of bar. The mechanical advantage of this type of lever can be
increased by increasing the length of the bar. A bottle opener or wheel barrow are examples of
class 2 levers.
Class 3 levers
In class 3 levers the fulcrum is also at the end of the bar, but the effort is between the fulcrum
and the load. An example of this type of lever is the human arm.


file_data: 12.6.4|Exercise|308


file_data: 12.7|Summary|309


file_data: 12.8|End of Chapter exercises|310









file_data: 13|Geometrical Optics - Grade 11|327


file_data: 13.1|Introduction|327
In Grade 10, we studied how light is reflected and refracted. This chapter builds on what you
have learnt in Grade 10. You will learn about lenses, how the human eye works as well as how
telescopes and microscopes work.


file_data: 13.2|Lenses|327
In this section we will discuss properties of thin lenses. In Grade 10, you learnt about two kinds
of mirrors: concave mirrors which were also known as converging mirrors and convex mirrors
which were also known as diverging mirrors. Similarly, there are two types of lenses: converging
and diverging lenses.
We have learnt how light travels in different materials, and we are now ready to learn how we
can control the direction of light rays. We use lenses to control the direction of light. When
light enters a lens, the light rays bend or change direction as shown in Figure 13.1.
Definition: Lens
A lens is any transparent material (e.g. glass) of an appropriate shape that can take parallel
rays of incident light and either converge the rays to a point or diverge the rays from a
point.
Some lenses will focus light rays to a single point. These lenses are called converging or concave
lenses. Other lenses spread out the light rays so that it looks like they all come from the same
point. These lenses are called diverging or convex lenses. Lenses change the direction of light
rays by refraction. They are designed so that the image appears in a certain place or as a certain
size. Lenses are used in eyeglasses, cameras, microscopes, and telescopes. You also have lenses
in your eyes!
Definition: Converging Lenses
Converging lenses converge parallel rays of light and are thicker in the middle than at the
edges.
Definition: Diverging Lenses
Diverging lenses diverge parallel rays of light and are thicker at the edges than in the middle.
parallel rays of
light enter the lens
rays are focused
at the same point
(a) A converging lens will focus the rays that enter the lens
parallel rays of
light enter the lens
rays are spread out
as if they are coming
from the same point
(b) A diverging lens will spread out the rays that enter the lens
Figure 13.1: The behaviour of parallel light rays entering either a converging or diverging lens.
Examples of converging and diverging lenses are shown in Figure 13.2.
converging lenses diverging lenses
Figure 13.2: Types of lenses
Before we study lenses in detail, there are a few important terms that must be defined. Figure 13.3
shows important lens properties:
• The principal axis is the line which runs horizontally straight through the optical centre
of the lens. It is also sometimes called the optic axis.
• The optical centre (O) of a convex lens is usually the centre point of the lens. The
direction of all light rays which pass through the optical centre, remains unchanged.
• The focus or focal point of the lens is the position on the principal axis where all light
rays which run parallel to the principal axis through the lens converge (come together) at
a point. Since light can pass through the lens either from right to left or left to right,
there is a focal point on each side of the lens (F1 and F2), at the same distance from the
optical centre in each direction. (Note: the plural form of the word focus is foci.)
• The focal length (f) is the distance between the optical centre and the focal point.



file_data: 13.2.1|Converging Lenses|329
We will only discuss double convex converging lenses as shown in Figure 13.4. Converging lenses
are thinner on the outside and thicker on the inside.
Figure 13.5 shows a convex lens. Light rays traveling through a convex lens are bent towards
the principal axis. For this reason, convex lenses are called converging lenses.
Figure 13.5: Light rays bend towards each other or converge when they travel through a convex
lens. F1 and F2 are the foci of the lens.
The type of images created by a convex lens is dependent on the position of the object. We will examine the following cases:
1. the object is placed at a distance greater than 2f from the lens
2. the object is placed at a distance equal to 2f from the lens
3. the object is placed at a distance between 2f and f from the lens
4. the object is placed at a distance less than f from the lens
We examine the properties of the image in each of these cases by drawing ray diagrams. We can
find the image by tracing the path of three light rays through the lens. Any two of these rays
will show us the location of the image. You can use the third ray to check the location.

Drawing Ray Diagrams for Converging Lenses
The three rays are labelled R1, R2 and R3. The ray diagrams that follow will use this naming
convention.
1. The first ray (R1) travels from the object to the lens parallel to the principal axis. This
ray is bent by the lens and travels through the focal point.
2. Any ray travelling parallel to the principal axis is bent through the focal point.
3. If a light ray passes through a focal point before it enters the lens, then it will leave the
lens parallel to the principal axis. The second ray (R2) is therefore drawn to pass through
the focal point before it enters the lens.
4. A ray that travels through the centre of the lens does not change direction. The third ray
(R3) is drawn through the centre of the lens.
5. The point where all three of the rays (R1, R2 and R3) intersect is the image of the point
where they all started. The image will form at this point.
CASE 1:
Object placed at a distance greater than 2f from the lens
Figure 13.7: An object is placed at a distance greater than 2f away from the converging lens.
Three rays are drawn to locate the image, which is real, smaller than the object and inverted.
We can locate the position of the image by drawing our three rays. R1 travels from the object
to the lens parallel to the principal axis and is bent by the lens and then travels through the focal
point. R2 passes through the focal point before it enters the lens and therefore must leave the
lens parallel to the principal axis. R3 travels through the center of the lens and does not change
direction. The point where R1, R2 and R3 intersect is the image of the point where they all
started.
The image of an object placed at a distance greater than 2f from the lens is upside down or
inverted. This is because the rays which began at the top of the object, above the principal
axis, after passing through the lens end up below the principal axis. The image is called a real
image because it is on the opposite side of the lens to the object and you can trace all the light
rays directly from the image back to the object.
The image is also smaller than the object and is located closer to the lens than the object.
Important: In reality, light rays come from all points along the length of the object. In ray
diagrams we only draw three rays (all starting at the top of the object) to keep the diagram
clear and simple.
CASE 2:
Object placed at a distance equal to 2f from the lens
Figure 13.8: An object is placed at a distance equal to 2f away from the converging lens. Three
rays are drawn to locate the image, which is real, the same size as the object and inverted.
We can locate the position of the image by drawing our three rays. R1 travels from the object
to the lens parallel to the principal axis and is bent by the lens and then travels through the focal
point. R2 passes through the focal point before it enters the lens and therefore must leave the
lens parallel to the principal axis. R3 travels through the center of the lens and does not change
direction. The point where R1, R2 and R3 intersect is the image of the point where they all
started.
The image of an object placed at a distance equal to 2f from the lens is upside down or inverted.
This is because the rays which began at the top of the object, above the principal axis, after
passing through the lens end up below the principal axis. The image is called a real image
because it is on the opposite side of the lens to the object and you can trace all the light rays
directly from the image back to the object.
The image is the same size as the object and is located at a distance 2f away from the lens.
CASE 3:
Object placed at a distance between 2f and f from the lens
Figure 13.9: An object is placed at a distance between 2f and f away from the converging lens.
Three rays are drawn to locate the image, which is real, larger than the object and inverted.
We can locate the position of the image by drawing our three rays. R1 travels from the object
to the lens parallel to the principal axis and is bent by the lens and then travels through the focal
point. R2 passes through the focal point before it enters the lens and therefore must leave the
lens parallel to the principal axis. R3 travels through the center of the lens and does not change
direction. The point where R1, R2 and R3 intersect is the image of the point where they all
started.
The image of an object placed at a distance between 2f and f from the lens is upside down
or inverted. This is because the rays which began at the top of the object, above the principal
axis, after passing through the lens end up below the principal axis. The image is called a real
image because it is on the opposite side of the lens to the object and you can trace all the light
rays directly from the image back to the object.
The image is larger than the object and is located at a distance greater than 2f away from the
lens.
CASE 4:
Object placed at a distance less than f from the lens
Figure 13.10: An object is placed at a distance less than f away from the converging lens. Three
rays are drawn to locate the image, which is virtual, larger than the object and upright.
We can locate the position of the image by drawing our three rays. R1 travels from the object
to the lens parallel to the principal axis and is bent by the lens and then travels through the focal
point. R2 passes through the focal point before it enters the lens and therefore must leave the
lens parallel to the principal axis. R3 travels through the center of the lens and does not change
direction. The point where R1, R2 and R3 intersect is the image of the point where they all
started.
The image of an object placed at a distance less than f from the lens is upright. The image is
called a virtual image because it is on the same side of the lens as the object and you cannot
trace all the light rays directly from the image back to the object.
The image is larger than the object and is located further away from the lens than the object.
Extension: The thin lens equation and magnification
The Thin Lens Equation
We can find the position of the image of a lens mathematically as there is
mathematical relation between the object distance, image distance, and focal length.
The equation is:
where f is the focal length, do is the object distance and di is the image distance.
The object distance do is the distance from the object to the lens. do is positive
if the object is on the same side of the lens as the light rays enter the lens. This should make sense: we expect the light rays to travel from the object to the lens.
The image distance di is the distance from the lens to the image. Unlike mirrors,
which reflect light back, lenses refract light through them. We expect to find the
image on the same side of the lens as the light leaves the lens. If this is the case,
then di is positive and the image is real (see Figure 13.9). Sometimes the image will
be on the same side of the lens as the light rays enter the lens. Then di is negative
and the image is virtual (Figure 13.10). If we know any two of the three quantities
above, then we can use the Thin Lens Equation to solve for the third quantity.
Magnification
It is possible to calculate the magnification of an image. The magnification is
how much bigger or smaller the image is than the object.
where m is the magnification, do is the object distance and di is the image distance.
If di and do are both positive, the magnification is negative. This means the
image is inverted, or upside down. If di is negative and do is positive, then the
image is not inverted, or right side up. If the absolute value of the magnification is
greater than one, the image is larger than the object. For example, a magnification
of -2 means the image is inverted and twice as big as the object.



file_data: 13.2.2|Diverging Lenses|340
We will only discuss double concave diverging lenses as shown in Figure 13.11. Concave lenses
are thicker on the outside and thinner on the inside.
Figure 13.12 shows a concave lens with light rays travelling through it. You can see that concave
lenses have the opposite curvature to convex lenses. This causes light rays passing through a
concave lens to diverge or be spread out away from the principal axis. For this reason, concave
lenses are called diverging lenses. Images formed by concave lenses are always virtual.
Unlike converging lenses, the type of images created by a concave lens is not dependent on the
position of the object. The image is always upright, smaller than the object, and located closer
to the lens than the object.
We examine the properties of the image by drawing ray diagrams. We can find the image by
tracing the path of three light rays through the lens. Any two of these rays will show us the location of the image. You can use the third ray to check the location, but it is not necessary
to show it on your diagram.
Figure 13.12: Light rays bend away from each other or diverge when they travel through a
concave lens. F1 and F2 are the foci of the lens.
Drawing Ray Diagrams for Diverging Lenses
Draw the three rays starting at the top of the object.
1. Ray R1 travels parallel to the principal axis. The ray bends and lines up with a focal
point. However, the concave lens is a diverging lens, so the ray must line up with the focal
point on the same side of the lens where light rays enter it. This means that we must
project an imaginary line backwards through that focal point (F1) (shown by the dashed
line extending from R1).
2. Ray R2 points towards the focal point F2 on the opposite side of the lens. When it hits
the lens, it is bent parallel to the principal axis.
3. Ray R3 passes through the optical center of the lens. Like for the convex lens, this ray
passes through with its direction unchanged.
4. We find the image by locating the point where the rays meet. Since the rays diverge,
they will only meet if projected backward to a point on the same side of the lens as the
object. This is why concave lenses always have virtual images. (Since the light rays do
not actually meet at the image, the image cannot be real.)
Figure 13.13 shows an object placed at an arbitrary distance from the diverging lens.
We can locate the position of the image by drawing our three rays for a diverging lens.
Figure 13.13 shows that the image of an object is upright. The image is called a virtual image
because it is on the same side of the lens as the object.
The image is smaller than the object and is closer to the lens than the object.
Figure 13.13: Three rays are drawn to locate the image, which is virtual, smaller than the object
and upright.



file_data: 13.2.3|Summary of Image Properties|343


file_data: 13.3|The Human Eye|344


file_data: 13.3.1|Structure of the Eye|345
Eyesight begins with lenses. As light rays enter your eye, they pass first through the cornea and
then through the crystalline lens. These form a double lens system and focus light rays onto
the back wall of the eye, called the retina. Rods and cones are nerve cells on the retina that
transform light into electrical signals. These signals are sent to the brain via the optic nerve.
A cross-section of the eye is shown in Figure 13.14.
For clear vision, the image must be formed right on the retina, not in front of or behind it. To
accomplish this, you may need a long or short focal length, depending on the object distance.
How do we get the exact right focal length we need? Remember that the lens system has two
parts. The cornea is fixed in place but the crystalline lens is flexible – it can change shape.
When the shape of the lens changes, its focal length also changes. You have muscles in your eye
called ciliary muscles that control the shape of the crystalline lens. When you focus your gaze
on something, you are squeezing (or relaxing) these muscles. This process of accommodation
changes the focal length of the lens and allows you to see an image clearly.
The lens in the eye creates a real image that is smaller than the object and is inverted


file_data: 13.3.2|Defects of Vision|346
In a normal eye the image is focused on the retina.
If the muscles in the eye are unable to accommodate adequately, the image will not be in focus.
This leads to problems with vision. There are three basic conditions that arise:
1. short-sightedness
2. long-sightedness
3. astigmatism
Short-sightedness
Short-sightedness or myopia is a defect of vision which means that the image is focused in front
of the retina. Close objects are seen clearly but distant objects appear blurry. This condition
can be corrected by placing a diverging lens in front of the eye. The diverging lens spreads out
light rays before they enter the eye. The situation for short-sightedness and how to correct it is
shown in Figure 13.17.
Long-sightedness
Long-sightedness or hyperopia is a defect of vision which means that the image is focused in
behind the retina. People with this condition can see distant objects clearly, but not close ones.
A converging lens in front of the eye corrects long-sightedness by converging the light rays slightly
before they enter the eye. Reading glasses are an example of a converging lens used to correct
long-sightedness.
Astigmatism
Astigmatism is characterised by a cornea or lens that is not spherical, but is more curved in one
plane compared to another. This means that horizontal lines may be focused at a different point
to vertical lines. Astigmatism is corrected by a special lens, which has different focal lengths in
the vertical and horizontal planes.




file_data: 13.4|Gravitational Lenses|347
Einstein’s Theory of General Relativity predicts that light that passes close to very heavy objects
like galaxies, black holes and massive stars will be bent. These massive objects therefore act as
a kind of lens that is known as a gravitational lens. Gravitational lenses distort and change the
apparent position of the image of stars.
If a heavy object is acting as a gravitational lens, then an observer from Earth will see many
images of a distant star (Figure 13.19).


file_data: 13.5|Telescopes|347
We have seen how a simple lens can be used to correct eyesight. Lenses and mirrors are also
combined to magnify (or make bigger) objects that are far away.
Telescopes use combinations of lenses to gather and focus light. However, telescopes collect light
from objects that are large but far away, like planets and galaxies. For this reason, telescopes
are the tools of astronomers. Astronomy is the study of objects outside the Earth, like stars,
planets, galaxies, comets, and asteroids.
Usually the object viewed with a telescope is very far away. There are two types of objects: those
with a detectable diameter, such as the moon, and objects that appear as points of light, like
stars.
There are many kinds of telescopes, but we will look at two basic types: reflecting and refracting.



file_data: 13.5.1|Refracting Telescopes|347
A refracting telescope like the one pictured in Figure 13.20 uses two convex lenses to enlarge
an image. The refracting telescope has a large primary lens with a long focal length to gather a lot of light. The lenses of a refracting telescope share a focal point. This ensures that parallel
rays entering the telescope are again parallel when they reach your eye.


file_data: 13.5.2|Reflecting Telescopes|348
Some telescopes use mirrors as well as lenses and are called reflecting telescopes. Specifically,
a reflecting telescope uses a convex lens and two mirrors to make an object appear larger.
(Figure 13.21.)
Light is collected by the primary mirror, which is large and concave. Parallel rays traveling toward
this mirror are reflected and focused to a point. The secondary plane mirror is placed within the
focal length of the primary mirror. This changes the direction of the light. A final eyepiece lens
diverges the rays so that they are parallel when they reach your eye.


file_data: 13.5.3|Southern African Large Telescope|348
The Southern African Large Telescope (SALT) is the largest single optical telescope in the
southern hemisphere, with a hexagonal mirror array 11 metres across. SALT is located in
Sutherland in the Northern Cape. SALT is able to record distant stars, galaxies and quasars a
billion times too faint to be seen with the unaided eye. This is equivalent to a person being
able to see a candle flame at on the moon.
SALT was completed in 2005 and is a truly international initiative, because the money to build
it came from South Africa, the United States, Germany, Poland, the United Kingdom and New
Zealand.


file_data: 13.6|Microscopes|349
We have seen how lenses and mirrors are combined to magnify objects that are far away in a
telescope. Lenses can also be used to make very small objects bigger.
Figure 13.10 shows that when an object is placed at a distance less than f from the lens, the
image formed is virtual, upright and is larger than the object. This set-up is a simple magnifier.
If you want to look at something very small, two lenses may work better than one. Microscopes
and telescopes often use two lenses to make an image large enough to see.
A compound microscope uses two lenses to achieve high magnification (Figure 13.22). Both
lenses are convex, or converging. Light from the object first passes through the objective lens.
The lens that you look through is called the eyepiece. The focus of the system can be
adjusted by changing the length of the tube between the lenses.
Drawing a Ray Diagram for a Two-Lens System
You already have all the tools to analyze a two-lens system. Just consider one lens at a time.
1. Use ray tracing or the lens equation to find the image for the first lens.
2. Use the image of the first lens as the object of the second lens.
3. To find the magnification, multiply:


file_data: 13.7|Summary|351


file_data: 13.8|Exercises|352




file_data: 14|Longitudinal Waves - Grade 11|355



file_data: 14.1|Introduction|355
In Grade 10 we studied pulses and waves. We looked at transverse waves more closely. In this
chapter we look at another type of wave called longitudinal waves. In transverse waves, the
motion of the particles in the medium were perpendicular to the direction of the wave. In
longitudinal waves, the particles in the medium move parallel (in the same direction as) to the
motion of the wave. Examples of transverse waves are water waves or light waves. An example
of a longitudinal wave is a sound wave.




file_data: 14.2|What is a longitudinal wave?|355
Definition: Longitudinal waves
A longitudinal wave is a wave where the particles in the medium move parallel to the
direction of propagation of the wave.
When we studied transverse waves we looked at two different motions: the motion of the
particles of the medium and the motion of the save itself. We will do the same for longitudinal
waves.
The question is how do we construct such a wave?
To create a transverse wave, we flick the end of for example a rope up and down. The particles
move up and down and return to their equilibrium position. The wave moves from left to right
and will be displaced.
A longitudinal wave is seen best in a spring that is hung from a ceiling. Do the following
investigation to find out more about longitudinal waves.
From the investigation you will have noticed that the disturbance moves in the same direction
as the direction in which the spring was pulled. The spring was pulled up and down and the
wave also moved up and down. The ribbon in the investigation represents one particle in the
medium. The particles in the medium move in the same direction as the wave. The ribbon
moves from rest upwards, then back to its original position, then down and then back to its
original position.



file_data: 14.3|Characteristics of Longitudinal Waves|356
As for transverse waves the following can be defined for longitudinal waves: wavelength,
amplitude, period, frequency and wave speed. However instead of peaks and troughs,
longitudinal waves have compressions and rarefactions.
Definition: Compression
A compression is a region in a longitudinal wave where the particles are closer together.
Definition: Rarefaction
A rarefaction is a region in a longitudinal wave where the particles are further apart.


file_data: 14.3.1|Compression and Rarefaction|356
As seen in Figure 14.2, there are regions where the medium is compressed and other regions
where the medium is spread out in a longitudinal wave.
The region where the medium is compressed is known as a compression and the region where
the medium is spread out is known as a rarefaction.



file_data: 14.3.2|Wavelength and Amplitude|357
Definition: Wavelength
The wavelength in a longitudinal wave is the distance between two consecutive points that
are in phase.
The wavelength in a longitudinal wave refers to the distance between two consecutive
compressions or between two consecutive rarefactions.
Definition: Amplitude
The amplitude is the maximum displacement from a position of rest.
The amplitude is the distance from the equilibrium position of the medium to a compression or
a rarefaction.


file_data: 14.3.3|Period and Frequency|357
Definition: Period
The period of a wave is the time taken by the wave to move one wavelength.
Definition: Frequency
The frequency of a wave is the number of wavelengths per second.
The period of a longitudinal wave is the time taken by the wave to move one wavelength. As
for transverse waves, the symbol T is used to represent period and period is measured in
seconds (s).
The frequency f of a wave is the number of wavelengths per second. Using this definition and
the fact that the period is the time taken for 1 wavelength, we can define:


file_data: 14.3.4|Speed of a Longitudinal Wave|358
The speed of a longitudinal wave is defined as:
v = f · λ
where
v = speed in m.s−1
f = frequency in Hz
λ = wavelength in m



file_data: 14.4|Graphs of Particle Position, Displacement, Velocity and Acceleration|359
When a longitudinal wave moves through the medium, the particles in the medium only move
back and forth relative to the direction of motion of the wave. We can see this in Figure 14.4
which shows the motion of the particles in a medium as a longitudinal wave moves through the
medium.
Figure 14.4: Positions of particles in a medium at different times as a longitudinal wave moves
through it. The wave moves to the right. The dashed line shows the equilibrium position of
particle 0.
Important: A particle in the medium only moves back and forth when a longitudinal wave
moves through the medium.
As in Chapter 6, we can draw a graph of the particle’s position as a function of time. For the
wave shown in Figure 14.4, we can draw the graph shown in Figure 14.5 for particle 0. The
graph for each of the other particles will be identical.
Figure 14.5: Graph of particle displacement as a function of time for the longitudinal wave shown
in Figure 14.4.
The graph of the particle’s velocity as a function of time is obtained by taking the gradient of
the position vs. time graph. The graph of velocity vs. time for the position vs. time graph
shown in Figure 14.5 is shown is Figure 14.6.
The graph of the particle’s acceleration as a function of time is obtained by taking the gradient
of the velocity vs. time graph. The graph of acceleration vs. time for the position vs. time
graph shown in Figure 14.5 is shown is Figure 14.7.


file_data: 14.5|Sound Waves|360
Sound waves coming from a tuning fork cause the tuning fork to vibrate and push against the
air particles in front of it. As the air particles are pushed together a compression is formed.
The particles behind the compression move further apart causing a rarefaction. As the particles
continue to push against each other, the sound wave travels through the air. Due to this
motion of the particles, there is a constant variation in the pressure in the air. Sound waves are
therefore pressure waves. This means that in media where the particles are closer together,
sound waves will travel quicker.
Sound waves travel faster through liquids, like water, than through the air because water is
denser than air (the particles are closer together). Sound waves travel faster in solids than in
liquids.
Figure 14.8: Sound waves are pressure waves and need a medium through which to travel.
Important: A sound wave is different from a light wave.
• A sound wave is produced by an oscillating object while a light wave is not.
• A sound wave cannot be diffracted while a light wave can be diffracted.
Also, because a sound wave is a mechanical wave (i.e. that it needs a medium) it is not
capable of traveling through a vacuum, whereas a light wave can travel through a vacuum.
Important: A sound wave is a pressure wave. This means that regions of high pressure
(compressions) and low pressure (rarefactions) are created as the sound source vibrates.
These compressions and rarefactions arise because sound vibrates longitudinally and the
longitudinal motion of air produces pressure fluctuations.
Sound will be studied in more detail in Chapter 15.



file_data: 14.6|Seismic Waves|361
Seismic waves are waves from vibrations in the Earth (core, mantle, oceans). Seismic waves
also occur on other planets, for example the moon and can be natural (due to earthquakes,
volcanic eruptions or meteor strikes) or man-made (due to explosions or anything that hits the
earth hard). Seismic P-waves (P for pressure) are longitudinal waves which can travel through
solid and liquid.


file_data: 14.7|Summary - Longitudinal Waves|361


file_data: 14.8|Exercises - Longitudinal Waves|362




file_data: 15|Sound - Grade 11|363


file_data: 15.1|Introduction|363
Now that we have studied the basics of longitudinal waves, we are ready to study sound waves
in detail.
Have you ever thought about how amazing your sense of hearing is? It is actually pretty
remarkable. There are many types of sounds: a car horn, a laughing baby, a barking dog, and
somehow your brain can sort it all out. Though it seems complicated, it is rather simple to
understand once you learn a very simple fact. Sound is a wave. So you can use everything you
know about waves to explain sound.


file_data: 15.2|Characteristics of a Sound Wave|363
Since sound is a wave, we can relate the properties of sound to the properties of a wave. The
basic properties of sound are: pitch, loudness and tone.
Figure 15.1: Pitch and loudness of sound. Sound B has a lower pitch (lower frequency) than
Sound A and is softer (smaller amplitude) than Sound C.


file_data: 15.2.1|Pitch|364
The frequency of a sound wave is what your ear understands as pitch. A higher frequency
sound has a higher pitch, and a lower frequency sound has a lower pitch. In Figure 15.1 sound
A has a higher pitch than sound B. For instance, the chirp of a bird would have a high pitch,
but the roar of a lion would have a low pitch.
The human ear can detect a wide range of frequencies. Frequencies from 20 to 20 000 Hz are
audible to the human ear. Any sound with a frequency below 20 Hz is known as an infrasound
and any sound with a frequency above 20 000 Hz is known as an ultrasound.
Table 15.1 lists the ranges of some common animals compared to humans.




file_data: 15.2.2|Loudness|364
The amplitude of a sound wave determines its loudness or volume. A larger amplitude means a
louder sound, and a smaller amplitude means a softer sound. In Figure 15.1 sound C is louder
than sound B. The vibration of a source sets the amplitude of a wave. It transmits energy into
the medium through its vibration. More energetic vibration corresponds to larger amplitude.
The molecules move back and forth more vigorously.
The loudness of a sound is also determined by the sensitivity of the ear. The human ear is more
sensitive to some frequencies than to others. Loudness thus depends on both the amplitude of
a sound wave and its frequency whether it lies in a region where the ear is more or less sensitive.




file_data: 15.2.3|Tone|364
Tone is a measure of the quality of the sound wave. For example, the quality of the sound
produced in a particular musical instruments depends on which harmonics are superposed and
in which proportions. The harmonics are determined by the standing waves that are produced
in the instrument. Chapter 16 will explain the physics of music in greater detail.
The quality (timbre) of the sound heard depends on the pattern of the incoming vibrations, i.e.
the shape of the sound wave. The more irregular the vibrations, the more jagged is the shape
of the sound wave and the harsher is the sound heard.



file_data: 15.3|Speed of Sound|365
The speed of sound depends on the medium the sound is travelling in. Sound travels faster in
solids than in liquids, and faster in liquids than in gases. This is because the density of solids is
higher than that of liquids which means that the particles are closer together. Sound can be
transmitted more easily.
The speed of sound also depends on the temperature of the medium. The hotter the medium
is, the faster its particles move and therefore the quicker the sound will travel through the
medium. When we heat a substance, the particles in that substance have more kinetic energy
and vibrate or move faster. Sound can therefore be transmitted more easily and quickly in
hotter substances.
Sound waves are pressure waves. The speed of sound will therefore be influenced by the
pressure of the medium through which it is travelling. At sea level the air pressure is higher
than high up on a mountain. Sound will travel faster at sea level where the air pressure is
higher than it would at places high above sea level.
Definition: Speed of sound
The speed of sound in air, at sea level, at a temperature of 21◦C and under normal atmo-
spheric conditions, is 344 m·s−1.



file_data: 15.4|Physics of the Ear and Hearing|365
The human ear is divided into three main sections: the outer, middle, and inner ear. Let’s
follow the journey of a sound wave from the pinna to the auditory nerve which transmits a
signal to the brain. The pinna is the part of the ear we typically think of when we refer to the
ear. Its main function is to collect and focus an incident sound wave. The wave then travels
through the ear canal until it meets the eardrum. The pressure fluctuations of the sound wave
make the eardrum vibrate. The three very small bones of the middle ear, the malleus
(hammer), the incus (anvil), and the stapes (stirrup), transmit the signal through to the elliptical window. The elliptical window is the beginning of the inner ear. From the elliptical
window the sound waves are transmitted through the liquid in the inner ear and interpreted as
sounds by the brain. The inner ear, made of the semicircular canals, the cochlea, and the
auditory nerve, is filled with fluid. The fluid allows the body to detect quick movements and
maintain balance. The snail-shaped cochlea is covered in nerve cells. There are more than 25
000 hairlike nerve cells. Different nerve cells vibrate with different frequencies. When a nerve
cell vibrates, it releases electrical impulses to the auditory nerve. The impulses are sent to the
brain through the auditory nerve and understood as sound.



file_data: 15.4.1|Intensity of Sound|366
Intensity is one indicator of amplitude. Intensity is the energy transmitted over a unit of area
each second.
Extension: Intensity
Intensity is defined as:
Intensity =
energy
time × area
=
power
area
By the definition of intensity, we can see that the units of intensity are
Joules
s · m2 =
Watts
m2
The unit of intensity is the decibel (symbol: dB). This reduces to an SI equivalent of W· m−2.
The threshold of hearing is 10−12 W· m−2. Below this intensity, the sound is too soft for the
ear to hear. The threshold of pain is 1.0 W· m−2. Above this intensity a sound is so loud it
becomes uncomfortable for the ear.
Notice that there is a factor of 1012 between the thresholds of hearing and pain. This is one
reason we define the decibel (dB) scale.
Extension: dB Scale
The intensity in dB of a sound of intensity I, is given by:
β = 10 log
I
Io
Io = 10−12 W· m−2 (15.1)
In this way we can compress the whole hearing intensity scale into a range from 0 dB to 120 dB.
Notice that there are sounds which exceed the threshold of pain. Exposure to these sounds can
cause immediate damage to hearing. In fact, exposure to sounds from 80 dB and above can
damage hearing over time. Measures can be taken to avoid damage, such as wearing earplugs
or ear muffs. Limiting exposure time and increasing distance between you and the source are
also important steps to protecting your hearing.


file_data: 15.5|Ultrasound|367
Ultrasound is sound with a frequency that is higher than 20 kHz. Some animals, such as dogs,
dolphins, and bats, have an upper limit that is greater than that of the human ear and can hear
ultrasound.
The most common use of ultrasound is to create images, and has industrial and medical
applications. The use of ultrasound to create images is based on the reflection and
transmission of a wave at a boundary. When an ultrasound wave travels inside an object that is
made up of different materials such as the human body, each time it encounters a boundary,
e.g. between bone and muscle, or muscle and fat, part of the wave is reflected and part of it is
transmitted. The reflected rays are detected and used to construct an image of the object.
Ultrasound in medicine can visualise muscle and soft tissue, making them useful for scanning
the organs, and is commonly used during pregnancy. Ultrasound is a safe, non-invasive method
of looking inside the human body.
Ultrasound sources may be used to generate local heating in biological tissue, with applications
in physical therapy and cancer treatment. Focussed ultrasound sources may be used to break
up kidney stones.
Ultrasonic cleaners, sometimes called supersonic cleaners, are used at frequencies from 20-40
kHz for jewellery, lenses and other optical parts, watches, dental instruments, surgical
instruments and industrial parts. These cleaners consist of containers with a fluid in which the
object to be cleaned is placed. Ultrasonic waves are then sent into the fluid. The main
mechanism for cleaning action in an ultrasonic cleaner is actually the energy released from the
collapse of millions of microscopic bubbles occurring in the liquid of the cleaner.
Ultrasound generator/speaker systems are sold with claims that they frighten
away rodents and insects, but there is no scientific evidence that the devices
work; controlled tests have shown that rodents quickly learn that the speakers
are harmless.
In echo-sounding the reflections from ultrasound pulses that are bounced off
objects (for example the bottom of the sea, fish etc.) are picked up. The
reflections are timed and since their speed is known, the distance to the object
can be found. This information can be built into a picture of the object that
reflects the ultrasound pulses.



file_data: 15.6|SONAR|368
Ships on the ocean make use of the reflecting properties of sound waves to determine the
depth of the ocean. A sound wave is transmitted and bounces off the seabed. Because the
speed of sound is known and the time lapse between sending and receiving the sound can be
measured, the distance from the ship to the bottom of the ocean can be determined, This is
called sonar, which stands from Sound Navigation And Ranging.



file_data: 15.6.1|Echolocation|368
Animals like dolphins and bats make use of sounds waves to find their way. Just like ships on
the ocean, bats use sonar to navigate. Ultrasound waves that are sent out are reflected off the
objects around the animal. Bats, or dolphins, then use the reflected sounds to form a “picture”
of their surroundings. This is called echolocation.



file_data: 15.7|Summary|369


file_data: 15.8|Exercises|369





file_data: 16|The Physics of Music - Grade 11|373


file_data: 16.1|Introduction|373
What is your favorite musical instrument? How do you play it? Do you pluck a string, like a
guitar? Do you blow through it, like a flute? Do you hit it, like a drum? All of these work by
making standing waves. Each instrument has a unique sound because of the special waves
made in it. These waves could be in the strings of a guitar or violin. They could also be in the
skin of a drum or a tube of air in a trumpet. These waves are picked up by the air and later
reach your ear as sound.
In Grade 10, you learned about standing waves and boundary conditions. We saw a rope that
was:
• fixed at both ends
• fixed at one end and free at the other
We also saw a pipe:
• closed at both ends
• open at both ends
• open at one end, closed at the other
String and wind instruments are good examples of standing waves on strings and pipes.
One way to describe standing waves is to count nodes. Recall that a node is a point on a string
that does not move as the wave changes. The anti-nodes are the highest and lowest points on
the wave. There is a node at each end of a fixed string. There is also a node at the closed end
of a pipe. But an open end of a pipe has an anti-node.
What causes a standing wave? There are incident and reflected waves traveling back and forth
on our string or pipe. For some frequencies, these waves combine in just the right way so that
the whole wave appears to be standing still. These special cases are called harmonic
frequencies, or harmonics. They depend on the length and material of the medium.
Definition: Harmonic
A harmonic frequency is a frequency at which standing waves can be made.



file_data: 16.2|Standing Waves in String Instruments|373
Let us look at a basic ”instrument”: a string pulled tight and fixed at both ends. When you
pluck the string, you hear a certain pitch. This pitch is made by a certain frequency. What
causes the string to emit sounds at this pitch?
You have learned that the frequency of a standing wave depends on the length of the wave.
The wavelength depends on the nodes and anti-nodes. The longest wave that can ”fit” on the
string is shown in Figure 16.1. This is called the fundamental or natural frequency of the
string. The string has nodes at both ends. The wavelength of the fundamental is twice the
length of the string.
Now put your finger on the center of the string. Hold it down gently and pluck it. The
standing wave now has a node in the middle of the string. There are three nodes. We can fit a
whole wave between the ends of the string. This means the wavelength is equal to the length
of the string. This wave is called the first harmonic. As we add more nodes, we find the second
harmonic, third harmonic, and so on. We must keep the nodes equally spaced or we will lose
our standing wave.
You should have found this formula:
λ =
2L
n − 1
Here, n is the number of nodes. L is the length of the string. The frequency f is:
f =
v
λ
Here, v is the velocity of the wave. This may seem confusing. The wave is a standing wave, so
how can it have a velocity? But one standing wave is made up of many waves that travel back
and forth on the string. Each of these waves has the same velocity. This speed depends on the
mass and tension of the string.
Extension: Guitar
Guitars use strings with high tension. The length, tension and mass of the
strings affect the pitches you hear. High tension and short strings make high
frequencies; Low tension and long strings make low frequencies. When a string is
first plucked, it vibrates at many frequencies. All of these except the harmonics are
quickly filtered out. The harmonics make up the tone we hear.
The body of a guitar acts as a large wooden soundboard. Here is how a
soundboard works: the body picks up the vibrations of the strings. It then passes
these vibrations to the air. A sound hole allows the soundboard of the guitar to
vibrate more freely. It also helps sound waves to get out of the body.
The neck of the guitar has thin metal bumps on it called frets. Pressing a
string against a fret shortens the length of that string. This raises the natural
frequency and the pitch of that string.
Most guitars use an ”equal tempered” tuning of 12 notes per octave. A 6
string guitar has a range of 4 1
2 octaves with pitches from 82.407 Hz (low E) to
2093 kHz (high C). Harmonics may reach over 20 kHz, in the inaudible range.
Extension: Piano
Let us look at another stringed instrument: the piano. The piano has strings
that you can not see. When a key is pressed, a felt-tipped hammer hits a string
inside the piano. The pitch depends on the length, tension and mass of the string.
But there are many more strings than keys on a piano. This is because the short
and thin strings are not as loud as the long and heavy strings. To make up for this,
the higher keys have groups of two to four strings each.
The soundboard in a piano is a large cast iron plate. It picks up vibrations from
the strings. This heavy plate can withstand over 200 tons of pressure from string
tension! Its mass also allows the piano to sustain notes for long periods of time.
The piano has a wide frequency range, from 27,5 Hz (low A) to 4186,0 Hz
(upper C). But these are just the fundamental frequencies. A piano plays complex,
rich tones with over 20 harmonics per note. Some of these are out of the range of
human hearing. Very low piano notes can be heard mostly because of their higher
harmonics.



file_data: 16.3|Standing Waves in Wind Instruments|377
A wind instrument is an instrument that is usually made with a a pipe or thin tube. Examples
of wind instruments are recorders, clarinets, flutes, organs etc.
When one plays a wind instrument, the air that is pushed through the pipe vibrates and
standing waves are formed. Just like with strings, the wavelengths of the standing waves will
depend on the length of the pipe and whether it is open or closed at each end. Let’s consider
each of the following situations:
• A pipe with both ends open, like a flute or organ pipe.
• A pipe with one end open and one closed, like a clarinet.
If you blow across a small hole in a pipe or reed, it makes a sound. If both ends are open,
standing waves will form according to figure 16.2. You will notice that there is an anti-node at
each end. In the next activity you will find how this affects the wavelengths.
The formula is different because there are more anti-nodes than nodes. The right formula is:
Here, n is still the number of nodes.
A long wavelength has a low frequency and low pitch. If you took your pipe from the last
example and covered one end, you should hear a much lower note! Also, the wavelengths of
the harmonics for this tube are not integer multiples of each other.
Extension: Musical Scale
The 12 tone scale popular in Western music took centuries to develop. This
scale is also called the 12-note Equal Tempered scale. It has an octave divided into
12 steps. (An octave is the main interval of most scales. If you double a frequency,
you have raised the note one octave.) All steps have equal ratios of frequencies.
But this scale is not perfect. If the octaves are in tune, all the other intervals are
slightly mistuned. No interval is badly out of tune. But none is perfect.
For example, suppose the base note of a scale is a frequency of 110 Hz ( a low
A). The first harmonic is 220 Hz. This note is also an A, but is one octave higher.
The second harmonic is at 330 Hz (close to an E). The third is 440 Hz (also an A).
But not all the notes have such simple ratios. Middle C has a frequency of about
262 Hz. This is not a simple multiple of 110 Hz. So the interval between C and A
is a little out of tune.
Many other types of tuning exist. Just Tempered scales are tuned so that all
intervals are simple ratios of frequencies. There are also equal tempered scales with
more or less notes per octave. Some scales use as many as 31 or 53 notes.


file_data: 16.4|Resonance|382
Resonance is the tendency of a system to vibrate at a maximum amplitude at the natural
frequency of the system.
Resonance takes place when a system is made to vibrate at its natural frequency as a result of
vibrations that are received from another source of the same frequency. In the following
investigation you will measure the speed of sound using resonance.
Interesting fact: Soldiers march out of time on bridges to avoid stimulating the bridge to
vibrate at its natural frequency.
From the investigation you will notice that the column of air will make a sound at a certain
length. This is where resonance takes place.



file_data: 16.5|Music and Sound Quality|384
In the sound chapter, we referred to the quality of sound as its tone. What makes the tone of a
note played on an instrument? When you pluck a string or vibrate air in a tube, you hear
mostly the fundamental frequency. Higher harmonics are present, but are fainter. These are
called overtones. The tone of a note depends on its mixture of overtones. Different
instruments have different mixtures of overtones. This is why the same note sounds different
on a flute and a piano.
Let us see how overtones can change the shape of a wave:
The resultant waveform is very different from the fundamental frequency. Even though the two
waves have the same main frequency, they do not sound the same!



file_data: 16.6|Summary - The Physics of Music|385


file_data: 16.7|End of Chapter Exercises|386




file_data: 17|Electrostatics - Grade 11|387


file_data: 17.1|Introduction|387
In Grade 10, you learnt about the force between charges. In this chapter you will learn exactly
how to determine this force and about a basic law of electrostatics.



file_data: 17.2|Forces between charges - Coulomb's Law|387
Like charges repel each other while opposite charges attract each other. If the charges are at
rest then the force between them is known as the electrostatic force. The electrostatic force
between charges increases when the magnitude of the charges increases or the distance
between the charges decreases.
The electrostatic force was first studied in detail by Charles Coulomb around 1784. Through
his observations he was able to show that the electrostatic force between two point-like charges
is inversely proportional to the square of the distance between the objects. He also discovered
that the force is proportional to the product of the charges on the two objects.
F ∝
Q1Q2
r2 ,
where Q1 is the charge on the one point-like object, Q2 is the charge on the second, and r is
the distance between the two. The magnitude of the electrostatic force between two point-like
charges is given by Coulomb’s Law.
Definition: Coulomb’s Law
Coulomb’s Law states that the magnitude of the electrostatic force between two point
charges is directly proportional to the magnitudes of each charge and inversely proportional
to the square of the distance between the charges.
F = k
Q1Q2
r2
and the proportionality constant k is called the electrostatic constant and has the value:
k = 8,99 × 109N · m2 · C−2.
Extension: Similarity of Coulomb’s Law to the Newton’s Universal Law of
Gravitation.
Notice how similar Coulomb’s Law is to the form of Newton’s Universal Law of
Gravitation between two point-like particles:
where m1 and m2 are the masses of the two particles, r is the distance between
them, and G is the gravitational constant.
Both laws represent the force exerted by particles (masses or charges) on each
other that interact by means of a field.
It is very interesting that Coulomb’s Law has been shown to be correct no
matter how small the distance, nor how large the charge. For example it still
applies inside the atom (over distances smaller than 10−10m).
Next is another example that demonstrates the difference in magnitude between the
gravitational force and the electrostatic force.
Important: We can apply Newton’s Third Law to charges because, two charges exert forces
of equal magnitude on one another in opposite directions.
Important: Coulomb’s Law
When substituting into the Coulomb’s Law equation, it is not necessary to include the signs of
the charges. Instead, select a positive direction. Then forces that tend to move the charge in
this direction are added, while forces that act in the opposite direction are subtracted.
We mentioned in Chapter 9 that charge placed on a spherical conductor spreads evenly along
the surface. As a result, if we are far enough from the charged sphere, electrostatically, it
behaves as a point-like charge. Thus we can treat spherical conductors (e.g. metallic balls) as
point-like charges, with all the charge acting at the centre.




file_data: 17.3|Electric field around charges|392
We have learnt that objects that carry charge feel forces from all other charged objects. It is
useful to determine what the effect of a charge would be at every point surrounding it. To do
this we need some sort of reference. We know that the force that one charge feels due to
another depends on both charges (Q1 and Q2). How then can we talk about forces if we only
have one charge? The solution to this dilemma is to introduce a test charge. We then
determine the force that would be exerted on it if we placed it at a certain location. If we do
this for every point surrounding a charge we know what would happen if we put a test charge
at any location.
This map of what would happen at any point we call an electric field map. It is a map of the
electric field due to a charge. It tells us how large the force on a test charge would be and in
what direction the force would be. Our map consists of the lines that tell us how the test
charge would move if it were placed there.
Definition: Electric field
An electric field as a region of space in which an electric charge experiences a force. The
direction of the electric field at a point is the direction that a positive test charge would
move if placed at that point.



file_data: 17.3.1|Electric field lines|393
The maps depend very much on the charge or charges that the map is being made for. We will
start off with the simplest possible case. Take a single positive charge with no other charges
around it. First, we will look at what effects it would have on a test charge at a number of
points.
Electric field lines, like the magnetic field lines that were studied in Grade 10, are a way of
representing the electric field at a point.
• Arrows on the field lines indicate the direction of the field, i.e. the direction a positive
test charge would move.
• Electric field lines therefore point away from positive charges and towards negative
charges.
• Field lines are drawn closer together where the field is stronger.



file_data: 17.3.2|Positive charge acting on a test charge|393
At each point we calculate the force on a test charge, q, and represent this force by a vector.
We can see that at every point the positive test charge, q, would experience a force pushing it
away from the charge, Q. This is because both charges are positive and so they repel. Also
notice that at points further away the vectors are shorter. That is because the force is smaller
if you are further away.
Negative charge acting on a test charge
If the charge were negative we would have the following result.
Notice that it is almost identical to the positive charge case. This is important – the arrows
are the same length because the magnitude of the charge is the same and so is the magnitude
of the test charge. Thus the magnitude (size) of the force is the same. The arrows point in
the opposite direction because the charges now have opposite sign and so the test charge is
attracted to the charge. Now, to make things simpler, we draw continuous lines showing the
path that the test charge would travel. This means we don’t have to work out the magnitude
of the force at many different points.
Some important points to remember about electric fields:
• There is an electric field at every point in space surrounding a charge.
• Field lines are merely a representation – they are not real. When we draw them, we just
pick convenient places to indicate the field in space.
• Field lines always start at a right-angle (90o) to the charged object causing the field.
• Field lines never cross.



file_data: 17.3.3|Combined charge distributions|394
We will now look at the field of a positive charge and a negative charge placed next to each
other. The net resulting field would be the addition of the fields from each of the charges. To
start off with let us sketch the field maps for each of the charges separately.
Notice that a test charge starting off directly between the two would be pushed away from the
positive charge and pulled towards the negative charge in a straight line. The path it would
follow would be a straight line between the charges.
Now let’s consider a test charge starting off a bit higher than directly between the charges. If it
starts closer to the positive charge the force it feels from the positive charge is greater, but the
negative charge also attracts it, so it would move away from the positive charge with a tiny
force attracting it towards the negative charge. As it gets further from the positive charge the
force from the negative and positive charges change and they are equal in magnitude at equal
distances from the charges. After that point the negative charge starts to exert a stronger force
on the test charge. This means that the test charge moves towards the negative charge with
only a small force away from the positive charge.
Two like charges : both positive
For the case of two positive charges things look a little different. We can’t just turn the arrows
around the way we did before. In this case the test charge is repelled by both charges. This
tells us that a test charge will never cross half way because the force of repulsion from both
charges will be equal in magnitude.
The field directly between the charges cancels out in the middle. The force has equal
magnitude and opposite direction. Interesting things happen when we look at test charges that
are not on a line directly between the two.
We know that a charge the same distance below the middle will experience a force along a
reflected line, because the problem is symmetric (i.e. if we flipped vertically it would look the
same). This is also true in the horizontal direction. So we use this fact to easily draw in the
next four lines.
Two like charges : both negative
We can use the fact that the direction of the force is reversed for a test charge if you change
the sign of the charge that is influencing it. If we change to the case where both charges are
negative we get the following result:




file_data: 17.3.4|Parallel plates|397
One very important example of electric fields which is used extensively is the electric field
between two charged parallel plates. In this situation the electric field is constant. This is used
for many practical purposes and later we will explain how Millikan used it to measure the
charge on the electron.
Field map for oppositely charged parallel plates
This means that the force that a test charge would feel at any point between the plates would
be identical in magnitude and direction. The fields on the edges exhibit fringe effects, i.e. they
bulge outwards. This is because a test charge placed here would feel the effects of charges only
on one side (either left or right depending on which side it is placed). Test charges placed in
the middle experience the effects of charges on both sides so they balance the components in
the horizontal direction. This is clearly not the case on the edges.
Strength of an electric field
When we started making field maps we drew arrows to indicate the strength of the field and
the direction. When we moved to lines you might have asked “Did we forget about the field
strength?”. We did not. Consider the case for a single positive charge again:
Notice that as you move further away from the charge the field lines become more spread out.
In field map diagrams the closer field lines are together the stronger the field. Therefore, the
electric field is stronger closer to the charge (the electric field lines are closer together) and
weaker further from the charge (the electric field lines are further apart).
The magnitude of the electric field at a point as the force per unit charge. Therefore,
E =
F
q
E and F are vectors. From this we see that the force on a charge q is simply:
F = E · q
The force between two electric charges is given by:
F = k
Qq
r2 .
(if we make the one charge Q and the other q.) Therefore, the electric field can be written as:
E = k
Q
r2
The electric field is the force per unit of charge and hence has units of newtons per coulomb.
As with Coulomb’s law calculations, do not substitute the sign of the charge into the equation
for electric field. Instead, choose a positive direction, and then either add or subtract the
contribution to the electric field due to each charge depending upon whether it points in the
positive or negative direction, respectively.




file_data: 17.4|Electrical potential energy and potential|400
The electrical potential energy of a charge is the energy it has because of its position relative
to other charges that it interacts with. The potential energy of a charge Q1 relative to a
charge Q2 a distance r away is calculated by:





file_data: 17.4.1|Electrical potential|400
The electric potential at a point is the electrical potential energy per unit charge, i.e. the
potential energy a positive test charge would have if it were placed at that point.
Consider a positive test charge +Q placed at A in the electric field of another positive point
charge.
The test charge moves towards B under the influence of the electric field of the other charge.
In the process the test charge loses electrical potential energy and gains kinetic energy. Thus,
at A, the test charge has more potential energy than at B – A is said to have a higher
electrical potential than B.
The potential energy of a charge at a point in a field is defined as the work required to move
that charge from infinity to that point.
Definition: Potential difference
The potential difference between two points in an electric field is defined as the work
required to move a unit positive test charge from the point of lower potential to
that of higher potential.
If an amount of work W is required to move a charge Q from one point to another, then the
potential difference between the two points is given by,
V =
W
Q
unit : J.C−1 or V (the volt)
From this equation we can define the volt.
Definition: The Volt
One volt is the potential difference between two points in an electric field if one joule of
work is done in moving one coulomb of charge from the one point to the other.



file_data: 17.4.2|Real-world application: lightning|402
Lightning is an atmospheric discharge of electricity, usually, but not always, during a rain
storm. An understanding of lightning is important for power transmission lines as engineers
who need to know about lightning in order to adequately protect lines and equipment.
Extension: Formation of lightning
1. Charge separation
The first process in the generation of lightning is charge separation. The
mechanism by which charge separation happens is still the subject of research.
One theory is that opposite charges are driven apart and energy is stored in
the electric field between them. Cloud electrification appears to require strong
updrafts which carry water droplets upward, supercooling them to −10 to
−20 oC. These collide with ice crystals to form a soft ice-water mixture called
graupel. The collisions result in a slight positive charge being transferred to
ice crystals, and a slight negative charge to the graupel. Updrafts drive lighter
ice crystals upwards, causing the cloud top to accumulate increasing positive
charge. The heavier negatively charged graupel falls towards the middle and
lower portions of the cloud, building up an increasing negative charge. Charge
separation and accumulation continue until the electrical potential becomes
sufficient to initiate lightning discharges, which occurs when the gathering of
positive and negative charges forms a sufficiently strong electric field.
2. Leader formation
As a thundercloud moves over the Earth’s surface, an equal but opposite
charge is induced in the Earth below, and the induced ground charge follows
the movement of the cloud. An initial bipolar discharge, or path of ionized
air, starts from a negatively charged mixed water and ice region in the
thundercloud. The discharge ionized channels are called leaders. The negative
charged leaders, called a ”stepped leader”, proceed generally downward in a
number of quick jumps, each up to 50 metres long. Along the way, the
stepped leader may branch into a number of paths as it continues to descend.
The progression of stepped leaders takes a comparatively long time (hundreds
of milliseconds) to approach the ground. This initial phase involves a
relatively small electric current (tens or hundreds of amperes), and the leader
is almost invisible compared to the subsequent lightning channel. When a
step leader approaches the ground, the presence of opposite charges on the
ground enhances the electric field. The electric field is highest on trees and
tall buildings. If the electric field is strong enough, a conductive discharge
(called a positive streamer) can develop from these points. As the field
increases, the positive streamer may evolve into a hotter, higher current
leader which eventually connects to the descending stepped leader from the
cloud. It is also possible for many streamers to develop from many different objects simultaneously, with only one connecting with the leader and forming
the main discharge path. Photographs have been taken on which
non-connected streamers are clearly visible. When the two leaders meet, the
electric current greatly increases. The region of high current propagates back
up the positive stepped leader into the cloud with a ”return stroke” that is
the most luminous part of the lightning discharge.
3. Discharge When the electric field becomes strong enough, an electrical
discharge (the bolt of lightning) occurs within clouds or between clouds and
the ground. During the strike, successive portions of air become a conductive
discharge channel as the electrons and positive ions of air molecules are pulled
away from each other and forced to flow in opposite directions. The electrical
discharge rapidly superheats the discharge channel, causing the air to expand
rapidly and produce a shock wave heard as thunder. The rolling and gradually
dissipating rumble of thunder is caused by the time delay of sound coming
from different portions of a long stroke.
Important: Estimating distance of a lightning strike
The flash of a lightning strike and resulting thunder occur at roughly the same time. But light
travels at 300 000 kilometres in a second, almost a million times the speed of sound. Sound
travels at the slower speed of 330 m/s in the same time, so the flash of lightning is seen before
thunder is heard. By counting the seconds between the flash and the thunder and dividing by 3,
you can estimate your distance from the strike and initially the actual storm cell (in kilometres).




file_data: 17.5|Capacitance and the parallel plate capacitor|403


file_data: 17.5.1|Capacitors and capacitance|403
A parallel plate capacitor is a device that consists of two oppositely charged conducting plates
separated by a small distance, which stores charge. When voltage is applied to the capacitor,
electric charge of equal magnitude, but opposite polarity, build up on each plate.
Figure 17.1: A capacitor (C) connected in series with a resistor (R) and an energy source (E).
Definition: Capacitance
Capacitance is the charge stored per volt and is measured in farad (F)
Mathematically, capacitance is the ratio of the charge on a single plate to the voltage across
the plates of the capacitor:
Capacitance is measured in farads (F). Since capacitance is defined as C = Q
V , the units are in
terms of charge over potential difference. The unit of charge is the coulomb and the unit of the
potential difference is the volt. One farad is therefore the capacitance if one coulomb of charge
was stored on a capacitor for every volt applied.
1 C of charge is a very large amount of charge. So, for a small amount of voltage applied, a
1 F capacitor can store a enormous amount of charge. Therefore, capacitors are often denoted
in terms of microfarads (1 × 10−6), nanofarads (1 × 10−9), or picofarads (1 × 10−12).
Important: Q is the magnitude of the charge stored on either plate, not on both plates
added together. Since one plate stores positive charge and the other stores negative charge,
the total charge on the two plates is zero.




file_data: 17.5.2|Dielectrics|404
The electric field between the plates of a capacitor is affected by the substance between them.
The substance between the plates is called a dielectric. Common substances used as dielectrics
are mica, perspex, air, paper and glass.
When a dielectric is inserted between the plates of a parallel plate capacitor the dielectric
becomes polarised so an electric field is induced in the dielectric that opposes the field between
the plates. When the two electric fields are superposed, the new field between the plates
becomes smaller. Thus the voltage between the plates decreases so the capacitance increases.
In every capacitor, the dielectric keeps the charge on one plate from travelling to the other
plate. However, each capacitor is different in how much charge it allows to build up on the
electrodes per voltage applied. When scientists started studying capacitors they discovered the
property that the voltage applied to the capacitor was proportional to the maximum charge
that would accumulate on the electrodes. The constant that made this relation into an
equation was called the capacitance, C. The capacitance was different for different capacitors.
But, it stayed constant no matter how much voltage was applied. So, it predicts how much
charge will be stored on a capacitor when different voltages are applied.



file_data: 17.5.3|Physical properties of the capacitor and capacitance|404
The capacitance of a capacitor is proportional to the surface area of the conducting plate and
inversely proportional to the distance between the plates. It is also proportional to the permittivity of the dielectric. The dielectric is the non-conducting substance that separates the
plates. As mentioned before, dielectrics can be air, paper, mica, perspex or glass.
The capacitance of a parallel-plate capacitor is given by:
C = ǫ0
A
d
where ǫ0 is the permittivity of air, A is the area of the plates and d is the distance between the
plates.



file_data: 17.5.4|Electric field in a capacitor|405
The electric field strength between the plates of a capacitor can be calculated using the
formula:
E = V
d where E is the electric field in J.C−1, V is the potential difference in V and d is the
distance between the plates in m.



file_data: 17.6|Capacitor as a circuit device|406


file_data: 17.6.1|A capacitor in a circuit|406
When a capacitor is connected in a DC circuit, current will flow until the capacitor is fully
charged. After that, no further current will flow. If the charged capacitor is connected to
another circuit with no source of emf in it, the capacitor will discharge through the circuit,
creating a potential difference for a short time. This is useful, for example, in a camera flash.
Initially, the electrodes have no net charge. A voltage source is applied to charge a capacitor.
The voltage source creates an electric field, causing the electrons to move. The charges move
around the circuit stopping at the left electrode. Here they are unable to travel across the
dielectric, since electrons cannot travel through an insulator. The charge begins to accumulate,
and an electric field forms pointing from the left electrode to the right electrode. This is the
opposite direction of the electric field created by the voltage source. When this electric field is
equal to the electric field created by the voltage source, the electrons stop moving. The
capacitor is then fully charged, with a positive charge on the left electrode and a negative
charge on the right electrode.
If the voltage is removed, the capacitor will discharge. The electrons begin to move because in
the absence of the voltage source, there is now a net electric field. This field is due to the
imbalance of charge on the electrodes–the field across the dielectric. Just as the electrons
flowed to the positive electrode when the capacitor was being charged, during discharge, the
electrons flow to negative electrode. The charges cancel, and there is no longer an electric field
across the dielectric.



file_data: 17.6.2|Real-world applications: capacitors|407
Capacitors are used in many different types of circuitry. In car speakers, capacitors are often
used to aid the power supply when the speaker require more power than the car battery can
provide. Capacitors are also used to in processing electronic signals in circuits, such as
smoothing voltage spikes due to inconsistent voltage sources. This is important for protecting
sensitive electronic compoments in a circuit.



file_data: 17.7|Summary|407


file_data: 17.8|Exercises - Electrostatics|407





file_data: 18|Electromagnetism - Grade 11|413


file_data: 18.1|Introduction|413
Electromagnetism is the science of the properties and relationship between electric currents and
magnetism. An electric current creates a magnetic field and a moving magnetic field will create
a flow of charge. This relationship between electricity and magnetism has resulted in the
invention of many devices which are useful to humans.



file_data: 18.2|Magnetic field associated with a current|413
If you hold a compass near a wire through which current is flowing, the needle on the compass
will be deflected.
The discovery of the relationship between magnetism and electricity was, like
so many other scientific discoveries, stumbled upon almost by accident. The
Danish physicist Hans Christian Oersted was lecturing one day in 1820 on the
possibility of electricity and magnetism being related to one another, and in the
process demonstrated it conclusively by experiment in front of his whole class.
By passing an electric current through a metal wire suspended above a
magnetic compass, Oersted was able to produce a definite motion of the
compass needle in response to the current. What began as a guess at the start
of the class session was confirmed as fact at the end. Needless to say, Oersted
had to revise his lecture notes for future classes. His discovery paved the way
for a whole new branch of science - electromagnetism.
The magnetic field produced by an electric current is always oriented perpendicular to the
direction of the current flow. When we are drawing directions of magnetic fields and currents,
we use the symbol ⊙ and ⊗. The symbol
⊙
for an arrow that is coming out of the page and the symbol
⊗
for an arrow that is going into the page.
It is easy to remember the meanings of the symbols if you think of an arrow with a head and a
tail.
When the arrow is coming out of the page, you see the head of the arrow (⊙). When the arrow
is going into the page, you see the tail of the arrow (⊗).
The direction of the magnetic field around the current carrying conductor is shown in
Figure 18.1.
Figure 18.1: Magnetic field around a conductor when you look at the conductor from one end.
(a) Current flows into the page and the magnetic field is counter clockwise. (b) Current flows
out of the page and the magnetic field is clockwise.



file_data: 18.2.1|Real-world applications|418
Electromagnets
An electromagnet is a piece of wire intended to generate a magnetic field with the passage of
electric current through it. Though all current-carrying conductors produce magnetic fields, an
electromagnet is usually constructed in such a way as to maximize the strength of the magnetic
field it produces for a special purpose. Electromagnets find frequent application in research,
industry, medical, and consumer products.
As an electrically-controllable magnet, electromagnets find application in a wide variety of
”electromechanical” devices: machines that effect mechanical force or motion through
electrical power. Perhaps the most obvious example of such a machine is the electric motor
which will be described in detail in Grade 12. Other examples of the use of electromagnets are
electric bells, relays, loudspeakers and scrapyard cranes.






file_data: 18.3|Current induced by a changing magnetic field|420
While Oersted’s surprising discovery of electromagnetism paved the way for more practical
applications of electricity, it was Michael Faraday who gave us the key to the practical
generation of electricity: electromagnetic induction.
Faraday discovered that a voltage was generated across a length of wire while moving a magnet
nearby, such that the distance between the two changed. This meant that the wire was
exposed to a magnetic field flux of changing intensity. Furthermore, the voltage also depended
on the orientation of the magnet; this is easily understood again in terms of the magnetic flux.
The flux will be at its maximum as the magnet is aligned perpendicular to the wire. The
magnitude of the changing flux and the voltage are linked. In fact, if the lines of flux are
parallel to the wire, there will be no induced voltage.
Definition: Faraday’s Law
The emf, ǫ, produced around a loop of conductor is proportional to the rate of change of
the magnetic flux, φ, through the area, A, of the loop. This can be stated mathematically
as:
ǫ = −N
φ
t
where φ = B · A and B is the strength of the magnetic field.
Faraday’s Law relates induced emf to the rate of change of flux, which is the product of the
magnetic field and the cross-sectional area the field lines pass through.

When the north pole of a magnet is pushed into a solenoid, the flux in the solenoid increases so
the induced current will have an associated magnetic field pointing out of the solenoid (opposite to the magnet’s field). When the north pole is pulled out, the flux decreases, so the
induced current will have an associated magnetic field pointing into the solenoid (same
direction as the magnet’s field) to try to oppose the change. The directions of currents and
associated magnetic fields can all be found using only the Right Hand Rule. When the fingers
of the right hand are pointed in the direction of the current, the thumb points in the direction
of the magnetic field. When the thumb is pointed in the direction of the magnetic field, the
fingers point in the direction of the current.
Important: An easy way to create a magnetic field of changing intensity is to move a
permanent magnet next to a wire or coil of wire. The magnetic field must increase or
decrease in intensity perpendicular to the wire (so that the lines of flux ”cut across” the
conductor), or else no voltage will be induced.
Important: Finding the direction of the induced current
The induced current generates a magnetic field. The induced magnetic field is in a direction
that cancels out the magnetic field in which the conductor is moving. So, you can use the
Right Hand Rule to find the direction of the induced current by remembering that the induced
magnetic field is opposite in direction to the magnetic field causing the change.
Electromganetic induction is put into practical use in the construction of electrical generators,
which use mechanical power to move a magnetic field past coils of wire to generate voltage.
However, this is by no means the only practical use for this principle.
If we recall that the magnetic field produced by a current-carrying wire was always
perpendicular to that wire, and that the flux intensity of that magnetic field varied with the
amount of current through it, we can see that a wire is capable of inducing a voltage along its
own length simply due to a change in current through it. This effect is called self-induction.
Self-induction is when a changing magnetic field is produced by changes in current through a
wire inducing voltage along the length of that same wire.
If the magnetic field flux is enhanced by bending the wire into the shape of a coil, and/or
wrapping that coil around a material of high permeability, this effect of self-induced voltage will
be more intense. A device constructed to take advantage of this effect is called an inductor,
and will be discussed in greater detail in the next chapter.
Extension: Lenz’s Law
The induced current will create a magnetic field that opposes the change in the
magnetic flux.
 



file_data: 18.3.1|Real-life applications|422
The following devices use Faraday’s Law in their operation.
• induction stoves
• tape players
• metal detectors
• transformers




file_data: 18.4|Transformers|423
One of the real-world applications of Faraday’s Law is in a transformer.
Eskom generates electricity at around 22 000 V. When you plug in a toaster, the mains voltage
is 220 V. A transformer is used to step-down the high voltage to the lower voltage that is used
as mains voltage.
Definition: Transformer
A transformer is an electrical device that uses the principle of induction between the primary
coil and the secondary coil to either step-up or step-down voltage.
The essential features of a transformer are two coils of wire, called the primary coil and the
secondary coil, which are wound around different sections of the same iron core.
When an alternating voltage is applied to the primary coil it creates an alternating current in
that coil, which induces an alternating magnetic field in the iron core. This changing magnetic
field induces an emf, which creates a current in the secondary coil.
The circuit symbol for a transformer is:
A very useful property of transformers is the ability to transform voltage and current levels
according to a simple ratio, determined by the ratio of input and output coil turns. We can
derive a mathematical relationship by using Faraday’s law.
Assume that an alternating voltage Vp is applied to the primary coil (which has Np turns) of a
transformer. The current that results from this voltage generates a magnetic flux φp. We can
then describe the emf in the primary coil by:
Vp = Np
φp
t
Similarly, for the secondary coil,
Vs = Ns
φs
t
If we assume that the primary and secondary windings are perfectly coupled, then:
φp = φs
which means that:
Vp
Vs
=
Np
Ns
A transformer designed to output more voltage than it takes in across the input coil is called a
step-up transformer. A step-up transformer has more windings on the secondary coil than on
the primary coil. This means that:
Similarly, a transformer designed to output less than it takes in across the input coil is called a
step-down transformer. A step-down transformer has more windings on the primary coil than
on the primary coil. This means that:
Np > Ns
We use a step-up transformer to increase the voltage from the primary coil to the secondary
coil. It is used at power stations to increase the voltage for the transmission lines. A step-down
transformer decreases the voltage from the primary coil to the secondary coil. It is particularly
used to decrease the voltage from the transmission lines to a voltage which can be used in
factories and in homes.
Transformer technology has made long-range electric power distribution practical. Without the
ability to efficiently step voltage up and down, it would be cost-prohibitive to construct power
systems for anything but close-range (within a few kilometres) use.
As useful as transformers are, they only work with AC, not DC. This is because the
phenomenon of mutual inductance relies on changing magnetic fields, and direct current (DC)
can only produce steady magnetic fields, transformers simply will not work with direct current.
Of course, direct current may be interrupted (pulsed) through the primary winding of a
transformer to create a changing magnetic field (as is done in automotive ignition systems to
produce high-voltage spark plug power from a low-voltage DC battery), but pulsed DC is not
that different from AC. Perhaps more than any other reason, this is why AC finds such
widespread application in power systems.




file_data: 18.4.1|Real-world applications|425
Transformers are very important in the supply of electricity nationally. In order to reduce energy
losses due to heating, electrical energy is transported from power stations along power lines at
high voltage and low current. Transformers are used to step the voltage up from the power
station to the power lines, and step it down from the power lines to buildings where it is needed.



file_data: 18.5|Motion of a charged particle in a magnetic field|425
When a charged particle moves through a magnetic field it experiences a force. For a particle
that is moving at right angles to the magnetic field, the force is given by:
F = qvB
where q is the charge on the particle, v is the velocity of the particle and B is the magnetic
field through which the particle is moving.
Important: The direction of the force exerted on a charged particle moving through a
magnetic field is determined by using the Right Hand Rule.
Point your fingers in the direction of the velocity of the charge and turn them (as if turning
a screwdriver) towards the direction of the magnetic field. Your thumb will point in the
direction of the force. If the charge is negative, the direction of the force will be opposite
to the direction of your thumb.



file_data: 18.5.1|Real-world applications|426
The following devices use the movement of charge in a magnetic field
• televisions
• oscilloscope



file_data: 18.6|Summary|427


file_data: 18.7|End of chapter exercises|427








file_data: 19|Electric Circuits - Grade 11|429


file_data: 19.1|Introduction|429
The study of electrical circuits is essential to understand the technology that uses electricity in
the real-world. This includes electricity being used for the operation of electronic devices like
computers.



file_data: 19.2|Ohm's Law|429


file_data: 19.2.1|Definition of Ohm's Law|429
An important relationship between the current, voltage and resistance in a circuit was
discovered by Georg Simon Ohm and is called Ohm’s Law.
Definition: Ohm’s Law
The amount of electric current through a metal conductor, at a constant temperature, in a
circuit is proportional to the voltage across the conductor. Mathematically, Ohm’s Law is
written:
V = R · I.
Ohm’s Law tells us that if a conductor is at a constant temperature, the voltage across the
ends of the conductor is proportional to the current. This means that if we plot voltage on the
y-axis of a graph and current on the x-axis of the graph, we will get a straight-line. The
gradient of the straight-line graph is then the resistance of the conductor.


file_data: 19.2.2|Ohmic and non-ohmic conductors|431
As you have seen, there is a mention of constant temperature when we talk about Ohm’s Law.
This is because the resistance of some conductors change as their temperature changes. These
types of conductors are called non-ohmic conductors, because they do not obey Ohm’s Law.
As can be expected, the conductors that obey Ohm’s Law are called ohmic conductors. A light
bulb is a common example of a non-ohmic conductor. Nichrome wire is an ohmic conductor.
In a light bulb, the resistance of the filament wire will increase dramatically as it warms from
room temperature to operating temperature. If we increase the supply voltage in a real lamp
circuit, the resulting increase in current causes the filament to increase in temperature, which
increases its resistance. This effectively limits the increase in current. In this case, voltage and
current do not obey Ohm’s Law.
The phenomenon of resistance changing with variations in temperature is one shared by almost
all metals, of which most wires are made. For most applications, these changes in resistance
are small enough to be ignored. In the application of metal lamp filaments, which increase a lot
in temperature (up to about 1000◦C, and starting from room temperature) the change is quite
large.
In general non-ohmic conductors have plots of voltage against current that are curved,
indicating that the resistance is not constant over all values of voltage and current.



file_data: 19.2.3|Using Ohm's Law|432
We are now ready to see how Ohm’s Law is used to analyse circuits.
Consider the circuit with an ohmic resistor, R. If the resistor has a resistance of 5 
 and
voltage across the resistor is 5V, then we can use Ohm’s law to calculate the current flowing
through the resistor.



file_data: 19.3|Resistance|433
In Grade 10, you learnt about resistors and were introduced to circuits where resistors were
connected in series and circuits where resistors were connected in parallel. In a series circuit
there is one path for the current to flow through. In a parallel circuit there are multiple paths
for the current to flow through.



file_data: 19.3.1|Equivalent resistance|433
When there is more than one resistor in a circuit, we are usually able to replace all resistors
with a single resistor whose effect is the same as all the resistors put together. The resistance
of the single resistor is known as equivalent resistance. We are able to calculate equivalent
resistance for resistors connected in series and parallel.
Equivalent Series Resistance
Consider a circuit consisting of three resistors and a single battery connected in series.
The first principle to understand about series circuits is that the amount of current is the same
through any component in the circuit. This is because there is only one path for electrons to
flow in a series circuit. From the way that the battery is connected, we can tell which direction
the current will flow. We know that charge flows from positive to negative, by convention.
Current in this circuit will flow in a clockwise direction, from point A to B to C to D and back
to A.
So, how do we use this knowledge to calculate the value of a single resistor that can replace
the three resistors in the circuit and still have the same current?
We know that in a series circuit the current has to be the same in all components. So we can
write:
I = I1 = I2 = I3
We also know that total voltage of the circuit has to be equal to the sum of the voltages over
all three resistors. So we can write:
V = V1 + V2 + V3
Finally, we know that Ohm’s Law has to apply for each resistor individually, which gives us:
V1 = I1 · R1
V2 = I2 · R2
V3 = I3 · R3
Therefore:
V = I1 · R1 + I2 · R2 + I3 · R3
However, because
I = I1 = I2 = I3
, we can further simplify this to:
V = I · R1 + I · R2 + I · R3
= I(R1 + R2 + R3)
Further, we can write an Ohm’s Law relation for the entire circuit:
V = I · R
Definition: Equivalent resistance in a series circuit, Rs
For n resistors in series the equivalent resistance is:
Rs = R1 + R2 + R3 + · · · + Rn
Let us apply this to the following circuit.
Equivalent parallel resistance
Consider a circuit consisting of a single battery and three resistors that are connected in parallel.
The first principle to understand about parallel circuits is that the voltage is equal across all
components in the circuit. This is because there are only two sets of electrically common
points in a parallel circuit, and voltage measured between sets of common points must always
be the same at any given time. So, for the circuit shown, the following is true:
V = V1 = V2 = V3
The second principle for a parallel circuit is that all the currents through each resistor must add
up to the total current in the circuit.
I = I1 + I2 + I3
Also, from applying Ohm’s Law to the entire circuit, we can write:
Definition: Equivalent resistance in a parallel circuit, Rp
For n resistors in parallel, the equivalent resistance is:



file_data: 19.3.2|Use of Ohm's Law in series and parallel Circuits|438




file_data: 19.3.3|Batteries and internal resistance|440
Real batteries are made from materials which have resistance. This means that real batteries
are not just sources of potential difference (voltage), but they also possess internal resistances.
If the pure voltage source is referred to as the emf, E, then a real battery can be represented as
an emf connected in series with a resistor r. The internal resistance of the battery is
represented by the symbol r.
Definition: Load
The external resistance in the circuit is referred to as the load.
Suppose that the battery (or cell) with emf E and internal resistance r supplies a current I
through an external load resistor R. Then the voltage drop across the load resistor is that
supplied by the battery:
V = I · R
Similarly, from Ohm’s Law, the voltage drop across the internal resistance is:
Vr = I · r
The voltage V of the battery is related to its emf E and internal resistance r by:
E = V + Ir; or
V = E − Ir
The emf of a battery is essentially constant because it only depends on the chemical reaction
(that converts chemical energy into electrical energy) going on inside the battery. Therefore,
we can see that the voltage across the terminals of the battery is dependent on the current
drawn by the load. The higher the current, the lower the voltage across the terminals, because
the emf is constant. By the same reasoning, the voltage only equals the emf when the current
is very small.
The maximum current that can be drawn from a battery is limited by a critical value Ic. At a
current of Ic, V =0 V. Then, the equation becomes:





file_data: 19.4|Series and parallel networks of resistors|442
Now that you know how to handle simple series and parallel circuits, you are ready to tackle
problems like this:
It is relatively easy to work out these kind of circuits because you use everything you have
already learnt about series and parallel circuits. The only difference is that you do it in stages.
Figure 19.1: An example of a series-parallel network. The dashed boxes indicate parallel sections
of the circuit.
In Figure 19.1, the circuit consists of 2 parallel portions that are then in series with 1 resistor.
So, in order to work out the equivalent resistance, you start by reducing the parallel portions to
a single resistor and then add up all the resistances in series. If all the resistors in Figure 19.1
had resistances of 10 
, we can calculate the equivalent resistance of the entire circuit.
We start by reducing Parallel Circuit 1 to a single resistor.





file_data: 19.5|Wheatstone bridge|445
Another method of finding an unknown resistance is to use a Wheatstone bridge. A
Wheatstone bridge is a measuring instrument that is used to measure an unknown electrical
resistance by balancing two legs of a bridge circuit, one leg of which includes the unknown
component. Its operation is similar to the original potentiometer except that in potentiometer
circuits the meter used is a sensitive galvanometer.
The Wheatstone bridge was invented by Samuel Hunter Christie in 1833 and
improved and popularized by Sir Charles Wheatstone in 1843.
In the circuit of the Wheatstone bridge, Rx is the unknown resistance. R1, R2 and R3 are
resistors of known resistance and the resistance of R2 is adjustable. If the ratio of R2:R1 is
equal to the ratio of Rx:R3, then the voltage between the two midpoints will be zero and no
current will flow between the midpoints. In order to determine the unknown resistance, R2 is
varied until this condition is reached. That is when the voltmeter reads 0 V.
Extension: Power in electric circuits
In addition to voltage and current, there is another measure of free electron
activity in a circuit: power. Power is a measure of how rapidly a standard amount
of work is done. In electric circuits, power is a function of both voltage and
current:
Definition: Electrical Power
Electrical power is calculated as:
P = I · V
Power (P) is exactly equal to current (I) multiplied by voltage (V ) and there is
no extra constant of proportionality. The unit of measurement for power is the
Watt (abbreviated W).
It was James Prescott Joule, not Georg Simon Ohm, who first
discovered the mathematical relationship between power dissipation
and current through a resistance. This discovery, published in 1841,
followed the form of the equation:
P = I2R
and is properly known as Joule’s Law. However, these power
equations are so commonly associated with the Ohm’s Law equations
relating voltage, current, and resistance that they are frequently
credited to Ohm.



file_data: 19.6|Summary|447


file_data: 19.7|End of chapter exercise|447





file_data: 20|Electronic Properties of Matter - Grade 11|451


file_data: 20.1|Introduction|451
We can study many different features of solids. Just a few of the things we could study are
how hard or soft they are, what are their magnetic properties or how well do they conduct heat.
The thing that we are interested in, in this chapter are their electronic properties. Simply how
well do they conduct electricity and how do they do it.
We are only going to discuss materials that form a 3-dimensional lattice. This means that the
atoms that make up the material have a regular pattern (carbon, silicon, etc.). We won’t
discuss materials where the atoms are jumbled together in a irregular way (plastic, glass,
rubber etc.).



file_data: 20.2|Conduction|451
We know that there are materials that do conduct electricity, called conductors, like the copper
wires in the circuits you build. There are also materials that do not conduct electricity, called
insulators, like the plastic covering on the copper wires.
Conductors come in two major categories: metals (e.g. copper) and semi-conductors (e.g.
silicon). Metals conduct very well and semi-conductors don’t. One very interesting difference is
that metals conduct less as they become hotter but semi-conductors conduct more.
What is different about these substances that makes them conduct differently? That is what
we are about to find out.
We have learnt that electrons in an atom have discrete energy levels. When an electron is given
the right amount of energy, it can jump to a higher energy level, while if it loses the right
amount of energy it can drop to a lower energy level. The lowest energy level is known as the
ground state.
When two atoms are far apart from each other they don’t influence each other. Look at the
picture below. There are two atoms depicted by the black dots. When they are far apart their
electron clouds (the gray clouds) are distinct. The dotted line depicts the distance of the
outermost electron energy level that is occupied.
b b
In some lattice structures the atoms would be closer together. If they are close enough their
electron clouds, and therefore electron energy levels start to overlap. Look at the picture
below. In this picture the two atoms are closer together. The electron clouds now overlap. The
overlapping area is coloured in solid gray to make it easier to see.
b b
When this happens we might find two electrons with the same energy and spin in the same
space. We know that this is not allowed from the Pauli exclusion principle. Something must
change to allow the overlapping to happen. The change is that the energies of the energy
levels change a tiny bit so that the electrons are not in exactly the same spin and energy state
at the same time.
So if we have 2 atoms then in the overlapping area we will have twice the number of electrons
and energy levels but the energy levels from the different atoms will be very very close in
energy. If we had 3 atoms then there would be 3 energy levels very close in energy and so on.
In a solid there may be very many energy levels that are very close in energy. These groups of
energy levels are called bands. The spacing between these bands determines whether the solid
is a conductor or an insulator.
In a gas, the atoms are spaced far apart and they do not influence each other. However, the
atoms in a solid greatly influence each other. The forces that bind these atoms together in a
solid affect how the electrons of the atoms behave, by causing the individual energy levels of an
atom to break up and form energy bands. The resulting energy levels are more closely spaced
than those in the individual atoms. The energy bands still contain discrete energy levels, but
there are now many more energy levels than in the single atom.
In crystalline solids, atoms interact with their neighbors, and the energy levels of the electrons
in isolated atoms turn into bands. Whether a material conducts or not is determined by its
band structure.
Electrons follow the Pauli exclusion principle, meaning that two electrons cannot occupy the
same state. Thus electrons in a solid fill up the energy bands up to a certain level (this is called
the Fermi energy). Bands which are completely full of electrons cannot conduct electricity,
because there is no state of nearby energy to which the electrons can jump. Materials in which
all bands are full are insulators.


file_data: 20.2.1|Metals|453
Metals are good conductors because they have unfilled space in the valence energy band. In
the absence of an electric field, there are electrons traveling in all directions. When an electric
field is applied the mobile electrons flow. Electrons in this band can be accelerated by the
electric field because there are plenty of nearby unfilled states in the band.



file_data: 20.2.2|Insulator|453
The energy diagram for the insulator shows the insulator with a very wide energy gap. The
wider this gap, the greater the amount of energy required to move the electron from the
valence band to the conduction band. Therefore, an insulator requires a large amount of energy
to obtain a small amount of current. The insulator “insulates” because of the wide forbidden
band or energy gap.
Breakdown
A solid with filled bands is an insulator. If we raise the temperature the electrons gain thermal
energy. If there is enough energy added then electrons can be thermally excited from the
valence band to the conduction band. The fraction of electrons excited in this way depends on:
• the temperature and
• the band gap, the energy difference between the two bands.
Exciting these electrons into the conduction band leaves behind positively charged holes in the
valence band, which can also conduct electricity.




file_data: 20.2.3|Semi-conductors|454
A semi-conductor is very similar to an insulator. The main difference between semiconductors
and insulators is the size of the band gap between the conduction and valence bands. The
band gap in insulators is larger than the band gap in semiconductors.
In semi-conductors at room temperature, just as in insulators, very few electrons gain enough
thermal energy to leap the band gap, which is necessary for conduction. For this reason, pure
semi-conductors and insulators, in the absence of applied fields, have roughly similar electrical
properties. The smaller band gaps of semi-conductors, however, allow for many other means
besides temperature to control their electrical properties. The most important one being that
for a certain amount of applied voltage, more current will flow in the semiconductor than in the
insulator.



file_data: 20.3|Intrinsic Properties and Doping|454
We have seen that the size of the energy gap between the valence band and the conduction
band determines whether a solid is a conductor or an insulator. However, we have seen that
there is a material known as a semi-conductor. A semi-conductor is a solid whose band gap is
smaller than that of an insulator and whose electrical properties can be modified by a process
known as doping.
Definition: Doping
Doping is the deliberate addition of impurities to a pure semiconductor material to change
its electrical properties.
Semiconductors are often the Group IV elements in the periodic table. The most common
semiconductor elements are silicon (Si) and germanium (Ge). The most important property of
Group IV elements is that they 4 valence electrons.
Extension: Band Gaps of Si and Ge
Si has a band gap of 1.744 × 10−19 J while Ge has a band gap of
1.152 × 10−19 J.
So, if we look at the arrangement of for example Si atoms in a crystal, they would look like
that shown in Figure 20.1.
The main aim of doping is to make sure there are either too many (surplus) or too few
electrons (deficiency). Depending on what situation you want to create you use different
elements for the doping.




file_data: 20.3.1|Surplus|455
A surplus of electrons is created by adding an element that has more valence electrons than Si
to the Si crystal. This is known as n-type doping and elements used for n-type doping usually
come from Group V in the periodic table. Elements from Group V have 5 valence electrons,
one more than the Group IV elements.
A common n-type dopant (substance used for doping) is arsenic (As). The combination of a
semiconductor and an n-type dopant is known as an n-type semiconductor. A Si crystal doped
with As is shown in Figure 20.2. When As is added to a Si crystal, the 4 of the 5 valence
electrons in As bond with the 4 Si valence electrons. The fifth As valence electron is free to
move around.
It takes only a few As atoms to create enough free electrons to allow an electric current to flow
through the silicon. Since n-type dopants ‘donate’ their free atoms to the semiconductor, they
are known as donor atoms.
Figure 20.2: Si crystal doped with As. For each As atom present in the Si crystal, there is one
extra electron. This combination of Si and As is known as an n-type semiconductor, because of
its overall surplus of electrons.








file_data: 20.3.2|Deficiency|455
A deficiency of electrons is created by adding an element that has less valence electrons than Si
to the Si crystal. This is known as p-type doping and elements used for p-type doping usually
come from Group III in the periodic table. Elements from Group III have 3 valence electrons,
one less than the semiconductor elements that come from Group IV. A common p-type dopant
is boron (B). The combination of a semiconductor and a p-type dopant is known as an p-type
semiconductor. A Si crystal doped with B is shown in Figure 20.3. When B is mixed into the
silicon crystal, there is a Si valence electron that is left unbonded.
The lack of an electron is known as a hole and has the effect of a positive charge. Holes can
conduct current. A hole happily accepts an electron from a neighbor, moving the hole over a
space. Since p-type dopants ‘accept’ electrons, they are known as acceptor atoms.
Figure 20.3: Si crystal doped with B. For each B atom present in the Si crystal, there is one
less electron. This combination of Si and B is known as a p-type semiconductor, because of its
overall deficiency of electrons.
Donor (n-type) impurities have extra valence electrons with energies very close to the
conduction band which can be easily thermally excited to the conduction band. Acceptor
(p-type) impurities capture electrons from the valence band, allowing the easy formation of
holes.
The energy level of the donor atom is close to the conduction band and it is relatively easy for
electrons to enter the conduction band. The energy level of the acceptor atom is close to the
valence band and it is relatively easy for electrons to leave the valence band and enter the
vacancies left by the holes.






file_data: 20.4|The p-n junction|457


file_data: 20.4.1|Differences between p- and n-type semi-conductors|457
We have seen that the addition of specific elements to semiconductor materials turns them into
p-type semiconductors or n-type semiconductors. The differences between n- and p-type
semiconductors are summarised in Table ??.




file_data: 20.4.2|The p-n Junction|457
When p-type and n-type semiconductors are placed in contact with each other, a p-n junction
is formed. Near the junction, electrons and holes combine to create a depletion region.
bc
depletion band
Figure 20.4: The p-n junction forms between p- and n-type semiconductors. The free electrons
from the n-type material combine with the holes in the p-type material near the junction. There
is a small potential difference across the junction. The area near the junction is called the
depletion region because there are few holes and few free electrons in this region.
Electric current flows more easily across a p-n junction in one direction than in the other. If the
positive pole of a battery is connected to the p-side of the junction, and the negative pole to
the n-side, charge flows across the junction. If the battery is connected in the opposite
direction, very little charge can flow.
This might not sound very useful at first but the p-n junction forms the basis for computer
chips, solar cells, and other electronic devices.


file_data: 20.4.3|Unbiased|457
In a p-n junction, without an external applied voltage (no bias), an equilibrium condition is
reached in which a potential difference is formed across the junction.
P-type is where you have more ”holes”; N-type is where you have more electrons in the
material. Initially, when you put them together to form a junction, holes near the junction
tends to ”move” across to the N-region, while the electrons in the N-region drift across to the
p-region to ”fill” some holes. This current will quickly stop as the potential barrier is built up
by the migrated charges. So in steady state no current flows.
Then now when you put a potential different across the terminals you have two cases: forward
biased and reverse biased.



file_data: 20.4.4|Forward biased|457
Forward-bias occurs when the p-type semiconductor material is connected to the positive
terminal of a battery and the n-type semiconductor material is connected to the negative
terminal.
The electric field from the external potential different can easily overcome the small internal
field (in the so-called depletion region, created by the initial drifting of charges): usually
anything bigger than 0.6V would be enough. The external field then attracts more e- to flow
from n-region to p-region and more holes from p-region to n-region and you have a forward
biased situation. the diode is ON.


file_data: 20.4.5|Reverse biased|458
in this case the external field pushes e- back to the n-region while more holes into the p-region,
as a result you get no current flow. Only the small number of thermally released minority
carriers (holes in the n-type region and e- in the p-type region) will be able to cross the
junction and form a very small current, but for all practical purposes, this can be ignored
of course if the reverse biased potential is large enough you get avalanche break down and
current flow in the opposite direction. In many cases, except for Zener diodes, you most likely
will destroy the diode.


file_data: 20.4.6|Real-World Applications of Semiconductors|458
Semiconductors form the basis of modern electronics. Every electrical appliance usually has
some semiconductor-based technology inside it. The fundamental uses of semiconductors are in
microchips (also known as integrated circuits) and microprocessors.
Integrated circuits are miniaturised circuits. The use of integrated circuits makes it possible for
electronic devices (like a cellular telephone or a hi-fi) to get smaller.
Microprocessors are a special type of integrated circuit. (NOTE TO SELF: more is needed but
I’m not that knowledgable and I’m tired of Googling...)



file_data: 20.5|End of Chapter Exercises|459









file_data: 21|Motion in Two Dimensions - Grade 12|463


file_data: 21.1|Introduction|463
In Chapter 3, we studied motion in one dimension and briefly looked at vertical motion. In this
chapter we will discuss vertical motion and also look at motion in two dimensions. In
Chapter 12, we studied the conservation of momentum and looked at applications in one
dimension. In this chapter we will look at momentum in two dimensions.


file_data: 21.2|Vertical Projectile Motion|463
In Chapter 4, we studied the motion of objects in free fall and we saw that an object in free fall
falls with gravitational acceleration g. Now we can consider the motion of objects that are
thrown upwards and then fall back to the Earth. We call this projectile motion and we will only
consider the situation where the object is thrown straight upwards and then falls straight
downwards - this means that there is no horizontal displacement of the object, only a vertical
displacement.


file_data: 21.2.1|Motion in a Gravitational Field|463
When an object is in a gravitational field, it always accelerates downwards with a constant
acceleration g whether the object is moving upward or downward. This is shown in Figure 21.1.
Important: Projectiles moving upwards or downwards always accelerate downwards with a
constant acceleration g.
object moving upwards b g g bobject moving downwards
Figure 21.1: Objects moving upwards or downwards, always accelerate downwards.
This means that if an object is moving upwards, it decreases until it stops (vf = 0 m·s−1).
This is the maximum height that the object reaches, because after this, the object starts to fall.
Important: Projectiles have zero velocity at their greatest height.
Consider an object thrown upwards from a vertical height ho. We have seen that the object
will travel upwards with decreasing velocity until it stops, at which point it starts falling. The
time that it takes for the object to fall down to height ho is the same as the time taken for the
object to reach its maximum height from height ho.
Figure 21.2: (a) An object is thrown upwards from height h0. (b) After time tm, the object
reaches its maximum height, and starts to fall. (c) After a time 2tm the object returns to height
h0.
Important: Projectiles take the same the time to reach their greatest height from the point
of upward launch as the time they take to fall back to the point of launch.





file_data: 21.2.2|Equations of Motion|464
The equations of motion that were used in Chapter 4 to describe free fall can be used for
projectile motion. These equations are the same as those equations that were derived in
Chapter 3, but with a = g. We use g = 9,8m · s−2 for our calculations.
vi = initial velocity (m·s−1) at t = 0 s
vf = final velocity (m·s−1) at time t
x = height above ground (m)
t = time (s)
t = time interval (s)
g = acceleration due to gravity (m·s−2)




file_data: 21.2.3|Graphs of Vertical Projectile Motion|467
Vertical projectile motion is similar to motion at constant acceleration. In Chapter 3 you
learned about the graphs for motion at constant acceleration. The graphs for vertical projectile
motion are therefore identical to the graphs for motion under constant acceleration.
When we draw the graphs for vertical projectile motion, we consider two main situations: an
object moving upwards and an object moving downwards.
If we take the upwards direction as positive then for an object moving upwards we get the
graphs shown in Figure 21.9.
Figure 21.3: Graphs for an object thrown upwards with an initial velocity vi. The object takes
tm s to reach its maximum height of hm m after which it falls back to the ground. (a) position
vs. time graph (b) velocity vs. time graph (c) acceleration vs. time graph.





file_data: 21.3|Conservation of Momentum in Two Dimensions|475
We have seen in Chapter ?? that the momentum of a system is conserved when there are no
external forces acting on the system. Conversely, an external force causes a change in
momentum p, with the impulse delivered by the force, F acting for a time t given by:
p = F · t
The same principles that were studied in applying the conservation of momentum to problems
in one dimension, can be applied to solving problems in two dimensions.
The calculation of momentum is the same in two dimensions as in one dimension. The
calculation of momentum in two dimensions is broken down into determining the x and y
components of momentum and applying the conservation of momentum to each set of
components.
Consider two objects moving towards each other as shown in Figure 21.4. We analyse this
situation by calculating the x and y components of the momentum of each object.
Before the collision
Total momentum:
pi1 = m1vi1
pi2 = m2vi2
y-component of momentum:
pi1y = m1vi1y = m1vi1 cos θ1
pi2y = m2vi2y = m2vi2 sin θ2
After the collision
Total momentum:
pf1 = m1vf1
pf2 = m2vf2
x-component of momentum:
pf1x = m1vf1x = m1vf1 cos φ1
pf2x = m2vf2x = m2vf2 sin φ2
y-component of momentum:
pf1y = m1vf1y = m1vf1 cos φ1
pf2y = m2vf2y = m2vf2 sin φ2
Conservation of momentum
The initial momentum is equal to the final momentum:
pi = pf
pi = pi1 + pi2
pf = pf1 + pf2
This forms the basis of analysing momentum conservation problems in two dimensions.





file_data: 21.4|Types of Collisions|480
Two types of collisions are of interest:
• elastic collisions
• inelastic collisions
In both types of collision, total momentum is always conserved. Kinetic energy is conserved for
elastic collisions, but not for inelastic collisions.



file_data: 21.4.1|Elastic Collisions|480
Definition: Elastic Collisions
An elastic collision is a collision where total momentum and total kinetic energy are both
conserved.
This means that in an elastic collision the total momentum and the total kinetic energy before
the collision is the same as after the collision. For these kinds of collisions, the kinetic energy is
not changed into another type of energy.
Before the Collision
Figure 21.5 shows two balls rolling toward each other, about to collide:
Before the balls collide, the total momentum of the system is equal to all the individual
momenta added together. Ball 1 has a momentum which we call pi1 and ball 2 has a
momentum which we call pi2, it means the total momentum before the collision is:
pi = pi1 + pi2
We calculate the total kinetic energy of the system in the same way. Ball 1 has a kinetic energy
which we call KEi1 and the ball 2 has a kinetic energy which we call KEi2, it means that the
total kinetic energy before the collision is:
KEi = KEi1 + KEi2
After the Collision
Figure 21.6 shows two balls after they have collided:
After the balls collide and bounce off each other, they have new momenta and new kinetic
energies. Like before, the total momentum of the system is equal to all the individual momenta
added together. Ball 1 now has a momentum which we call pf1 and ball 2 now has a
momentum which we call pf2, it means the total momentum after the collision is
pf = pf1 + pf2
Ball 1 now has a kinetic energy which we call KEf1 and ball 2 now has a kinetic energy which
we call KEf2, it means that the total kinetic energy after the collision is:
KEf = KEf1 + KEf2
Since this is an elastic collision, the total momentum before the collision equals the total
momentum after the collision and the total kinetic energy before the collision equals the total
kinetic energy after the collision. Therefore:
Initial Final
pi = pf (21.5)
pi1 + pi2 = pf1 + pf2
and
KEi = KEf (21.6)
KEi1 + KEi2 = KEf1 + KEf2




file_data: 21.4.2|Inelastic Collisions|485
Definition: Inelastic Collisions
An inelastic collision is a collision in which total momentum is conserved but total kinetic
energy is not conserved. The kinetic energy is transformed into other kinds of energy.
So the total momentum before an inelastic collisions is the same as after the collision. But the
total kinetic energy before and after the inelastic collision is different. Of course this does not
mean that total energy has not been conserved, rather the energy has been transformed into
another type of energy.
As a rule of thumb, inelastic collisions happen when the colliding objects are distorted in some
way. Usually they change their shape. The modification of the shape of an object requires
energy and this is where the “missing” kinetic energy goes. A classic example of an inelastic
collision is a motor car accident. The cars change shape and there is a noticeable change in the
kinetic energy of the cars before and after the collision. This energy was used to bend the
metal and deform the cars. Another example of an inelastic collision is shown in Figure 21.7.
An asteroid is moving through space towards the Moon. Before the asteroid crashes into the
Moon, the total momentum of the system is:
pi = pim + pia
The total kinetic energy of the system is:
KEi = KEim + KEia
When the asteroid collides inelastically with the Moon, its kinetic energy is transformed
mostly into heat energy. If this heat energy is large enough, it can cause the asteroid and the
area of the Moon’s surface that it hits, to melt into liquid rock! From the force of impact of
the asteroid, the molten rock flows outwards to form a crater on the Moon.
After the collision, the total momentum of the system will be the same as before. But since
this collision is inelastic, (and you can see that a change in the shape of objects has taken
place!), total kinetic energy is not the same as before the collision.
Momentum is conserved:
pi = pf
But the total kinetic energy of the system is not conserved:
Author: Thomas D. Gutierrez
Tom Gutierrez received his Bachelor of Science and Master degrees in Physics
from San Jose State University in his home town of San Jose, California. As a
Master’s student he helped work on a laser spectrometer at NASA Ames Research
Centre. The instrument measured the ratio of different isotopes of carbon in CO2
gas and could be used for such diverse applications as medical diagnostics and
space exploration. Later, he received his PhD in physics from the University of
California, Davis where he performed calculations for various reactions in high
energy physics collisions. He currently lives in Berkeley, California where he studies
proton-proton collisions seen at the STAR experiment at Brookhaven National
Laboratory on Long Island, New York.
High Energy Collisions
Take an orange and expand it to the size of the earth. The atoms of the
earth-sized orange would themselves be about the size of regular oranges and would
fill the entire “earth-orange”. Now, take an atom and expand it to the size of a
football field. The nucleus of that atom would be about the size of a tiny seed in
the middle of the field. From this analogy, you can see that atomic nuclei are very
small objects by human standards. They are roughly 10−15 meters in diameter –
one-hundred thousand times smaller than a typical atom. These nuclei cannot be
seen or studied via any conventional means such as the naked eye or microscopes.
So how do scientists study the structure of very small objects like atomic nuclei?
The simplest nucleus, that of hydrogen, is called the proton. Faced with the
inability to isolate a single proton, open it up, and directly examine what is inside,
scientists must resort to a brute-force and somewhat indirect means of exploration:
high energy collisions. By colliding protons with other particles (such as other
protons or electrons) at very high energies, one hopes to learn about what they are
made of and how they work. The American physicist Richard Feynman once
compared this process to slamming delicate watches together and figuring out how
they work by only examining the broken debris. While this analogy may seem
pessimistic, with sufficient mathematical models and experimental precision,
considerable information can be extracted from the debris of such high energy
subatomic collisions. One can learn about both the nature of the forces at work
and also about the sub-structure of such systems.
The experiments are in the category of “high energy physics” (also known as
“subatomic” physics). The primary tool of scientific exploration in these
experiments is an extremely violent collision between two very, very small
subatomic objects such as nuclei. As a general rule, the higher the energy of the
collisions, the more detail of the original system you are able to resolve. These
experiments are operated at laboratories such as CERN, SLAC, BNL, and Fermilab,
just to name a few. The giant machines that perform the collisions are roughly the
size of towns. For example, the RHIC collider at BNL is a ring about 1 km in
diameter and can be seen from space. The newest machine currently being built,
the LHC at CERN, is a ring 9 km in diameter!





file_data: 21.5|Frames of Reference|490


file_data: 21.5.1|Introduction|490
Figure 21.8: Top view of a road with two people standing on opposite sides. A car drives past.
Consider two people standing, facing each other on either side of a road. A car drives past
them, heading West. For the person facing South, the car was moving toward the right.
However, for the person facing North, the car was moving toward the left. This discrepancy is
due to the fact that the two people used two different frames of reference from which to
investigate this system. If each person were asked in what direction the car were moving, they
would give a different answer. The answer would be relative to their frame of reference.




file_data: 21.5.2|What is a frame of reference?|491
Definition: Frame of Reference
A frame of reference is the point of view from which a system is observed.
In practical terms, a frame of reference is a set of axes (specifying directions) with an origin.
An observer can then measure the position and motion of all points in a system, as well as the
orientation of objects in the system relative to the frame of reference.
There are two types of reference frames: inertial and non-inertial. An inertial frame of
reference travels at a constant velocity, which means that Newton’s first law (inertia) holds
true. A non-inertial frame of reference, such as a moving car or a rotating carousel, accelerates.
Therefore, Newton’s first law does not hold true in a non-inertial reference frame, as objects
appear to accelerate without the appropriate forces.




file_data: 21.5.3|Why are frames of reference important?|491
Frames of reference are important because (as we have seen in the introductory example) the
velocity of a car can differ depending on which frame of reference is used.
Extension: Frames of Reference and Special Relativity
Frames of reference are especially important in special relativity, because when
a frame of reference is moving at some significant fraction of the speed of light,
then the flow of time in that frame does not necessarily apply in another reference
frame. The speed of light is considered to be the only true constant between
moving frames of reference.
The next worked example will explain this.




file_data: 21.5.4|Relative Velocity|491
The velocity of an object is frame dependent. More specifically, the perceived velocity of an
object depends on the velocity of the observer. For example, a person standing on shore would
observe the velocity of a boat to be different than a passenger on the boat.




file_data: 21.6|Summary|494


file_data: 21.7|End of chapter exercises|495








file_data: 22|Mechanical Properties of Matter - Grade 12|503


file_data: 22.1|Introduction|503
In this chapter we will look at some mechanical (physical) properties of various materials that
we use. The mechanical properties of a material are those properties that are affected by forces
being applied to the material. These properties are important to consider when we are
constructing buildings, structures or modes of transport like an aeroplane.



file_data: 22.2|Deformation of materials|503


file_data: 22.2.1|Hooke's Law|503
Deformation (change of shape) of a solid is caused by a force that can either be compressive or
tensile when applied in one direction (plane). Compressive forces try to compress the object
(make it smaller or more compact) while tensile forces try to tear it apart. We can study these
effects by looking at what happens when you compress or expand a spring.
Hooke’s Law describes the relationship between the force applied to a spring and its extension.
Historical Note: Hooke’s Law
Hooke’s law is named after the seventeenth century physicist Robert Hooke who discovered
it in 1660 (18 July 1635 - 3 March 1703).
Definition: Hooke’s Law
In an elastic spring, the extension varies linearly with the force applied.
F = −kx where F is the force in newtons (N), k is the spring constant in N · m−1 and x
is the extension in metres (m).





file_data: 22.2.2|Deviation from Hooke's Law|506
We know that if you have a small spring and you pull it apart too much it stops ’working’. It
bends out of shape and loses its springiness. When this happens Hooke’s Law no longer
applies, the spring’s behaviour deviates from Hooke’s Law.
Depending on what type of material we are dealing the manner in which it deviates from
Hooke’s Law is different. We give classify materials by this deviation. The following graphs
show the relationship between force and extension for different materials and they all deviate
from Hooke’s Law. Remember that a straight line show proportionality so as soon as the graph
is no longer a straight line, Hooke’s Law no longer applies.
Brittle material
This graph shows the relationship between force and extension for a brittle, but strong material.
Note that there is very little extension for a large force but then the material suddenly
fractures. Brittleness is the property of a material that makes it break easily without bending.
Have you ever dropped something made of glass and seen it shatter? Glass does this because
of its brittleness.
Plastic material
Here the graph shows the relationship between force and extension for a plastic material. The
material extends under a small force but it does not fracture.
Ductile material
In this graph the relationship between force and extension is for a material that is ductile. The
material shows plastic behaviour over a range of forces before the material finally fractures.
Ductility is the ability of a material to be stretched into a new shape without breaking.
Ductility is one of the characteristic properties of metals.
A good example of this is aluminium, many things are made of aluminium. Aluminium is used
for making everything from cooldrink cans to aeroplane parts and even engine blocks for cars.
Think about squashing and bending a cooldrink can.
Brittleness is the opposite of ductility.
When a material reaches a point where Hooke’s Law is no longer valid, we say it has reached
its limit of proportionality. After this point, the material will not return to its original shape
after the force has been removed. We say it has reached its elastic limit.
Definition: Elastic limit
The elastic limit is the point beyond which permanent deformation takes place.
Definition: Limit of proportionality
The limit of proportionality is the point beyond which Hooke’s Law is no longer obeyed.




file_data: 22.3|Elasticity, plasticity, fracture, creep|508


file_data: 22.3.1|Elasticity and plasticity|508
Materials are classified as plastic or elastic depending on how they respond to an applied force.
It is important to note that plastic substances are not necessarily a type of plastic (polymer)
they only behave like plastic. Think of them as being like plastic which you will be familiar with.
A rubber band is a material that has elasticity. It returns to its original shape after an applied
force is removed, providing that the material is not stretched beyond its elastic limit.
Plasticine is an example of a material that is plastic. If you flatten a ball of plasticine, it will
stay flat. A plastic material does not return to its original shape after an applied force is
removed.
• Elastic materials return to their original shape.
• Plastic materials deform easily and do not return to their original shape.




file_data: 22.3.2|Fracture, creep and fatigue|508
Some materials are neither plastic nor elastic. These substances will break or fracture when a
large enough force is applied to them. The brittle glass we mentioned earlier is an example.
Creep occurs when a material deforms over a long period of time because of an applied force.
An example of creep is the bending of a shelf over time when a heavy object is put on it. Creep
may eventually lead to the material fracturing. The application of heat may lead to an increase
in creep in a material.
Fatigue is similar to creep. The difference between the two is that fatigue results from the force
being applied and then removed repeatedly over a period of time. With metals this results in
failure because of metal fatigue.
• Fracture is an abrupt breaking of the material.
• Creep is a slow deformation process due to a continuous force over a long time.
• Fatigue is weakening of the material due to short forces acting many many times.



file_data: 22.4|Failure and strength of materials|509


file_data: 22.4.1|The properties of matter|509
The strength of a material is defined as the stress (the force per unit cross-sectional area) that
it can withstand. Strength is measured in newtons per square metre (N ·m−2).
Stiffness is a measure of how flexible a material is. In Science we measure the stiffness of a
material by calculating its Young’s Modulus. The Young’s modulus is a ratio of how much it
bends to the load applied to it. Stiffness is measure in newtons per metre (N ·m−1).
Hardness of a material can be measured by determining what force will cause a permanent
deformation in the material. Hardness can also be measured using a scale like Mohs hardness
scale. On this scale, diamond is the hardest at 10 and talc is the softest at 1.
Remembering that the Mohs scale is the hardness scale and that the softest
substance is talc will often come in handy for general knowledge quizes.
The toughness of a material is a measure of how it can resist breaking when it is stressed. It is
scientifically defined as the amount of energy that a material can absorb before breaking.
A ductile material is a substance that can undergo large plastic deformation without fracturing.
Many metals are very ductile and they can be drawn into wires, e.g. copper, silver, aluminium
and gold.
A malleable material is a substance that can easily undergo plastic deformation by hammering
or rolling. Again, metals are malleable substances, e.g. copper can be hammered into sheets
and aluminium can be rolled into aluminium foil.
A brittle material fractures with very little or no plastic deformation. Glassware and ceramics
are brittle.





file_data: 22.4.2|Structure and failure of materials|509
Many substances fail because they have a weakness in their atomic structure. There are a
number of problems that can cause these weaknesses in structure. These are vacancies,
dislocations, grain boundaries and impurities.
Vacancies occur when there are spaces in the structure of a crystalline solid. These vacancies
cause weakness and the substance often fail at these places. Think about bricks in a wall, if
you started removing bricks the wall would get weaker.
Dislocations occur when there are no strong bonds between two rows in a crystal lattice. The
crystal will fail along this boundary when sufficient force is applied. The two pieces of the
crystal keep their shape and structure but move along the boundary.
Impurities in a crystal structure can cause a weak spot in the crystal lattice around the
impurity. Like vacancies, the substance often fail from these places in the lattice. This you can
think of as bricks in a wall which don’t fit properly, they are the wrong kind of bricks (atoms)
to make the structure strong.
A difference in grain size in a crystal lattice will result in rusting or oxidation at the boundary
which again will result in failure when sufficient force is applied.



file_data: 22.4.3|Controlling the properties of materials|509
There are a number of processes that can be used to ensure that materials are less likely to fail.
We shall look at a few methods in this section.
Cold working
Cold working is a process in which a metal is strengthened by repeatedly being reshaped. This
is carried out at a temperature below the melting point of the metal. The repeated shaping of
the metal result in dislocations which then prevent further dislocations in the metal. Cold
working increases the strength of the metal but in so doing, the metal loses its ductility. We
say the metal is work-hardened.
Annealing
Annealing is a process in which a metal is heated strongly to a temperature that is about half
of its melting point. When the metal cools, it recrystallises which removes vacancies and
dislocations in the metal. Annealing is often used before cold working. In annealing the metal
cools very very slowly.
Alloying
An alloy is a mixture of a metal with other substances. The other substances can be metal or
non-metal. An alloy often has properties that are very different to the properties of the
substances from which it is made. The added substances strengthen the metal by preventing
dislocations from spreading. Ordinary steel is an alloy of iron and carbon. There are many
types of steel that also include other metals with iron and carbon. Brass is an alloy of copper
and Zinc. Bronze is an alloy of copper and tin. Gold and silver that is used in coins or jewellery
are also alloyed.
Tempering
Tempering is a process in which a metal is melted then quickly cooled. The rapid cooling is
called quenching. Usually tempering is done a number of times before a metal has the correct
properties that are needed for a particular application.
Sintering
Sintering is used for making ceramic objects among other things. In this process the substance
is heated so that its particles stick together. It is used with substances that have a very high
melting point. The resulting product is often very pure and it is formed in the process into the
shape that is wanted. Unfortunately, sintered products are brittle.



file_data: 22.4.4|Steps of Roman Swordsmithing|510
• Purifying the iron ore.
• Heating the iron blocks in a furnace with charcoal.
• Hammering and getting into the needed shape. The smith used a hammer to pound the
metal into blade shape. He usually used tongs to hold the iron block in place.
• Reheating. When the blade cooled, the smith reheated it to keep it workable. While
reheated and hammered repeatedly.
• Quenching which involved the process of white heating and cooling in water. Quenching
made the blade harder and stronger. At the same time it made the blade quite brittle,
which was a considerable problem for the sword smiths.
• Tempering was then done to avoid brittleness the blade was tempered. In another words
it was reheated a final time to a very specific temperature. How the Romans do balanced
the temperature? The smith was guided only by the blade’s color and his own experience.



file_data: 22.5|Summary|511


file_data: 22.6|End of chapter exercise|511







file_data: 23|Work, Energy and Power - Grade 12|513


file_data: 23.1|Introduction|513
Imagine a vendor carrying a basket of vegetables on her head. Is she doing any work? One
would definitely say yes! However, in Physics she is not doing any work! Again, imagine a boy
pushing against a wall? Is he doing any work? We can see that his muscles are contracting and
expanding. He may even be sweating. But in Physics, he is not doing any work!
If the vendor is carrying a very heavy load for a long distance, we would say she has lot of
energy. By this, we mean that she has a lot of stamina. If a car can travel very fast, we
describe the car as powerful. So, there is a link between power and speed. However, power
means something different in Physics. This chapter describes the links between work, energy
and power and what these mean in Physics.
You will learn that work and energy are closely related. You shall see that the energy of an
object is its capacity to do work and doing work is the process of transferring energy from one
object or form to another. In other words,
• an object with lots of energy can do lots of work.
• when work is done, energy is lost by the object doing work and gained by the object on
which the work is done.
Lifting objects or throwing them requires that you do work on them. Even making electricity
flow requires that something do work. Something must have energy and transfer it through
doing work to make things happen.



file_data: 23.2|Work|513
Definition: Work
When a force exerted on an object causes it to move, work is done on the object (except if
the force and displacement are at right angles to each other).
This means that in order for work to be done, an object must be moved a distance d by a force
F, such that there is some non-zero component of the force in the direction of the
displacement. Work is calculated as:
W = F · x cos θ.
where F is the applied force, x is the displacement of the object and θ is the angle between
the applied force and the direction of motion.
Figure 23.1: The force F causes the object to be displaced by x at angle θ.
It is very important to note that for work to be done there must be a component of the applied
force in the direction of motion. Forces perpendicular to the direction of motion do no work.
For example work is done on the object in Figure 23.2,
Figure 23.2: (a) The force F causes the object to be displaced by x in the same direction as
the force. θ = 180◦ and cos θ = 1. Work is done in this situation. (b) A force F is applied to
the object. The object is displaced by y at right angles to the force. θ = 90◦ and cos θ = 0.
Work is not done in this situation.
Important: The Meaning of θ The angle θ is the angle between the force vector and the
displacement vector. In the following situations, θ = 0◦.
As with all physical quantities, work must have units. Following from the definition, work is
measured in N·m. The name given to this combination of S.I. units is the joule (symbol J).
Definition: Joule
1 joule is the work done when an object is moved 1 m under the application of a force of
1 N in the direction of motion.
The work done by an object can be positive or negative. Since force (Fk) and displacement (s)
are both vectors, the result of the above equation depends on their directions:
• If Fk acts in the same direction as the motion then positive work is being done. In this
case the object on which the force is applied gains energy.
• If the direction of motion and Fk are opposite, then negative work is being done. This
means that energy is transferred in the opposite direction. For example, if you try to push
a car uphill by applying a force up the slope and instead the car rolls down the hill you
are doing negative work on the car. Alternatively, the car is doing positive work on you!
Important: The everyday use of the word ”work” differs from the physics use. In physics,
only the component of the applied force that is parallel to the motion does work on an
object. So, for example, a person holding up a heavy book does no work on the book.






file_data: 23.3|Energy|519


file_data: 23.3.1|External and Internal Forces|519
In Grade 10, you saw that mechanical energy was conserved in the absence of external forces.
It is important to know whether a force is an internal force or an external force, because this is
related to whether the force can change an object’s total mechanical energy when it does work
upon an object.
When an external force (for example friction, air resistance, applied force) does work on an
object, the total mechanical energy (KE + PE) of that object changes. If positive work is done,
then the object will gain energy. If negative work is done, then the object will lose energy. The
gain or loss in energy can be in the form of potential energy, kinetic energy, or both. However,
the work which is done is equal to the change in mechanical energy of the object.
When an internal force does work on an object by an (for example, gravitational and spring
forces), the total mechanical energy (KE + PE) of that object remains constant but the
object’s energy can change form. For example, as an object falls in a gravitational field from a
high elevation to a lower elevation, some of the object’s potential energy is changed into
kinetic energy. However, the sum of the kinetic and potential energies remain constant. When
the only forces doing work are internal forces, energy changes forms - from kinetic to potential
(or vice versa); yet the total amount of mechanical is conserved.




file_data: 23.3.2|Capacity to do Work|520
Energy is the capacity to do work. When positive work is done on an object, the system doing
the work loses energy. In fact, the energy lost by a system is exactly equal to the work
done by the system. An object with larger potential energy has a greater capacity to do work.
This leads us to the work-energy theorem.
Definition: Work-Energy Theorem
The work-energy theorem states that the work done on an object is equal to the change in
its kinetic energy:
W = KE = KEf − KEi
The work-energy theorem is another example of the conservation of energy which you saw in
Grade 10.
Important: A force only does work on an object for the time that it is in contact with the
object. For example, a person pushing a trolley does work on the trolley, but the road does
no work on the tyres of a car if they turn without slipping (the force is not applied over any
distance because a different piece of tyre touches the road every instant.
Important: Energy Conservation
In the absence of friction, the work done on an object by a system is equal to the energy
gained by the object.
Work Done = Energy Transferred
In the presence of friction, only some of the energy lost by the system is transferred to useful
energy. The rest is lost to friction.
Total Work Done = Useful Work Done + Work Done Against Friction
In the example of a falling mass the potential energy is known as gravitational potential energy
as it is the gravitational force exerted by the earth which causes the mass to accelerate towards
the ground. The gravitational field of the earth is what does the work in this case.
Another example is a rubber-band. In order to stretch a rubber-band we have to do work on it.
This means we transfer energy to the rubber-band and it gains potential energy. This potential
energy is called elastic potential energy. Once released, the rubber-band begins to move and
elastic potential energy is transferred into kinetic energy.




file_data: 23.4|Power|525
Now that we understand the relationship between work and energy, we are ready to look at a
quantity that defines how long it takes for a certain amount of work to be done. For example,
a mother pushing a trolley full of groceries can take 30 s or 60 s to push the trolley down an
aisle. She does the same amount of work, but takes a different length of time. We use the idea
of power to describe the rate at which work is done.
Definition: Power
Power is defined as the rate at which work is done or the rate at which energy is expended.
The mathematical definition for power is:
P = F · v
The unit watt is named after Scottish inventor and engineer James Watt (19
January 1736 - 19 August 1819) whose improvements to the steam engine were
fundamental to the Industrial Revolution. A key feature of it was that it
brought the engine out of the remote coal fields into factories.
Historically, the horsepower (symbol hp) was the unit used to describe the
power delivered by a machine. One horsepower is equivalent to approximately
750 W. The horsepower is sometimes used in the motor industry to describe
the power output of an engine. Incidentally, the horsepower was derived by
James Watt to give an indication of the power of his steam engine in terms of
the power of a horse, which was what most people used to for example, turn a
mill wheel.
Machines are designed and built to do work on objects. All machines usually have a power
rating. The power rating indicates the rate at which that machine can do work upon other
objects.
A car engine is an example of a machine which is given a power rating. The power rating
relates to how rapidly the car can accelerate. Suppose that a 50 kW engine could accelerate
the car from 0 km · hr−1 to 60km · hr−1 in 16 s. Then a car with four times the power rating
(i.e. 200 kW) could do the same amount of work in a quarter of the time. That is, a 200 kW
engine could accelerate the same car from 0 km · hr−1 to 60km· hr−1 in 4 s.




file_data: 23.5|Important Equations and Quantities|529
Momentum:
~p = m~v (23.4)
Kinetic energy:
Ek =
1
2
m~v2 (23.5)
Principle of Conservation of Energy: Energy is never created nor destroyed, but is merely
transformed from one form to another.
Conservation of Mechanical Energy: In the absence of friction, the total mechanical energy
of an object is conserved.
When a force moves in the direction along which it acts, work is done.
Work is the process of converting energy.
Energy is the ability to do work.



file_data: 23.6|End of Chapter Exercises|529







file_data: 24|Doppler Effect - Grade 12|533


file_data: 24.1|Introduction|533
Have you noticed how the pitch of a car hooter changes as the car passes by or how the pitch
of a radio box on the pavement changes as you drive by? This effect is known as the Doppler
Effect and will be studied in this chapter.
The Doppler Effect is named after Johann Christian Andreas Doppler (29
November 1803 - 17 March 1853), an Austrian mathematician and physicist
who first explained the phenomenon in 1842.


file_data: 24.2|The Doppler Effect with Sound and Ultrasound|533
As seen in the introduction, there are two situations which lead to the Doppler Effect:
1. When the source moves relative to the observer, for example the pitch of a car hooter as
it passes by.
2. When the observer moves relative to the source, for example the pitch of a radio on the
pavement as you drive by.
Definition: Doppler Effect
The Doppler effect is the apparent change in frequency and wavelength of a wave when the
observer and the source of the wave move relative to each other.
We experience the Doppler effect quite often in our lives, without realising that it is science
taking place. The changing sound of a taxi hooter or ambulance as it drives past are examples
of this as you have seen in the introduction.
The question is how does the Doppler effect take place. Let us consider a source of sound
waves with a constant frequency and amplitude. The sound waves can be drawn as concentric
circles where each circle represents another wavefront, like in figure 24.1 below.
The sound source is the dot in the middle and is stationary. For the Doppler effect to take
place, the source must be moving. Let’s consider the following situation: The source (dot)
emits one peak (represented by a circle) that moves away from the source at the same rate in
all directions.
As this peak moves away, the source also moves and then emits the second peak. Now the two
circles are not concentric any more, but on the one side they are closer together and on the
other side they are further apart. This is shown in the next diagram.
If the source continues moving at the same speed in the same direction (i.e. with the same
velocity which you will learn more about later). then the distance between peaks on the right
of the source is the constant. The distance between peaks on the left is also constant but they
are different on the left and right.
This means that the time between peaks on the right is less so the frequency is higher. It is
higher than on the left and higher than if the source were not moving at all.
On the left hand side the peaks are further apart than on the right and further apart than if the
source were at rest - this means the frequency is lower.
When a car appoaches you, the sound waves that reach you have a shorter wavelength and a
higher frequency. You hear a higher sound. When the car moves away from you, the sound
waves that reach you have a longer wavelength and lower frequency. You hear a lower sound.
This change in frequency can be calculated by using:
where fL is the frequency perceived by the listener,
fS is the frequency of the source,
v is the speed of the waves,
vL the speed of the listener and
vS the speed of the source.
Radar-based speed-traps use the Doppler Effect. The radar gun emits radio
waves of a specific frequency. When the car is standing still, the waves reflected
waves are the same frequency as the waves emitted by the radar gun. When
the car is moving the Doppler frequency shift can be used to determine the
speed of the car.



file_data: 24.2.1|Ultrasound and the Doppler Effect|537
Ultrasonic waves (ultrasound) are sound waves with a frequency greater than 20 000 Hz (the
upper limit of hearing). These waves can be used in medicine to determine the direction of
blood flow. The device, called a Doppler flow meter, sends out sound waves. The sound waves
can travle through skin and tissue and will be reflected by moving objects in the body (like
blood). The reflected waves return to the flow meter where its frequency (received frequency)
is compared to the transmitted frequency. Because of the Doppler effect, blood that is moving
towards the flow meter will change the sound to a higher frequency (blue shift) and blood that
is moving away from the flow meter will cause a lower frequency (red shift).
Ultrasound can be used to determine whether blood is flowing in the right direction in the
circulation system of unborn babies, or identify areas in the body where blood flow is restricted
due to narrow veins. The use of ultrasound equipment in medicine is called sonography or
ultrasonography.



file_data: 24.3|The Doppler Effect with Light|537
Light is a wave and earlier you learnt how you can study the properties of one wave and apply
the same ideas to another wave. The same applies to sound and light. We know the Doppler
effect affects sound waves when the source is moving. Therefore, if we apply the Doppler effect
to light, the frequency of the emitted light should change when the source of the light is
moving relative to the observer.
When the frequency of a sound wave changes, the sound you hear changes. When the
frequency of light changes, the colour you would see changes.
This means that the Doppler effect can be observed by a change in sound (for sound waves)
and a change in colour (for light waves). Keep in mind that there are sounds that we cannot
hear (for example ultrasound) and light that we cannot see (for example ultraviolet light).
We can apply all the ideas that we learnt about the Doppler effect to light. When talking
about light we use slightly different names to describe what happens. If you look at the colour
spectrum (more details Chapter 30) then you will see that blue light has shorter wavelengths
than red light. If you are in the middle of the visible colours then longer wavelengths are more
red and shorter wavelengths are more blue. So we call shifts towards longer wavelengths
”red-shifts” and shifts towards shorter wavelengths ”blue-shifts”.
A shift in wavelength is the same as a shift in frequency. Longer wavelengths of light have
lower frequencies and shorter wavelengths have higher frequencies. From the Doppler effect we
know that when things move towards you any waves they emit that you measure are shifted to
shorter wavelengths (blueshifted). If things move away from you, the shift is to longer
wavelengths (redshifted).



file_data: 24.3.1|The Expanding Universe|538
Stars emit light, which is why we can see them at night. Galaxies are huge collections of stars.
An example is our own Galaxy, the Milky Way, of which our sun is only one of the millions of
stars! Using large telescopes like the Southern African Large Telescope (SALT) in the Karoo,
astronomers can measure the light from distant galaxies. The spectrum of light (see
Chapter ??) can tell us what elements are in the stars in the galaxies because each element
emits/absorbs light at particular wavelengths (called spectral lines). If these lines are observed
to be shifted from their usual wavelengths to shorter wavelengths, then the light from the
galaxy is said to be blueshifted. If the spectral lines are shifted to longer wavelengths, then the
light from the galaxy is said to be redshifted. If we think of the blueshift and redshift in
Doppler effect terms, then a blueshifted galaxy would appear to be moving towards us (the
observers) and a redshifted galaxy would appear to be moving away from us.
Important:
• If the light source is moving away from the observer (positive velocity) then the
observed frequency is lower and the observed wavelength is greater (redshifted).
• If the source is moving towards (negative velocity) the observer, the observed fre-
quency is higher and the wavelength is shorter (blueshifted).
Edwin Hubble (20 November 1889 - 28 September 1953) measured the Doppler shift of a large
sample of galaxies. He found that the light from distant galaxies is redshifted and he
discovered that there is a proportionality relationship between the redshift and the distance to
the galaxy. Galaxies that are further away always appear more redshifted than nearby galaxies.
Remember that a redshift in Doppler terms means a velocity of the light source away from the
observer. So why do all distant galaxies appear to be moving away from our Galaxy?
The reason is that the universe is expanding! The galaxies are not actually moving themselves,
rather the space between them is expanding!


file_data: 24.4|Summary|539


file_data: 24.5|End of Chapter Exercises|539





file_data: 25|Colour - Grade 12|541


file_data: 25.1|Introduction|541
We call the light that we humans can see ’visible light’. Visible light is actually just a small
part of the large spectrum of electromagnetic radiation which you will learn more about in
Chapter 30. We can think of electromagnetic radiation and visible light as transverse waves.
We know that transverse waves can be described by their amplitude, frequency (or wavelength)
and velocity. The velocity of a wave is given by the product of its frequency and wavelength:
v = f × λ (25.1)
However, electromagnetic radiation, including visible light, is special because, no matter what
the frequency, it all moves at a constant velocity (in vacuum) which is known as the speed of
light. The speed of light has the symbol c and is:
c = 3 × 108 m.s−1
Since the speed of light is c, we can then say:
c = f × λ




file_data: 25.2|Colour and Light|541
Our eyes are sensitive to visible light over a range of wavelengths from 390 nm to 780 nm (1
nm = 1 × 10−9 m). The different colours of light we see are related to specific frequencies
(and wavelengths) of visible light. The wavelengths and frequencies are listed in table 25.1.
You can see from table 25.1 that violet light has the shortest wavelengths and highest
frequencies while red light has the longest wavelengths and lowest frequencies.



file_data: 25.2.1|Dispersion of white light|544
White light, like the light which comes from the sun, is made up of all the visible wavelengths
of light. In other words, white light is a combination of all the colours of visible light.
In Chapter 7, you learnt that the speed of light is different in different substances. The speed
of light in different substances depends on the frequency of the light. For example, when white
light travels through glass, light of the different frequencies is slowed down by different
amounts. The lower the frequency, the less the speed is reduced which means that red light
(lowest frequency) is slowed down less than violet light (highest frequency). We can see this
when white light is incident on a glass prism.
Have a look at the picture below. When the white light hits the edge of the prism, the light
which travels through the glass is refracted as it moves from the less dense medium (air) to the
more dense medium (glass).
• The red light which is slowed down the least, is refracted the least.
• The violet light which is slowed down the most, is refracted the most.
When the light hits the other side of the prism it is again refracted but the angle of the prism
edge allows the light to remain separated into its different colours. White light is therefore
separated into its different colours by the prism and we say that the white light has been
dispersed by the prism.
The dispersion effect is also responsible for why we see rainbows. When sunlight hits drops of
water in the atmosphere, the white light is dispersed into its different colours by the water.


file_data: 25.3|Addition and Subtraction of Light|544


file_data: 25.3.1|Additive Primary Colours|544
The primary colours of light are red, green and blue. When all the primary colours are
superposed (added together), white light is produced. Red, green and blue are therefore called
the additive primary colours. All the other colours can be produced by different combinations
of red, green and blue.



file_data: 25.3.2|Subtractive Primary Colours|545
The subtractive primary colours are obtained by subtracting one of the three additive primary
colours from white light. The subtractive primary colours are yellow, magenta and cyan.
Magenta appears as a pinkish-purplish colour and cyan looks greenish-blue. You can see how
the primary colours of light add up to the different subtractive colours in the illustration below.



file_data: 25.3.3|Complementary Colours|546
Complementary colours are two colours of light which add together to give white.
You should have found that the complementary colours for red, green and blue are:
• Red and Cyan
• Green and Magenta
• Blue and Yellow



file_data: 25.3.4|Perception of Colour|546
The light-sensitive lining on the back inside half of the human eye is called the retina. The
retina contains two kinds of light sensitive cells or photoreceptors: the rod cells (sensitive to
low light) and the cone cells (sensitive to normal daylight) which enable us to see. The rods
are not very sensitive to colour but work well in dimly lit conditions. This is why it is possible
to see in a dark room, but it is hard to see any colours. Only your rods are sensitive to the low
light levels and so you can only see in black, white and grey. The cones enable us to see
colours. Normally, there are three kinds of cones, each containing a different pigment. The
cones are activated when the pigments absorb light. The three types of cones are sensitive to
(i.e. absorb) red, blue and green light respectively. Therefore we can perceive all the different
colours in the visible spectrum when the different types of cones are stimulated by different
amounts since they are just combinations of the three primary colours of light.
The rods and cones have different response times to light. The cones react quickly when bright
light falls on them. The rods take a longer time to react. This is why it takes a while (about 10
minutes) for your eyes to adjust when you enter a dark room after being outside on a sunny day.
Color blindness in humans is the inability to perceive differences between some
or all colors that other people can see. Most often it is a genetic problem, but
may also occur because of eye, nerve, or brain damage, or due to exposure to
certain chemicals. The most common forms of human color blindness result
from problems with either the middle or long wavelength sensitive cone
systems, and involve difficulties in discriminating reds, yellows, and greens from
one another. This is called ”red-green color blindness”. Other forms of color
blindness are much rarer. They include problems in discriminating blues from
yellows, and the rarest forms of all, complete color blindness or monochromasy,
where one cannot distinguish any color from grey, as in a black-and-white
movie or photograph.



file_data: 25.3.5|Colours on a Television Screen|547
If you look very closely at a colour cathode-ray television screen or computer screen, you will
see that there are very many small red, green and blue dots called phosphors on it. These dots
are caused to fluoresce (glow brightly) when a beam of electrons from the cathode-ray tube
behind the screen hits them. Since different combinations of the three primary colours of light
can produce any other colour, only red, green and blue dots are needed to make pictures
containing all the colours of the visible spectrum.



file_data: 25.4|Pigments and Paints|548
We have learnt that white light is a combination of all the colours of the visible spectrum and
that each colour of light is related to a different frequency. But what gives everyday objects
around us their different colours?
Pigments are substances which give an object its colour by absorbing certain frequencies of
light and reflecting other frequencies. For example, a red pigment absorbs all colours of light
except red which it reflects. Paints and inks contain pigments which gives the paints and inks
different colours.



file_data: 25.4.1|Colour of opaque objects|548
Objects which you cannot see through (i.e. they are not transparent) are called opaque.
Examples of some opaque objects are metals, wood and bricks. The colour of an opaque object
is determined by the colours (therefore frequencies) of light which it reflects. For example,
when white light strikes a blue opaque object such as a ruler, the ruler will absorb all
frequencies of light except blue, which will be reflected. The reflected blue light is the light
which makes it into our eyes and therefore the object will appear blue.
Opaque objects which appear white do not absorb any light. They reflect all the frequencies.
Black opaque objects absorb all frequencies of light. They do not reflect at all and therefore
appear to have no colour.



file_data: 25.4.2|Colour of transparent objects|548
If an object is transparent it means that you can see through it. For example, glass, clean
water and some clear plastics are transparent. The colour of a transparent object is determined
by the colours (frequencies) of light which it transmits (allows to pass through it). For
example, a cup made of green glass will appear green because it absorbs all the other
frequencies of light except green, which it transmits. This is the light which we receive in our
eyes and the object appears green.




file_data: 25.4.3|Pigment primary colours|549
The primary pigments and paints are cyan, magenta and yellow. When pigments or paints of
these three colours are mixed together in equal amounts they produce black. Any other colour
of paint can be made by mixing the primary pigments together in different quantities. The
primary pigments are related to the primary colours of light in the following way:
Colour printers only use 4 colours of ink: cyan, magenta, yellow and black. All
the other colours can be mixed from these!


file_data: 25.5|End of Chapter Exercises|550






file_data: 26|2D and 3D Wavefronts - Grade 12|553


file_data: 26.1|Introduction|553
You have learnt about the basic principles of reflection and refraction. In this chapter, you will
learn about phenomena that arise with waves in two and three dimensions: interference and
diffraction.



file_data: 26.2|Wavefronts|553
Consider three point sources of waves. If each source emits waves isotropically (i.e. the same in
all directions) we will get the situation shown in as shown in Figure 26.1.
We define a wavefront as the imaginary line that joins waves that are in phase. These are
indicated by the grey, vertical lines in Figure 26.1. The points that are in phase can be peaks,
troughs or anything in between, it doesn’t matter which points you choose as long as they are
in phase.
Figure 26.1: Wavefronts are imaginary lines joining waves that are in phase. In the example, the
wavefronts (shown by the grey, vertical lines) join all waves at the crest of their cycle.




file_data: 26.3|The Huygens Principle|554
Christiaan Huygens described how to determine the path of waves through a medium.
Definition: The Huygens Principle
Each point on a wavefront acts like a point source of circular waves. The waves emitted
from these point sources interfere to form another wavefront.
A simple example of the Huygens Principle is to consider the single wavefront in Figure 26.2.
Christiaan Huygens (14 April 1629 - 8 July 1695), was a Dutch mathematician,
astronomer and physicist; born in The Hague as the son of Constantijn
Huygens. He studied law at the University of Leiden and the College of Orange
in Breda before turning to science. Historians commonly associate Huygens
with the scientific revolution.
Huygens generally receives minor credit for his role in the development of
modern calculus. He also achieved note for his arguments that light consisted of
waves; see: wave-particle duality. In 1655, he discovered Saturn’s moon Titan.
He also examined Saturn’s planetary rings, and in 1656 he discovered that those
rings consisted of rocks. In the same year he observed and sketched the Orion
Nebula. He also discovered several interstellar nebulae and some double stars.



file_data: 26.4|Interference|556
Interference occurs when two identical waves pass through the same region of space at the
same time resulting in a superposition of waves. There are two types of interference which is of
interest: constructive interference and destructive interference.
Constructive interference occurs when both waves have a displacement in the same direction,
while destructive interference occurs when one wave has a displacement in the opposite
direction to the other, thereby resulting in a cancellation. There is no displacement of the
medium in destructive interference while for constructive interference the displacement of the
medium is greater than the individual displacements.
Constructive interference occurs when both waves have a displacement in the same direction,
this means they both have a peak or they both have a trough at the same place at the same
time. If they both have a peak then the peaks add together to form a bigger peak. If they both
have a trough then the trough gets deeper.
Destructive interference occurs when one wave has a displacement in the opposite direction to
the other, this means that the one wave has a peak and the other wave has a trough. If the
waves have identical magnitudes then the peak ”fills” up the trough and the medium will look
like there are no waves at that point. There will be no displacement of the medium. A place
where destructive interference takes places is called a node.
Waves can interfere at places where there is never a trough and trough or peak and peak or
trough and peak at the same time. At these places the waves will add together and the
resultant displacement will be the sum of the two waves but they won’t be points of maximum
interference.
Consider the two identical waves shown in the picture below. The wavefronts of the peaks are
shown as black lines while the wavefronts of the troughs are shown as grey lines. You can see
that the black lines cross other black lines in many places. This means two peaks are in the
same place at the same time so we will have constructive interference where the two peaks add
together to form a bigger peak.
Two points sources (A and B) radiate identical waves. The wavefronts of the peaks (black
lines) and troughs (grey lines) are shown. Constructive interference occurs where two black
lines intersect or where two gray lines intersect. Destructive interference occurs where a black
line intersects with a grey line.
You can see that the black lines cross other black lines in many places. This means two peaks
are in the same place at the same time so we will have constructive interference where the two
peaks add together to form a bigger peak.
When the grey lines cross other grey lines there are two troughs are in the same place at the
same time so we will have constructive interference where the two troughs add together to
form a bigger trough.
In the case where a grey line crosses a black line we are seeing a trough and peak in the same
place. These will cancel each other out and the medium will have no displacement at that
point.
• black line + black line = peak + peak = constructive interference
• grey line + grey line = trough + trough = constructive interference
• black line + grey line = grey line + black line = peak + trough = trough + peak =
destructive interference
On half the picture below, we have marked the constructive interference with a solid black
diamond and the destructive interference with a hollow diamond.
To see if you understand it, cover up the half we have marked with diamonds and try to work
out which points are constructive and destructive on the other half of the picture. The two
halves are mirror images of each other so you can check yourself.





file_data: 26.5|Diffraction|557
One of the most interesting, and also very useful, properties of waves is diffraction.
Definition: Diffraction
Diffraction is the ability of a wave to spread out in wavefronts as the wave passes through
a small aperture or around a sharp edge.
Extension: Diffraction
Diffraction refers to various phenomena associated with wave propagation, such
as the bending, spreading and interference of waves emerging from an aperture. It
occurs with any type of wave, including sound waves, water waves, electromagnetic
waves such as light and radio waves. While diffraction always occurs, its effects are
generally only noticeable for waves where the wavelength is on the order of the
feature size of the diffracting objects or apertures.
For example, if two rooms are connected by an open doorway and a sound is produced in a
remote corner of one of them, a person in the other room will hear the sound as if it originated
at the doorway.
As far as the second room is concerned, the vibrating air in the doorway is the source of the
sound. The same is true of light passing the edge of an obstacle, but this is not as easily
observed because of the short wavelength of visible light.
This means that when waves move through small holes they appear to bend around the sides
because there are not enough points on the wavefront to form another straight wavefront. This
is bending round the sides we call diffraction.
Extension: Diffraction
Diffraction effects are more clear for water waves with longer wavelengths.
Diffraction can be demonstrated by placing small barriers and obstacles in a ripple
tank and observing the path of the water waves as they encounter the obstacles.
The waves are seen to pass around the barrier into the regions behind it;
subsequently the water behind the barrier is disturbed. The amount of diffraction
(the sharpness of the bending) increases with increasing wavelength and decreases
with decreasing wavelength. In fact, when the wavelength of the waves are smaller
than the obstacle, no noticeable diffraction occurs.



file_data: 26.5.1|Diffraction through a Slit|558
When a wave strikes a barrier with a hole only part of the wave can move through the hole. If
the hole is similar in size to the wavelength of the wave diffractions occurs. The waves that
comes through the hole no longer looks like a straight wave front. It bends around the edges of
the hole. If the hole is small enough it acts like a point source of circular waves.
Now if allow the wavefront to impinge on a barrier with a hole in it, then only the points on
the wavefront that move into the hole can continue emitting forward moving waves - but
because a lot of the wavefront have been removed the points on the edges of the hole emit
waves that bend round the edges.
If you employ Huygens’ principle you can see the effect is that the wavefronts are no longer
straight lines.
Each point of the slit acts like a point source. If we think about the two point sources on the
edges of the slit and call them A and B then we can go back to the diagram we had earlier but
with some parts block by the wall.
If this diagram were showing sound waves then the sound would be louder (constructive
interference) in some places and quieter (destructive interference) in others. You can start to
see that there will be a pattern (interference pattern) to the louder and quieter places. If we
were studying light waves then the light would be brighter in some places than others
depending on the interferences.
The intensity (how bright or loud) of the interference pattern for a single narrow slit looks like
this:
The picture above shows how the waves add together to form the interference pattern. The
peaks correspond to places where the waves are adding most intensely and the zeroes are
places where destructive interference is taking place. When looking at interference patterns
from light the spectrum looks like:
There is a formula we can use to determine where the peaks and minimums are in the
interference spectrum. There will be more than one minimum. There are the same number of
minima on either side of the central peak and the distances from the first one on each side are
the same to the peak. The distances to the peak from the second minimum on each side is
also the same, in fact the two sides are mirror images of each other. We label the first
minimum that corresponds to a positive angle from the centre as m = 1 and the first on the
other side (a negative angle from the centre as m = −1, the second set of minima are labelled
m = 2 and m = −2 etc.
The equation for the angle at which the minima occur is
Definition: Interference Minima
The angle at which the minima in the interference spectrum occur is:
sin θ =
mλ
a
where
θ is the angle to the minimum
λ is the wavelength of the impinging wavefronts
m is the order of the mimimum, m = ±1,±2,±3, ...
From the formula you can see that a smaller wavelength for the same slit results in a smaller
angle to the interference minimum. This is something you just saw in the two worked
examples. Do a sanity check, go back and see if the answer makes sense. Ask yourself which
light had the longer wavelength, which light had the larger angle and what do you expect for
longer wavelengths from the formula.



file_data: 26.6|Shock Waves and Sonic Booms|562
Now we know that the waves move away from the source at the speed of sound. What
happens if the source moves at the same time as emitting sounds? Once a sound wave has
been emitted it is no longer connected to the source so if the source moves it doesn’t change
the way the sound wave is propagating through the medium. This means a source can actually
catch up with a sound waves it has emitted.
The speed of sound is very fast in air, about 340 m · s−1, so if we want to talk about a source
catching up to sound waves then the source has to be able to move very fast. A good source of
sound waves to discuss is a jet aircraft. Fighter jets can move very fast and they are very noisy
so they are a good source of sound for our discussion. Here are the speeds for a selection of
aircraft that can fly faster than the speed of sound.




file_data: 26.6.1|Subsonic Flight|563
Definition: Subsonic
Subsonic refers to speeds slower than the speed of sound.
When a source emits sound waves and is moving but slower than the speed of sound you get
the situation in this picture. Notice that the source moving means that the wavefronts and
therefore peaks in the wave are actually closer together in the one direction and further apart
in the other.
subsonic flight
If you measure the waves on the side where the peaks are closer together you’ll measure a
different wavelength than on the other side of the source. This means that the noise from the
source will sound different on the different sides. This is called the Doppler Effect.
Definition: Doppler Effect
when the wavelength and frequency measured by an observer are different to those emitted
by the source due to movement of the source or observer.




file_data: 26.6.2|Supersonic Flight|563
Definition: Supersonic
Supersonic refers to speeds faster than the speed of sound.
If a plane flies at exactly the speed of sound then the waves that it emits in the direction it is
flying won’t be able to get away from the plane. It also means that the next sound wave
emitted will be exactly on top of the previous one, look at this picture to see what the
wavefronts would look like:
Sometimes we use the speed of sound as a reference to describe the speed of the object
(aircraft in our discussion).
Definition: Mach Number
The Mach Number is the ratio of the speed of an object to the speed of sound in the
surrounding medium.
Mach number is tells you how many times faster than sound the aircraft is moving.
• Mach Number < 1 : aircraft moving slower than the speed of sound
• Mach Number = 1 : aircraft moving at the speed of sound
• Mach Number > 1 : aircraft moving faster than the speed of sound
To work out the Mach Number divide the speed of the aircraft by the speed of sound.
Mach Number =
vaircraft
vsound
Remember: the units must be the same before you divide.
If the aircraft is moving faster than the speed of sound then the wavefronts look like this:
If the source moves faster than the speed of sound a cone of wave fronts is created. This is
called a Mach cone. From constructive interference we know that two peaks that add together
form a larger peak. In a Mach cone many, many peaks add together to form a very large peak,
this is a sound wave so the large peak is a very very loud sound wave. This sounds like a huge
”boom” and we call the noise a sonic boom.
Definition: Sonic Boom
A sonic boom is the sound heard by an observer as a shockwave passes.




file_data: 26.6.3|Mach Cone|566
You can see that the shape of the Mach Cone depends on the speed of the aircraft. When the
Mach Number is 1 there is no cone but as the aircraft goes faster and faster the angle of the
cone gets smaller and smaller.
If we go back to the supersonic picture we can work out what the angle of the cone must be.
We build a triangle between how far the plane has moved and how far a wavefront at right
angles to the direction the plane is flying has moved:
An aircraft emits a sound wavefront. The wavefront moves at the speed of sound 340 m · s−1
and the aircraft moves at Mach 1.5, which is 1.5 × 340 = 510 m · s−1. The aircraft travels
faster than the wavefront. If we let the wavefront travel for a time t then the following diagram
will apply:
We know how fast the wavefront and the aircraft are moving so we know the distances that
they have traveled:
The angle between the cone that forms at the direction of the plane can be found from the
right-angle triangle we have drawn into the figure. We know that sin θ = opposite
hypotenuse which in
this figure means:
sin θ =
opposite
hypotenuse
sin θ =
vsound × t
vaircraft × t
sin θ =
vsound
vaircraft
In this case we have used sound and aircraft but a more general way of saying this is:
• aircraft = source
• sound = wavefront
We often just write the equation as:



file_data: 26.7|End of Chapter Exercises|568






file_data: 27|Wave Nature of Matter - Grade 12|571


file_data: 27.1|Introduction|571
In chapters 30 and 31 the so called wave-particle duality if light is described. This duality
states that light displays properties of both waves and of particles, depending on the
experiment performed. For example, interference and diffraction of light are properties of its
wave nature, while the photoelectric effect is a property of its particle nature. In fact we call a
particle of light a photon.
Hopefully you have realised that nature loves symmetry. So, if light which was originally
believed to be a wave also has a particle nature then perhaps particles, also display a wave
nature. In other words matter which which we originally thought of as particles may also
display a wave-particle duality.



file_data: 27.2|de Broglie Wavelength|571
Einstein showed that for a photon, its momentum, p, is equal to its energy, E divided the
speed of light, c:
p =
E
c
.
The energy of the photon can also be expressed in terms of the wavelength of the light, λ:
E =
hc
λ
,
where h is Planck’s constant. Combining these two equations we find that the the momentum
of the photon is related to its wavelength
p =
hc
cλ
=
h
λ
,
or equivalently
λ =
h
p
.
In 1923, Louis de Broglie proposed that this equation not only holds for photons, but also holds
for particles of matter. This is known as the de Broglie hypothesis
Definition: De Broglie Hypothesis
A particle of mass m moving with velocity v has a wavelength λ related to is momentum
p = mv by
λ =
h
p
=
h
mv
(27.1)
This wavelength, λ, is known as the de Broglie wavelength of the particle.
Since the value of Planck’s constant is incredibly small h = 6.63 × 10−34 J · s, the wavelike
nature of everyday objects is not really observable.
The de Broglie hypothesis was proposed by French physicist Louis de Broglie
(15 August 1892 – 19 March 1987) in 1923 in his PhD thesis. He was awarded
the Nobel Prize for Physics in 1929 for this work, which made him the first
person to receive a Nobel Prize on a PhD thesis.
This wavelength is considerably smaller than the diameter of a proton which is approximately
10−15 m. Hence the wave-like properties of this cricket ball are too small to be observed.
Although the electron and cricket ball in the two previous examples are travelling at the same
velocity the de Broglie wavelength of the electron is much larger than that of the cricket ball.
This is because the wavelength is inversely proportional to the mass of the particle.
Since the de Broglie wavelength of a particle is inversely proportional to its velocity, the
wavelength decreases as the velocity increases. This is confirmed in the last two examples with
the electrons. De Broglie’s hypothesis was confirmed by Davisson and Germer in 1927 when
they observed a beam of electrons being diffracted off a nickel surface. The diffraction means
that the moving electrons have a wave nature. They were also able to determine the wavelength
of the electrons from the diffraction. To measure a wavelength one needs two or more
diffacting centres such as pinholes, slits or atoms. For diffraction to occur the centres must be
separated by a distance about the same size as the wavelength. Theoretically, all objects, not
just sub-atomic particles, exhibit wave properties according to the de Broglie hypothesis.



file_data: 27.3|The Electron Microscope|574
We have seen that under certain circumstances particles behave like waves. This idea is used in
the electron microscope which is a type of microscope that uses electrons to create an image of
the target. It has much higher magnification or resolving power than a normal light
microscope, up to two million times, allowing it to see smaller objects and details.
Let’s first review how a regular optical microscope works. A beam of light is shone through a
thin target and the image is then magnified and focused using objective and ocular lenses. The
amount of light which passes through the target depends on the densities of the target since
the less dens regions allow more light to pass through than the denser regions. This means that
the beam of light which is partially transmitted through the target carries information about
the inner structure of the target.
The original form of the electron microscopy, the transmission electron microscopy, works in a
similar manner using electrons. In the electron microscope, electrons which are emitted by a
cathode are formed into a beam using magnetic lenses. This electron beam is then passed
through a very thin target. Again, the regions in the target with higher densities stop the
electrons more easily. So, the amount of electrons which pass through the different regions of
the target depend their densities. This means that the partially transmitted beam of electrons
carries information about the densities of the inner structure of the target. The spatial
variation in this information (the ”image”) is then magnified by a series of magnetic lenses and
it is recorded by hitting a fluorescent screen, photographic plate, or light sensitive sensor such
as a CCD (charge-coupled device) camera. The image detected by the CCD may be displayed
in real time on a monitor or computer. In figure ?? is an image of the polio virus obtained with
a transmission electron microscope.
The structure of an optical and electron microscope are compared in figure 27.3. While the
optical microscope uses light and focuses using lenses, the electron microscope uses electrons
and focuses using electromagnets.
The first electron microscope prototype was built in 1931 by the German
engineers Ernst Ruska and Maximillion Knoll. It was based on the ideas and
discoveries of Louis de Broglie. Although it was primitive and was not ideal for
practical use, the instrument was still capable of magnifying objects by four
hundred times. The first practical electron microscope was built at the
Electron microscopes are very useful as they are able to magnify objects to a much higher
resolution. This is because their de Broglie wavelengths are so much smaller than that of
visible light. You hopefully remember that light is diffracted by objects which are separated by
a distance of about the same size as the wavelength of the light. This diffraction then prevents
you from being able to focus the transmitted light into an image. So the sizes at which
diffraction occurs for a beam of electrons is much smaller than those for visible light. This is
why you can magnify targets to a much higher order of magnification using electrons rather
than visible light.
Extension: High-Resolution Transmission Electron Microscope (HRTEM)
There are high-resolution TEM (HRTEM) which have been built. However
their resolution is limited by spherical and chromatic aberration. Fortunately
though, software correction of the spherical aberration has allowed the production
of images with very high resolution. In fact the resolution is sufficient to show
carbon atoms in diamond separated by only 89 picometers and atoms in silicon at
78 picometers. This is at magnifications of 50 million times. The ability to
determine the positions of atoms within materials has made the HRTEM a very
useful tool for nano-technologies research. It is also very important for the
development of semiconductor devices for electronics and photonics.
Transmission electron microscopes produce two-dimensional images.
Extension: Scanning Electron Microscope (SEM)
The Scanning Electron Microscope (SEM) produces images by hitting the
target with a primary electron beam which then excites the surface of the target.
This causes secondary electrons to be emitted from the surface which are then
detected. So the the electron beam in the SEM is moved across the sample, while
detectors build an image from the secondary electrons.
Generally, the transmission electron microscope’s resolution is about an order of
magnitude better than the SEM resolution, however, because the SEM image relies
on surface processes rather than transmission it is able to image bulk samples and
has a much greater depth of view, and so can produce images that are a good
representation of the 3D structure of the sample.




file_data: 27.3.1|Disadvantages of an Electron Microscope|577
Electron microscopes are expensive to buy and maintain. they are also very sensitive to
vibration and external magnetic fields. This means that special facilities are required to house
microscopes aimed at achieving high resolutions. Also the targets have to be viewed in
vacuum, as the electrons would scatter with the molecules that make up air.
Extension: Scanning Electron Microscope (SEM)
Scanning electron microscopes usually image conductive or semi-conductive
materials best. A common preparation technique is to coat the target with a
several-nanometer layer of conductive material, such as gold, from a sputtering
machine; however this process has the potential to disturb delicate samples.
The targets have to be prepared in many ways to give proper detail, which may
result in artifacts purely the result of treatment. This gives the problem of
distinguishing artifacts from material, particularly in biological samples. Scientists
maintain that the results from various preparation techniques have been compared,
and as there is no reason that they should all produce similar artifacts, it is
therefore reasonable to believe that electron microscopy features correlate with
living cells.
The first electron microscope prototype was built in 1931 by the German
engineers Ernst Ruska and Maximillion Knoll. It was based on the ideas and
discoveries of Louis de Broglie. Although it was primitive and was not ideal for
practical use, the instrument was still capable of magnifying objects by four
hundred times. The first practical electron microscope was built at the
University of Toronto in 1938, by Eli Franklin Burton and students Cecil Hall,
James Hillier and Albert Prebus.
Although modern electron microscopes can magnify objects up to two million
times, they are still based upon Ruska’s prototype and his correlation between
wavelength and resolution. The electron microscope is an integral part of many
laboratories. Researchers use it to examine biological materials (such as
microorganisms and cells), a variety of large molecules, medical biopsy samples,
metals and crystalline structures, and the characteristics of various surfaces.



file_data: 27.3.2|Uses of Electron Microscopes|577
Electron microscopes can be used to study:
• the topography of an object − how its surface looks.
• the morphology of particles making up an object − its shape and size.
• the composition of an object − the elements and compounds that the object is
composed of and the relative amounts of them.
• the crystallographic information of the object − how the atoms are arranged in the
object.



file_data: 27.4|End of Chapter Exercises|578






file_data: 28|Electrodynamics - Grade 12|579


file_data: 28.1|Introduction|579
In Grade 11 you learnt how a magnetic field is generated around a current carrying conductor.
You also learnt how a current is generated in a conductor that moves in a magnetic field. This
chapter describes how conductors moved in a magnetic field are applied in the real-world.



file_data: 28.2|Electrical machines - generators and motors|579
We have seen that when a conductor is moved in a magnetic field or when a magnet is moved
near a conductor, such that the magnetic field is not parallel to the conductor, a current flows
in the conductor. The amount of current depends on the speed at which the conductor
experiences a changing magnetic field, the number of turns of the conductor and the
orientation of the plane of the conductor with respect to the magnetic field. The effect of the
orientation of the conductor with respect to the magnetic field is shown in Figure 28.1.
Figure 28.1: Series of figures showing that the magnetic flux through a conductor is dependent
on the angle that the plane of the conductor makes with the magnetic field. The greatest flux
passes through the conductor when the plane of the conductor is perpendicular to the magnetic
field lines as in (a). The number of field lines passing through the conductor decreases, as the
conductor rotates until it is parallel to the magnetic field.
If the current flowing in the conductor were plotted as a function of the angle between the
plane of the conductor and the magnetic field, then the current would vary as shown in
Figure 28.2. The current alternates about the zero value and is also known as an alternating
current (abbreviated AC).
Figure 28.2: Variation of current as angle of plane of conductor with the magnetic field changes.


file_data: 28.2.1|Electrical generators|580
AC generator
The principle of rotating a conductor in a magnetic field is used in electricity generators. A
generator converts mechanical energy into electrical energy.
Definition: Generator
A generator converts mechanical energy into electrical energy.
The layout of an AC generator is shown in Figure 28.3. The conductor in the shape of a coil is
connected to a ring. The conductor is then manually rotated in the magnetic field generating
an alternating emf. The slip rings are connected to the load via brushes.
If a machine is constructed to rotate a magnetic field around a set of stationary wire coils with
the turning of a shaft, AC voltage will be produced across the wire coils as that shaft is
rotated, in accordance with Faraday’s Law of electromagnetic induction. This is the basic
operating principle of an AC generator.
In an AC generator the two ends of the coil are each attached to a slip ring that makes contact
with brushes as the coil turns. The direction of the current changes with every half turn of the
coil. As one side of the loop moves to the other pole of the magnetic field, the current in it
changes direction. The two slip rings of the AC generator allow the current to change
directions and become alternating current.
AC generators are also known as alternators. They are found in motor cars to
charge the car battery.
DC generator
A DC generator is constructed the same way as an AC generator except that there is one slip
ring which is split into two pieces, called a commutator, so the current in the external circuit
does not change direction. The layout of a DC generator is shown in Figure 28.4. The
split-ring commutator accommodates for the change in direction of the current in the loop,
thus creating DC current going through the brushes and out to the circuit.
The shape of the emf from a DC generator is shown in Figure 28.5. The emf is not steady but
is more or less the positive halves of a sine wave.
AC versus DC generators
The problems involved with making and breaking electrical contact with a moving coil should
be obvious (sparking and heat), especially if the shaft of the generator is revolving at high
speed. If the atmosphere surrounding the machine contains flammable or explosive vapors, the
practical problems of spark-producing brush contacts are even greater.
An AC generator (alternator) does not require brushes and commutators to work, and so is
immune to these problems experienced by DC generators. The benefits of AC over DC with
regard to generator design is also reflected in electric motors. While DC motors require the use
of brushes to make electrical contact with moving coils of wire, AC motors do not. In fact, AC
and DC motor designs are very similar to their generator counterparts. The AC motor being
dependent upon the reversing magnetic field produced by alternating current through its
stationary coils of wire to rotate the rotating magnet around on its shaft, and the DC motor
being dependent on the brush contacts making and breaking connections to reverse current
through the rotating coil every 1/2 rotation (180 degrees).


file_data: 28.2.2|Electric motors|582
The basic principles of operation for a motor are the same as that of a generator, except that a
motor converts electrical energy into mechanical energy.
Definition: Motor
An electric motor converts electrical energy into mechanical energy.
Both motors and generators can be explained in terms of a coil that rotates in a magnetic field.
In a generator the coil is attached to an external circuit and it is mechanically turned, resulting
in a changing flux that induces an emf. In a motor, a current-carrying coil in a magnetic field
experiences a force on both sides of the coil, creating a torque which makes it turn.
Any coil carrying current can feel a force in a magnetic field, the force is the Lorentz force on
the moving charges in the conductor. We know that if the coil is parallel to the magnetic field
then the Lorentz force will be zero. The charge of opposite sides of the coil will be in opposite
directions because the charges are moving in opposite directions. This means the coil will
rotate.
Instead of rotating the loops through a magnetic field to create electricity, a current is sent
through the wires, creating electromagnets. The outer magnets will then repel the
electromagnets and rotate the shaft as an electric motor. If the current is AC, the two slip
rings are required to create an AC motor. An AC motor is shown in Figure 28.6
If the current is DC, split-ring commutators are required to create a DC motor. This is shown
in Figure 28.7.



file_data: 28.2.3|Real-life applications|582
Cars
A car contains an alternator that charges up its battery power the car’s electric system when its
engine is running. Alternators have the great advantage over direct-current generators of not
using a commutator, which makes them simpler, lighter, less costly, and more rugged than a
DC generator.
A car also contains a DC electric motor, the starter motor, to turn over the engine to start it.
A starter consists of the very powerful DC electric motor and starter solenoid that is attached
to the motor. A starter motor requires very high current to crank the engine, that’s why it’s
connected to the battery with large cables.
Electricity Generation
AC generators are mainly used in the real-world to generate electricity.




file_data: 28.2.4|Exercise - generators and motors|584


file_data: 28.3|Alternating Current|585
Most students of electricity begin their study with what is known as direct current (DC), which
is electricity flowing in a constant direction. DC is the kind of electricity made by a battery,
with definite positive and negative terminals).
However, we have seen that the electricity produced by a generator alternates and is therefore
known as alternating current(AC). The main advantage to AC is that the voltage can be
changed using transformers. That means that the voltage can be stepped up at power stations
to a very high voltage so that electrical energy can be transmitted along power lines at low
current and therefore experience low energy loss due to heating. The voltage can then be
stepped down for use in buildings and street lights.
In South Africa alternating current is generated at a frequency of 50 Hz.
The circuit symbol for alternating current is:
∼
Graphs of voltage against time and current against time for an AC circuit are shown in
Figure 28.9
In a DC circuit the current and voltage are constant. In an AC circuit the current and voltage
vary with time. The value of the current or voltage at any specific moment in time is called the
instantaneous current or voltage and is calculated as follows:
i = Imaxsin(2πft)
v = Vmaxsin(2πft)
i is the instantaneous current. Imax is the maximum current. v is the instantaneous voltage.
Vmax is the maximum voltage. f is the frequency of the AC and t is the time at which the
instantaneous current or voltage is being calculated.
This average value we use for AC is known as the root mean square (rms) average. This is
defined as:
Since AC varies sinusoidally, with as much positive as negative, doing a straight average would
get you zero for the average voltage. The rms value by-passes this problem.


file_data: 28.3.1|Exercise - alternating current|586


file_data: 28.4|Capacitance and inductance|586
Capacitors and inductors are found in many circuits. Capacitors store an electric field, and are
used as temporary power sources as well as minimize power fluctuations in major circuits.
Inductors work in conjunction with capacitors for electrical signal processing. Here we explain
the physics and applications of both.


file_data: 28.4.1|Capacitance|586
You have learnt about capacitance and capacitors in Grade 11. Please read through
section 17.5 to recap what you learnt about capacitance in a DC circuit.
In this section you will learn about capacitance in an AC circuit. A capacitor in an AC circuit
has reactance. Reactance in an AC circuit plays a similar role to resistance in a DC circuit.
The reactance of a capacitor XC is defined as:
XC = 1
2πfC
where C is the capacitance and f is the AC frequency.
If we examine the equation for the reactance of a capacitor, we see that the frequency is in the
denominator. Therefore, when the frequency is low, the capacitive reactance is very high. This
is why a capacitor blocks the flow of DC and low frequency AC because its reactance increases
with decreasing frequency.
When the frequency is high, the capacitive reactance is low. This is why a capacitor allows the
flow of high frequency AC because its reactance decreases with increasing frequency.



file_data: 28.4.2|Inductance|586
An inductor is a passive electrical device used in electrical circuits for its property of
inductance. An inductor is usually made as a coil (or solenoid) of conducting material, typically
copper wire, wrapped around a core either of air or of ferromagnetic material.
Electrical current through the conductor creates a magnetic flux proportional to the current. A
change in this current creates a change in magnetic flux that, in turn, generates an emf that
acts to oppose this change in current.
Inductance (measured in henries, symbol H) is a measure of the generated emf for a unit
change in current. For example, an inductor with an inductance of 1 H produces an emf of 1 V
when the current through the inductor changes at the rate of 1 A·s−1.
The inductance of an inductor is determined by several factors:
• the shape of the coil; a short, fat coil has a higher inductance than one that is thin and
tall.
• the material that conductor is wrapped around.
• how the conductor is wound; winding in opposite directions will cancel out the
inductance effect, and you will have only a resistor.
The inductance of a solenoid is defined by:
L = μ0AN2
l
where μ0 is the permeability of the core material (in this case air), A is the cross-sectional area
of the solenoid, N is the number of turns and l is the length of the solenoid.
Definition: Permeability
Permeability is the property of a material which describes the magnetisation developed in
that material when excited by a source.
The permeability of free space is 4πx10−7 henry per metre.
An inductor in an AC circuit also has a reactance, XL that is defined by:
XL = 2πfL
where L is the inductance and f is the frequency of the AC.
If we examine the equation for the reactance of an inductor, we see that inductive reactance
increases with increasing frequency. Therefore, when the frequency is low, the inductive
reactance is very low. This is why an inductor allows the flow of DC and low frequency AC
because its reactance decreases with decreasing frequency.
When the frequency is high, the inductive reactance is high. This is why an inductor blocks the
flow of high frequency AC because its reactance increases with increasing frequency.



file_data: 28.4.3|Exercise - capacitance and inductance|588


file_data: 28.5|Summary|588


file_data: 28.6|End of chapter exercise|589






file_data: 29|Electronics - Grade 12|591


file_data: 29.1|Introduction|591
Electronics and electrical devices surround us in daily life. From the street lights and water
pumps to computers and digital phones, electronics have enabled the digital revolution to
occur. All electronics are built on a backbone of simple circuits, and so an understanding of
circuits is vital in understanding more complex devices.
This chapter will explain the basic physics principles of many of the components of electronic
devices. We will begin with an explanation of capacitors and inductors. We see how these are
used in tuning a radio. Next, we look at active components such as transistors and operational
amplifiers. Lastly, the chapter will finish with an explanation of digital electronics, including
logic gates and counting circuits.
Before studying this chapter, you will want to remind yourself of:
• The meaning of voltage (V ), current (I) and resistance (R), as covered in Grade 10 (see
chapter 10), and Grade 11 (see chapter 19).
• Capacitors in electric circuits, as covered in Grade 11 (see section 17.6).
• Semiconductors, as covered in Grade 11 (see chapter 20).
• The meaning of an alternating current (see section 28.3).
• Capacitance (C) and Inductance (L) (see section 28.4).




file_data: 29.2|Capacitive and Inductive Circuits|591
Earlier in Grade 12, you were shown alternating currents (a.c.) and you saw that the voltage
and the current varied with time. If the a.c. supply is connected to a resistor, then the current
and voltage will be proportional to each other. This means that the current and voltage will
‘peak’ at the same time. We say that the current and voltage are in phase. This is shown in
Figure 29.1.
When a capacitor is connected to an alternating voltage, the maximum voltage is proportional
to the maximum current, but the maximum voltage does not occur at the same time as the
maximum current. The current has its maximum (it peaks) one quarter of a cycle before the
voltage peaks. Engineers say that the ‘current leads the voltage by 90◦’. This is shown in
Figure 29.2.
For a circuit with a capacitor, the instantaneous value of V
I is not constant. However the value
of Vmax
Imax
is useful, and is called the capacitive reactance (XC) of the component. Because it
is still a voltage divided by a current (like resistance), its unit is the ohm. The value of XC (C
Inductors are very similar, but the current peaks 90◦ after the voltage. This is shown in
Figure 29.3. Engineers say that the ‘current lags the voltage’. Again, the ratio of maximum
voltage to maximum current is called the reactance — this time inductive reactance (XL).
The value of the reactance depends on its inductance (L).
Definition: Reactance
The ratio of the maximum voltage to the maximum current when a capacitor or inductor is
connected to an alternating voltage. The unit of reactance is the ohm.
While inductive and capacitive reactances are similar, in one sense they are opposites. For an
inductor, the current peaks 90◦ after the voltage. For a capacitor the current peaks 90◦ ahead
of the voltage. When we work out the total reactance for an inductor and a capacitor in series,
we use the formula
to take this into account. This formula can also be used when there is more than one inductor
or more than one capacitor in the circuit. The total reactance is the sum of all of the inductive
reactances minus the sum of all the capacitive reactances. The magnitude (number) in the
final result gives the ratio of maximum voltage to maximum current in the circuit as a whole.
The sign of the final result tells you its phase. If it is positive, the current peaks 90◦ after the
voltage, if it is negative, the current peaks 90◦ before the voltage.
If a series circuit contains resistors as well, then the situation is more complicated. The
maximum current is still proportional to the maximum voltage, but the phase difference
between them won’t be 90◦. The ratio between the maximum voltage and maximum current is
called the impedance (Z), and its unit is also the ohm. Impedances are calculated using this
formula:
Z =
p
X2 + R2 (29.4)
where X is the total reactance of the inductors and capacitors in the circuit, and R is the total
resistance of the resistors in the circuit.
It is easier to understand this formula by thinking of a right angled triangle. Resistances are
drawn horizontally, reactances are drawn vertically. The hypotenuse of the triangle gives the
impedance. This is shown in Figure 29.4.
Definition: Impedance
The maximum voltage divided by the maximum current for any circuit. The unit of
impedance is the ohm.
It is important to remember that when resistors and inductances (or capacitors) are in a circuit,
the current will not be in phase with the voltage, so the impedance is not a resistance.
Similarly the current won’t be exactly 90◦ out of phase with the voltage so the impedance isn’t
a reactance either.
Most factories containing heavy duty electrical equipment (e.g. large motors)
have to pay extra money to their electricity supply company because the
inductance of the motor coils causes the current and voltage to get out of
phase. As this makes the electricity distribution network less efficient, a
financial penalty is incurred. The factory engineer can prevent this by
connecting capacitors into the circuit to reduce the reactance to zero, as in the
last question above. The current and voltage are then in phase again. We can’t
calculate the capacitance needed in this chapter, because the capacitors are
usually connected in parallel, and we have only covered the reactances and
impedances of series circuits.




file_data: 29.3|Filters and Signal Tuning|596


file_data: 29.3.1|Capacitors and Inductors as Filters|596
We have already seen how capacitors and inductors pass current more easily at certain
frequencies than others. To recap: if we examine the equation for the reactance of a capacitor,
we see that the frequency is in the denominator. Therefore, when the frequency is low, the
capacitive reactance is very high. This is why a capacitor blocks the flow of DC and low
frequency AC because its reactance increases with decreasing frequency.
When the frequency is high, the capacitive reactance is low. This is why a capacitor allows the
flow of high frequency AC because its reactance decreases with increasing frequency.
Therefore putting a capacitor in a circuit blocks the low frequencies and allows the high
frequencies to pass. This is called a high pass filter. A filter like this can be used in the ‘treble’
setting of a sound mixer or music player which controls the amount of high frequency signal
reaching the speaker. The more high frequency signal there is, the ‘tinnier’ the sound. A simple
high pass filter circuit is shown in Figure 29.5.
Similarly, if we examine the equation for the reactance of an inductor, we see that inductive
reactance increases with increasing frequency. Therefore, when the frequency is low, the
inductive reactance is very low. This is why an inductor allows the flow of DC and low
frequency AC because its reactance decreases with decreasing frequency.
When the frequency is high, the inductive reactance is high. This is why an inductor blocks the
flow of high frequency AC because its reactance increases with increasing frequency.
Therefore putting an inductor in a circuit blocks the high frequencies and allows the low
frequencies to pass. This is called a low pass filter. A filter like this can be used in the ‘bass’
setting of a sound mixer or music player which controls the amount of low frequency signal
reaching the speaker. The more low frequency signal there is, the more the sound ‘booms’. A
simple low pass filter circuit is shown in Figure 29.6.
Figure 29.5: A high pass filter. High frequencies easily pass through the capacitor and into the
next part of the circuit, while low frequencies pass through the inductor straight to ground.


file_data: 29.3.2|LRC Circuits, Resonance and Signal Tuning|596
A circuit containing a resistor, a capacitor and an inductor all in series is called an LRC circuit.
Because the components are in series, the current through each component at a particular time
will be the same as the current through the others. The voltage across the resistor will be in
phase with the current. The voltage across the inductor will be 90◦ ahead of the current (the
current always follows or lags the voltage in an inductor). The voltage across the capacitor will
be 90◦ behind the current (the current leads the voltage for a capacitor). The phases of the
three voltages are shown in Figure 29.7.
Figure 29.6: A low pass filter. Low frequencies pass through the inductor and into the next part
of the circuit, while high frequencies pass through the capacitor straight to ground.
Figure 29.7: The voltages across the separate components of an LRC circuit. Looking at the
peaks, you see that the voltage across the inductor VL ‘peaks’ first, followed 90◦ later by the
current I, followed 90◦ later by the voltage across the capacitor VC. The voltage across the
resistor is not shown — it is in phase with the current and peaks at the same time as the current.
59
The reactance of the inductor is 2πfL, and the reactance of the capacitor is 1/2πfC but with
the opposite phase. So the total reactance of the LRC circuit is
X = XL − XC = 2πfL −
1
2πfC
The impedance of the circuit as a whole is given by
Z =
p
X2 + R2 =
s
2πfL −
1
2πfC
2
+ R2
At different frequencies, the impedance will take different values. The impedance will have its
smallest value when the positive inductive reactance cancels out the negative capacitive
reactance. This occurs when
2πfL =
1
2πfC
so the frequency of minimum impedance must be
f =
1
2π√LC
This is called the resonant frequency of the circuit. This is the frequency at which you can
get the largest current for a particular supply voltage. It is also called the natural frequency
of the circuit. This means the frequency at which the circuit would oscillate by itself.
Definition: Resonance
Resonance occurs when a circuit is connected to an alternating voltage at its natural fre-
quency. A very large current in the circuit can build up, even with minimal power input.
An LRC circuit is very useful when we have a signal containing many different frequencies, and
we only want one of them. If a signal like this is connected to an LRC circuit, then only the
resonant frequency (and other frequencies close to it) will drive measureable currents. This
means that an LRC circuit can select one frequency from a range. This process is called signal
tuning.
When you set up a radio antenna, and amplify the radio signal it receives, you
find many different bands of frequencies — one from each radio station. When
you listen to the radio, you only want to listen to one station. An LRC circuit
in the radio (the tuning circuit) is set so that its resonant frequency is the
frequency of the station you want to listen to. This means that of the many
radio stations broadcasting, you only hear one. When you adjust the tuning
dial on the radio, it changes the capacitance of the capacitor in the tuning
circuit. This changes the resonant frequency, and this changes the radio station
that you will hear.


file_data: 29.4|Active Circuit Elements|599
The components you have been learning about so far — resistors, capacitors and inductors —
are called passive components. They do not change their behaviour or physics in response to
changes in voltage or current. Active components are quite different. Their response to
changes in input allows them to make amplifiers, calculators and computers.



file_data: 29.4.1|The Diode|599
A diode is an electronic device that allows current to flow in one direction only.
A diode consists of two doped semi-conductors joined together so that the resistance is low
when connected one way and very high the other way.
Figure 29.9: Operation of a diode. (a) The diode is forward biased and current is permitted.
The negative terminal of the battery is connected to the negative terminal of the diode. (b) The
diode is reverse biased and current flow is not allowed. The negative terminal of the battery is
connected to the positive terminal of the diode.
A full explanation of diode operation is complex. Here is a simplified description. The diode
consists of two semiconductor blocks attached together. Neither block is made of pure silicon
— they are both doped. Doping was described in more detail in Section 10.3.
In short, p-type semiconductor has fewer free electrons than normal semiconductor. ‘P’ stands
for ‘positive’, meaning a lack of electrons, although the material is actually neutral. The
locations where electrons are missing are called holes. This material can conduct electricity
well, because electrons can move into the holes, making a new hole somewhere else in the
material. Any extra electrons introduced into this region by the circuit will fill some or all of
the holes.
In n-type semiconductor, the situation is reversed. The material has an more free electrons
than normal semiconductor. ‘N’ stands for ‘negative’, meaning an excess of electrons, although
the material is actually neutral.
When a p-type semiconductor is attached to an n-type semiconductor, some of the free
electrons in the n-type move across to the p-type semiconductor. They fill the available holes
near the junction. This means that the region of the n-type semiconductor nearest the junction
has no free electrons (they’ve moved across to fill the holes). This makes this n-type
semiconductor positively charged. It used to be electrically neutral, but has since lost electrons.
The region of p-type semiconductor nearest the junction now has no holes (they’ve been filled
in by the migrating electrons). This makes the p-type semiconductor negatively charged. It
used to be electrically neutral, but has since gained electrons.
Without free electrons or holes, the central region can not conduct electricity well. It has a
high resistance, and is called the depletion band. This is shown in Figure 29.10.
You can explain the high resistance in a different way. A free electron in the n-type
semiconductor will be repelled from the p-type semiconductor because of its negative charge.
The electron will not go into the depletion band, and certainly won’t cross the band to the
p-type semiconductor. You may ask, “But won’t a free electron in the p-type semiconductor be
attracted across the band, carrying a current?” But there are no free electrons in p-type
semiconductor, so no current of this kind can flow.
If the diode is reverse-biased, the + terminal of the battery is connected to the n-type
semiconductor. This makes it even more negatively charged. It also removes even more of the
free electrons near the depletion band. At the same time, the − terminal of the battery is
connected to the p-type silicon. This will supply free electrons and fill in more of the holes next
to the depletion band. Both processes cause the depletion band to get wider. The resistance of
the diode (which was already high) increases. This is why a reverse-biased diode does not
conduct.
Another explanation for the increased resistance is that the battery has made the p-type
semiconductor more negative than it used to be, making it repel any electrons from the n-type
semiconductor which attempt to cross the depletion band.
On the other hand, if the diode is forward biased, the depletion band is made narrower. The
negative charge on the p-type silicon is cancelled out by the battery. The greater the voltage
used, the narrower the depletion band becomes. Eventually, when the voltage is about 0,6 V
(for silicon) the depletion band disappears. Once this has occurred, the diode conducts very
well.
Figure 29.10: A diode consists of two doped semi-conductors joined together so that the resis-
tance is low when connected one way and very high the other way.




file_data: 29.4.2|The Light Emitting Diode (LED)|601
A light-emitting diode (LED) is a diode device that emits light when charge flows in the correct
direction through it. If you apply a voltage to force current to flow in the direction the LED
allows it will light up.
Extension: Circuit Symbols
This notation of having two small arrows pointing away from the device is
common to the schematic symbols of all light-emitting semiconductor devices.
Conversely, if a device is light-activated (meaning that incoming light stimulates
it), then the symbol will have two small arrows pointing toward it. It is interesting
to note, though, that LEDs are capable of acting as light-sensing devices: they will
generate a small voltage when exposed to light, much like a solar cell on a small
scale. This property can be gainfully applied in a variety of light-sensing circuits.
The color depends on the semiconducting material used to construct the LED, and can be in
the near-ultraviolet, visible or infrared part of the electromagnetic spectrum.
Nick Holonyak Jr. (1928 ) of the University of Illinois at Urbana-Champaign
developed the first practical visible-spectrum LED in 1962.
Light emission
The wavelength of the light emitted, and therefore its color, depends on the materials forming
the p-n junction. A normal diode, typically made of silicon or germanium, emits invisible
far-infrared light (so it can’t be seen), but the materials used for an LED have emit light
corresponding to near-infrared, visible or near-ultraviolet frequencies.
LED applications
LEDs have many uses. Some of these are given here.
• thin, lightweight message displays, e.g. in public information signs (at airports and
railway stations, among other places)
• status indicators, e.g. on/off lights on professional instruments and consumers
audio/video equipment
• infrared LEDs in remote controls (for TVs, VCRs, etc)
• clusters of LEDs are used in traffic signals, replacing ordinary bulbs behind colored glass
• car indicator lights and bicycle lighting
• calculator and measurement instrument displays (seven segment displays), although now
mostly replaced by LCDs
• red or yellow LEDs are used in indicator and [alpha]numeric displays in environments
where night vision must be retained: aircraft cockpits, submarine and ship bridges,
astronomy observatories, and in the field, e.g. night time animal watching and military
field use
• red or yellow LEDs are also used in photographic darkrooms, for providing lighting which
does not lead to unwanted exposure of the film
• illumination, e.g. flashlights (a.k.a. torches, UK), and backlighting for LCD screens
• signaling/emergency beacons and strobes
• movement sensors, e.g. in mechanical and optical computer mice and trackballs
• in LED printers, e.g. high-end color printers
LEDs offer benefits in terms of maintenance and safety.
• The typical working lifetime of a device, including the bulb, is ten years, which is much
longer than the lifetimes of most other light sources.
• LEDs fail by dimming over time, rather than the abrupt burn-out of incandescent bulbs.
• LEDs give off less heat than incandescent light bulbs and are less fragile than fluorescent
lamps.
• Since an individual device is smaller than a centimetre in length, LED-based light sources
used for illumination and outdoor signals are built using clusters of tens of devices.
Because they are monochromatic, LED lights have great power advantages over white lights
where a specific color is required. Unlike the white lights, the LED does not need a filter that
absorbs most of the emitted white light. Colored fluorescent lights are made, but they are not
widely available. LED lights are inherently colored, and are available in a wide range of colors.
One of the most recently introduced colors is the emerald green (bluish green, about 500 nm)
that meets the legal requirements for traffic signals and navigation lights.
There are applications that specifically require light that does not contain any blue component.
Examples are photographic darkroom safe lights, illumination in laboratories where certain
photo-sensitive chemicals are used, and situations where dark adaptation (night vision) must be
preserved, such as cockpit and bridge illumination, observatories, etc. Yellow LED lights are a
good choice to meet these special requirements because the human eye is more sensitive to
yellow light.



file_data: 29.4.3|Transistor|603
The diode is the simplest semiconductor device, made up of a p-type semiconductor and an
n-type semiconductor in contact. It can conduct in only one direction, but it cannot control the
size of an electric current. Transistors are more complicated electronic components which can
control the size of the electric current flowing through them.
This enables them to be used in amplifiers. A small signal from a microphone or a radio
antenna can be used to control the transistor. In response, the transistor will then increase and
decrease a much larger current which flows through the speakers.
One of the earliest popular uses of transistors was in cheap and portable radios.
Before that, radios were much more expensive and contained glass valves which
were fragile and needed replacing. In some parts of the world you can still hear
people talking about their ‘transistor’ — they mean their portable radio.
You can also use a small current to turn the transistor on and off. The transistor then controls
a more complicated or powerful current through other components. When a transistor is used
in this way it is said to be in switching mode as it is acting as a remotely controlled switch. As
we shall see in the final sections of this chapter, switching circuits can be used in a computer
to process and store digital information. A computer would not work without the millions (or
billions) of transistors in it.
There are two main types of transistor - bipolar transistors (NPN or PNP), and field effect
transistors (FETs). Both use doped semiconductors, but in different ways. You are mainly
required to know about field effect transistors (FETs), however we have to give a brief
description of bipolar transistors so that you see the difference.
Bipolar Transistors
Bipolar transistors are made of a doped semiconductor ‘sandwich’. In an NPN transistor, a
very thin layer of p-type semiconductor is in between two thicker layers of n-type
semiconductor. This is shown in Figure 29.11. Similarly an PNP transistor consists of a very
thin n-type layer in between two thicker layers of p-type semiconductor.
In an NPN transistor a small current of electrons flows from the emitter (E) to the base (B).
Simultaneously, a much larger current of electrons flows from the emitter (E) to the collector
(C). If you lower the number of electrons able to leave the transistor at the base (B), the
transistor automatically reduces the number of electrons flowing from emitter (E) to collector
(C). Similarly, if you increase the current of electrons flowing out of the base (B), the transistor
automatically also increases the current of electrons flowing from emitter (E) to collector (C).
The transistor is designed so that the current of electrons from emitter to collector (IEC) is
proportional to the current of electrons from emitter to base (IEB). The constant of
proportionality is known as the current gain β. So IEC = βIEB.
How does it do it? The answer comes from our work with diodes. Electrons arriving at the
emitter (n-type semiconductor) will naturally flow through into the central p-type since the
base-emitter junction is forward biased. However if none of these electrons are removed from
the base, the electrons flowing into the base from the emitter will fill all of the available ‘holes’.
Accordingly, a large depletion band will be set up. This will act as an insulator preventing
current flow into the collector as well. On the other hand, if the base is connected to a positive
voltage, a small number of electrons will be removed by the base connection. This will prevent
the ‘holes’ in the base becoming filled up, and no depletion band will form. While some
electrons from the emitter leave via the base connection, the bulk of them flow straight on to
the collector. You may wonder how the electrons get from the base into the collector (it seems
to be reverse biased). The answer is complicated, but the important fact is that the p-type
layer is extremely thin. As long as there is no depletion layer, the bulk of the electrons will have
no difficulty passing straight from the n-type emitter into the n-type collector. A more
satisfactory answer can be given to a university student once band theory has been explained.
Summing up, in an NPN transistor, a small flow of electrons from emitter (E) to base (B)
allows a much larger flow of electrons from emitter (E) to collector (C). Given that
conventional current (flowing from + to −) is in the opposite direction to electron flow, we say
that a small conventional current from base to emitter allows a large current to flow from
collector to emitter.
A PNP transistor works the other way. A small conventional current from emitter to base
allows a much larger conventional current to flow from emitter to collector. The operation is
more complicated to explain since the principal charge carrier in a PNP transistor is not the
electron but the ‘hole’.
The operation of NPN and PNP transistors (in terms of conventional currents) is summarized
in Figure 29.12.
The transistor is considered by many to be one of the greatest discoveries or
inventions in modern history, ranking with banking and the printing press. Key
to the importance of the transistor in modern society is its ability to be
produced in huge numbers using simple techniques, resulting in vanishingly
small prices. Computer “chips” consist of millions of transistors and sell for
Rands, with per-transistor costs in the thousandths-of-cents. The low cost has
meant that the transistor has become an almost universal tool for
non-mechanical tasks. Whereas a common device, say a refrigerator, would
have used a mechanical device for control, today it is often less expensive to
simply use a few million transistors and the appropriate computer program to
carry out the same task through ”brute force”. Today transistors have replaced
almost all electromechanical devices, most simple feedback systems, and appear
in huge numbers in everything from computers to cars.
The transistor was invented at Bell Laboratories in December 1947 (first
demonstrated on December 23) by John Bardeen, Walter Houser Brattain, and
William Bradford Shockley, who were awarded the Nobel Prize in physics in
1956.
The Field Effect Transistor (FET)
To control a bipolar transistors, you control the current flowing into or out of its base. The
other type of transistor is the field effect transistor (FET). FETs work using control voltages
instead. Accordingly they can be controlled with much smaller currents and are much more
economic to use.
No-one would build a computer with billions of bipolar transistors — the
current in each transistor’s base might be small, but when you add up all of the
base currents in the millions of transistors, the computer as a whole would be
consuming a great deal of electricity and making a great deal of heat. Not only
is this wasteful, it would prevent manufacturers making a computer of
convenient size. If the transistors were too close together, they would overheat.
Figure 29.13: A field effect transistor (FET). The diagram on the left shows the semiconductor
structure. The diagram on the right shows its circuit symbol.
The three terminals of the FET are called the source (S), drain (D) and gate (G), as shown in
Figure 29.13. When the gate is not connected, a current of electrons can flow from source (S)
to drain (D) easily along the channel. The source is, accordingly, the negative terminal of the
transistor. The drain, where the electrons come out, is the positive terminal of the transistor.
A few electrons will flow from the n-type channel into the p-type semiconductor of the gate
when the device is manufactured. However, as these electrons are not removed (the gate is not
connected), a depletion band is set up which prevents further flow into the gate.
In operation, the gate is connected to negative voltages relative to the source. This makes the
p-n junction between gate and channel reverse-biased. Accordingly no current flows from the
source into the gate. When the voltage of the gate is lowered (made more negative), the
depletion band becomes wider. This enlarged depletion band takes up some of the space of the
channel. So the lower the voltage of the gate (the more negative it is relative to the source),
the larger the depletion band. The larger the depletion band, the narrower the channel. The
narrower the channel, the harder it is for electrons to flow from source to drain.
The voltage of the gate is not the only factor affecting the current of electrons between the
source and the drain. If the external circuit has a low resistance, electrons are able to leave the
drain easily. If the external circuit has a high resistance, electrons leave the drain slowly. This
creates a kind of ‘traffic jam’ which slows the passage of further electrons. In this way, the
voltage of the drain regulates itself, and is more or less independent of the current demanded
from the drain.
Once these two factors have been taken into account, it is fair to say that the positive output
voltage (the voltage of the drain relative to the source) is proportional to the negative input
voltage (the voltage of the gate relative to the source).
For this reason, the field effect transistor is known as a voltage amplifier. This contrasts with
the bipolar transistor which is a current amplifier.



file_data: 29.4.4|The Operational Amplifier|607
The operational amplifier is a special kind of voltage amplifier which is made from a handful of
bipolar or field effect transistors. Operational amplifiers are usually called op-amps for short.
They are used extensively in all kinds of audio equipment (amplifiers, mixers and so on) and in
instrumentation. They also have many other uses in other circuit - for example comparing
voltages from sensors.
Operational amplifiers are supplied on Integrated Circuits (I.C.s). The most famous operational
amplifier I.C. is numbered 741 and contains a single operational amplifier on an integrated
circuit (‘chip’) with eight terminals. Other varieties can be bought, and you can get a single
integrated circuit with two or four ‘741’-type operational amplifiers on it.
The symbol for an op-amp is shown in Figure 29.14. The operational amplifier has two input
terminals and one output terminal. The voltage of the output terminal is proportional to the
difference in voltage between the two input terminals. The output terminal is on the right (at
the sharp point of the triangle). The two input terminals are drawn on the left. One input
terminal (labelled with a + on diagrams) is called the non-inverting input. The other input
terminal (labelled −) is called the inverting input. The labels + and − have nothing to do
with the way in which the operational amplifier is connected to the power supply. Operational
amplifiers must be connected to the power supply, but this is taken for granted when circuit
diagrams are drawn, and these connections are not shown on circuit diagrams. Usually, when
drawing electronic circuits, ‘0V’ is taken to mean the negative terminal of the power supply.
This is not the case with op-amps. For an op-amp, ‘0V’ refers to the voltage midway between
the + and − of the supply.
The output voltage of the amplifier Vout is given by the formula
here A is a constant called the open loop gain, and V+ and V− are the voltages of the two
input terminals. That said, the output voltage can not be less than the voltage of the negative
terminal of the battery supplying it or higher than the positive terminal of the battery supplying
it. You will notice that Vout is positive if V+ > V− and negative if V+ < V−. This is why the − input is called the inverting input: raising its voltage causes the output voltage to drop.
The input resistance of an operational amplifier is very high. This means that very little current
flows into the input terminals during operation.
If all of the transistors in the operational amplifier were identical then the output voltage would
be zero if the two inputs were at equal voltages. In practice this is not quite the case, and for
sensitive work a trimming potentiometer is connected. This is adjusted until the op-amp is
zeroed correctly.
Simple operational amplifiers require the trimming potentiometer to be built into the circuit
containing them, and an example is shown in Figure 29.15. Other operational amplifier designs
incorporate separate terminals for the trimming potentiometer. These special terminals are
labelled offset on the manufacturer’s diagram. The exact method of connecting the
potentiometer to the offset terminals can depend on the design of the operational amplifier,
and you need to refer to the manufacturer’s data sheet for details of which potentiometer to
use and how to connect it.
For most commercially produced operational amplifiers (known as op-amps for short), the open
loop gain A is very large and does not stay constant. Values of 100 000 are typical. Usually a
designer would want an amplifier with a stable gain of smaller value, and builds the operational
amplifier into a circuit like the one in Figure 29.15.



file_data: 29.5|The Principles of Digital Electronics|609
The circuits and components we have discussed are very useful. You can build a radio or
television with them. You can make a telephone. Even if that was all there was to electronics,
it would still be very useful. However, the great breakthrough in the last fifty years or so has
been in digital electronics. This is the subject which gave us the computer. The computer has
revolutionized the way business, engineering and science are done. Small computers
programmed to do a specific job (called microprocessors) are now used in almost every
electronic machine from cars to washing machines. Computers have also changed the way we
communicate. We used to have telegraph or telephone wires passing up and down a country —
each one carrying one telephone call or signal. We now have optic fibres each capable of
carrying tens of thousands of telephone calls using digital signals.
So, what is a digital signal? Look at Figure 29.16. A normal signal, called an analogue signal,
carries a smooth wave. At any time, the voltage of the signal could take any value. It could be
2,00 V or 3,53 V or anything else. A digital signal can only take certain voltages. The simplest
case is shown in the figure — the voltage takes one of two values. It is either high, or it is low.
It never has any other value.
These two special voltages are given symbols. The low voltage level is written 0, while the high
voltage level is written as 1. When you send a digital signal, you set the voltage you want (0 or
1), then keep this fixed for a fixed amount of time (for example 0.01 μs), then you send the
next 0 or 1. The digital signal in Figure 29.16 could be written 01100101.
Why are digital signals so good?
Figure 29.16: The difference between normal (analogue) signals and digital signals. The analogue
signal is on the left.
1. Using a computer, any information can be turned into a pattern of 0s and 1s. Pictures,
recorded music, text and motion pictures can all be turned into a string of 0s and 1s and
transmitted or stored in the same way. The computer receiving the signal at the other
end converts it back again. A Compact Disc (CD) for example, can store music or text or
pictures, and all can be read using a computer.
2. The 0 and the 1 look very different. You can immediately tell if a 0 or a 1 is being sent.
Even if there is interference, you can still tell whether the sender sent a 0 or a 1. This
means that fewer mistakes are made when reading a digital signal. This is why the best
music recording technologies, and the most modern cameras, for example, all use digital
technology.
3. Using the 0s and 1s you can count, and do all kinds of mathematics. This will be
explained in more detail in the next section.
The simplest digital circuits are called logic gates. Each logic gate makes a decision based on
the information it receives. Different logic gates are set up to make the decisions in different
ways. Each logic gate will be made of many microscopic transistors connected together within
a thin wafer of silicon. This tiny circuit is called an Integrated Circuit or I.C. - all the parts are
in one place (integrated) on the silicon wafer.


file_data: 29.5.1|Logic Gates|610
There are five main types of logic gate: NOT, AND, OR, NAND and NOR. Each one makes its
decision in a different way.
The NOT Gate
Problem: You want an automatic circuit in your office to turn on the heating in the winter.
You already have a digital electronic temperature sensor. When the temperature is high, it
sends out a 1. When the office is cold, it sends out a 0. If this signal were sent straight to the
heater, the heater would turn on (1) when it was already hot, and would stay off when it was
cold. This is wrong! To make the heater work, we need a circuit which will change a 0 (from
the sensor) into a 1 (to send to the heater). This will make the heater come on when it is cold.
You also want it to change a 1 (from the sensor) into a 0 (to send to the heater). This will
turn the heater off when the room is hot. This circuit is called an inverter or NOT gate. It
changes 0 into 1 (1 is NOT 0). It changes 1 into 0 (0 is NOT 1). It changes a signal into what
it is NOT.
The symbol for the NOT gate is:
The action of the NOT gate is written in a table called a truth table. The left column shows
the possible inputs on different rows. The right column shows what the output (decision) of
the circuit will be for that input. The truth table for the NOT gate is shown below.
When you read the truth table, the top row says, “If the input is 0, the output will be 1.” For
our heater, this means, “If the room is cold, the heater will turn on.” The bottom row says, “If
the input is 1, the output will be 0.” For our heater, this means, “If the room is hot, the heater
will switch off.”
The AND Gate
Problem: An airliner has two toilets. Passengers get annoyed if they get up from their seat
only to find that both toilets are being used and they have to go back to their seat and wait.
You want to fit an automatic circuit to light up a display if both toilets are in use. Then
passengers know that if the light is off, there will be a free toilet for them to use. There is a
sensor in each toilet. It gives out a 0 of the toilet is free, and a 1 if it is in use. You want to
send a 1 to the display unit if both sensors are sending 1s. To do this, you use an AND gate.
The symbol for the AND gate is:
The truth table for the AND gate is shown below. An AND gate has two inputs (the NOT gate
only had one). This means we need four rows in the truth table, one for each possible set of
inputs. The first row, for example, tells us what the AND gate will do if both inputs are 0. In
our airliner, this means that both toilets are free. The right column has a 0 showing that the
output will be 0, so the display will not light up. The second row has inputs of 0 and 1 (the
first toilet is free, the other is in use). Again the output is 0. The third row tells us what will
happen if the inputs are 1 and 0 (the first toilet is in use, and the second is free). Finally, the
last line tells us what will happen if both inputs are 1 (both toilets are in use). It is only in this
case that the output is 1 and the display lights up.
This device is called an AND gate, because the output is only 1 if one input AND the other
input are both 1.
Extension: Using 0 and 1 to mean True and False
When we use logic gates we use the low voltage state 0 to represent ‘false’.
The high voltage state 1 represents ‘true’. This is why the word AND is so
appropriate. A AND B is true (1) if, and only if, A is true (1) AND B is true (1).
Extension: AND and multiplication
Sometimes, the AND operation is written as multiplication. A AND B is
written AB. If either A or B are 0, then AB will also be 0. For AB to be 1, we need
A and B to both be 1. Multiplication of the numbers 0 and 1 does exactly the
same job as an AND gate.
The NAND Gate
Problem: You build the circuit for the airliner toilets using an AND gate. Your customer is
pleased, but she says that it would be better if the display lit up when there was a free toilet.
In other words, the display should light up unless both toilets are in use. To do this we want a
circuit which does the opposite of an AND gate. We want a circuit which would give the
output 0 if an AND gate would give 1. We want a circuit which would give the output 1 if an
AND gate would give 0. This circuit is called a NAND gate.
The symbol for the NAND gate is:
You may have noticed that we could have done this job on the airliner by using our earlier
circuit, with a NOT gate added between the original AND gate and the display. This is where
the word NAND comes from — it is short for NotAND.
The OR Gate
Problem: A long, dark corridor has two light switches — one at each end of the corridor. The
switches each send an output of 0 to the control unit if no-one has pressed the switch. If
someone presses the switch, its output is 1. The lights in the corridor should come on if either
switch is pressed. To do this job, the control unit needs an OR gate. The symbol for the OR
gate is:
The truth table for the OR gate is shown.
You can see that the output is 1 (and the lights come on in the corridor) if either one switch
OR the other is pressed. Pressing both switches also turns on the lights, as the last row in the
table shows.
Extension: OR and addition
Sometimes you will see A OR B written mathematically as A+B. This makes
sense, since if A=0 and B=0, then A OR B = A+B = 0. Similarly, if A=0 and
B=1, then A OR B = A+B = 1. If A=1 and B=0, then A OR B = A+B = 1
once again. The only case where the OR function differs from normal addition is
when A=1 and B=1. Here A OR B = 1 in logic, but A+B=2 in arithmetic.
However, there is no such thing as ‘2’ in logic, so we define + to mean ‘OR’, and
write 1+1=1 with impunity!
If you wish, you can prove that the normal rules of algebra still work using this
notation: A+(B+C) = (A+B)+C, A(BC) = (AB)C, and A(B+C) = AB + AC.
This special kind of algebra where variables can only be 0 (representing false) or 1
(representing true) is called Boolean algebra.
The NOR Gate
The last gate you need to know is the NOR gate. This is opposite to the OR gate. The output
is 1 if both inputs are 0. In other words, the output switches on if neither the first NOR the
second input is 1. The symbol for the NOR gate is:
The truth table for the NOR gate is shown below.
The examples given were easy. Each job only needed one logic gate. However any ‘decision
making’ circuit can be built with logic gates, no matter how complicated the decision. Here is
an example.
Each logic gate is manufactured from two or more transistors. Other circuits can be made
using logic gates, as we shall see in the next section. We shall show you how to count and
store numbers using logic gates. This means that if you have enough transistors, and you
connect them correctly to make the right logic gates, you can make circuits which count and
store numbers.
In practice, the cheapest gate to manufacture is usually the NAND gate. Additionally, Charles
Peirce showed that NAND gates alone (as well as NOR gates alone) can be used to reproduce
all the other logic gates.



file_data: 29.6|Using and Storing Binary Numbers|616
In the previous section, we saw how the numbers 0 and 1 could represent ‘false’ and ‘true’ and
could be used in decision making. Often we want to program a computer to count with
numbers. To do this we need a way of writing any number using nothing other than 0 and 1.
When written in this way, numbers are called binary numbers.
Definition: Binary
A way of writing any number using only the digits 0 and 1.



file_data: 29.6.1|Binary numbers|616
In normal (denary) numbers, we write 9+1 as 10. The fact that the ‘1’ in 10 is the second digit
from the right tells us that it actually means 10 and not 1. Similarly, the ‘3’ in 365 represents
300 because it is the third digit from the right. You could write 365 as 3 × 100 + 6 × 10 + 5.
You will notice the pattern that the nth digit from the right represents 10n−1. In binary, we
use the nth digit from the right to represent 2n−1. Thus 2 is written as 10 in binary. Similarly
22 = 4 is written as 100 in binary, and 23 = 8 is written as 1000 in binary.
How do you write numbers as a sum of powers of two? The first power of two
(the largest) is the largest power of two which is not larger than the number
you are working with. In our last example, where we wanted to know what
twelve was in binary, the largest power of two which is not larger than 12 is 8.
Thus 12 = 8 + something. By arithmetic, the ‘something’ must be 4, and the
largest power of two not larger than this is 4 exactly. Thus 12 = 8 + 4, and we
have finished.
A more complicated example would be to write one hundred in binary. The
largest power of two not larger than 100 is 64 (1000000 in binary). Subtracting
64 from 100 leaves 36. The largest power of two not larger than 36 is 32
(100000 in binary). Removing this leaves a remainder of 4, which is a power of
two itself (100 in binary). Thus one hundred is 64 + 32 + 4, or in binary
1000000 + 100000 + 100 = 1100100.
Once a number is written in binary, it can be represented using the low and high voltage levels
of digital electronics. We demonstrate how this is done by showing you how an electronic
counter works.



file_data: 29.6.2|Counting circuits|617
To make a counter you need several ‘T flip flops’, sometimes called ‘divide by two’ circuits. A
T flip flop is a digital circuit which swaps its output (from 0 to 1 or from 1 to 0) whenever the
input changes from 1 to 0. When the input changes from 0 to 1 it doesn’t change its output.
It is called a flip flop because it changes (flips or flops) each time it receives a pulse.
If you put a series of pulses 10101010 into a T flip flop, the result is 01100110. Figure 29.18
makes this clearer.
As you can see from Figure 29.18, there are half as many pulses in the output. This is why it is
called a ‘divide by two’ circuit.
If we connect T flip flops in a chain, then we make a counter which can count pulses. As an
example, we connect three T flip flops in a chain. This is shown in Figure 29.19.
When this circuit is fed with a stream of pulses, the outputs of the different stages change.
The table below shows how this happens. Each row shows a different stage, with the first stage
at the top. We assume that all of the flip flops have 0 as their output to start with.
Figure 29.18: The output of a T flip flop, or ‘divide by two’ circuit when a square wave is
connected to the input. The output changes state when the input goes from 1 to 0.
Figure 29.19: Three T flip flops connected together in a chain to make a counter. The input
of each flip flop is labelled T, while each output is labelled Q. The pulses are connected to the
input on the left. The outputs Q0, Q1 and Q2 give the three digits of the binary number as the
pulses are counted. This is explained in the text and in the next table.
The binary numbers in the right hand column count the pulses arriving at the input. You will
notice that the output of the first flip flop gives the right most digit of the pulse count (in
binary). The output of the second flip flop gives the second digit from the right (the ‘twos’
digit) of the pulse count. The output of the third flip flop gives the third digit from the right
(the ‘fours’ digit) of the pulse count. As there are only three flip flops, there is nothing to
provide the next digit (the ‘eights’ digit), and so the eighth pulse is recorded as 000, not 1000.
This device is called a modulo 8 counter because it can count in eight stages from 000 to 111
before it goes back to 000. If you put four flip flops in the counter, it will count in sixteen
stages from 0000 to 1111, and it is called a modulo 16 counter because it counts in sixteen
stages before going back to 0000.
Definition: Modulo
The modulo of a counter tells you how many stages (or pulses) it receives before going back
to 0 as its output. Thus a modulo 8 counter counts in eight stages 000, 001, 010, 011,
100, 101, 110, 111, then returns to 000 again.



file_data: 29.6.3|Storing binary numbers|619
Counting is important. However, it is equally important to be able to remember the numbers.
Computers can convert almost anything to a string of 0s and 1s, and therefore to a binary
number. Unless this number can be stored in the computer’s memory, the computer would be
useless.
The memory in the computer contains many parts. Each part is able to store a single 0 or 1.
Since 0 and 1 are the two binary digits, we say that each part of the memory stores one bit.
Figure 29.20: A bistable circuit made from two NOR gates. This circuit is able to store one bit
of digital information. With the two inputs set to 0, you can see that the output could be (and
will remain) either 0 or 1. The circuit on the left shows an output of 0, the circuit on the right
shows an output of 1. Wires carrying high logic levels (1) are drawn thicker. The output of the
bistable is labelled Q.
Definition: Bit
One bit is a short way of saying one ‘binary digit’. It is a single 0 or 1.
If you have eight bits, you can store a binary number from 00000000 to
11111111 (0 to 255 in denary). This gives you enough permutations of 0s and
1s to have one for each letter of the alphabet (in upper and lower case), each
digit from 0 to 9, each punctuation mark and each control code used by a
computer in storing a document. When you type text into a word processor,
each character is stored as a set of eight bits. Each set of eight bits is called a
byte. Computer memories are graded according to how many bytes they store.
There are 1024 bytes in a kilobyte (kB), 1024 × 1024 bytes in a megabyte
(MB), and 1024 × 1024 × 1024 bytes in a gigabyte (GB).
To store a bit we need a circuit which can ‘remember’ a 0 or a 1. This is called a bistable
circuit because it has two stable states. It can stay indefinitely either as a 0 or a 1. An example
of a bistable circuit is shown in Figure 29.20. It is made from two NOR gates.
To store the 0 or the 1 in the bistable circuit, you set one of the inputs to 1, then put it back
to 0 again. If the input labelled ‘S’ (set) is raised, the output will immediately become 1. This
is shown in Figure 29.21.
To store a 0, you raise the ‘R’ (reset) input to 1. This is shown in Figure 29.22.
Once you have used the S or R inputs to set or reset the bistable circuit, you then bring both
inputs back to 0. The bistable ‘remembers’ the state. Because of the ease with which the
circuit can be Reset and Set it is also called a RS flip flop circuit.
A computer memory will be able to store millions or billions of bits. If it used our circuit above,
it would need millions or billions of NOR gates, each of which is made from several transistors.
The computer memory is made of many millions of transistors.
The bistable circuits drawn here don’t remember 0s or 1s for ever — they lose
the information if the power is turned off. The same is true for the RAM
(Random Access Memory) used to store working and temporary data in a
computer. Some modern circuits contain special memory which can remember
its state even if the power is turned off. This is used in FLASH drives,
commonly found in USB data sticks and on the memory cards used with digital
cameras. These bistable circuits are much more complex.
You can also make T flip flops out of logic gates, however these are more complicated to design.









file_data: 30|EM Radiation|625


file_data: 30.1|Introduction|625
This chapter will focus on the electromagnetic (EM) radiation. Electromagnetic radiation is a
self-propagating wave in space with electric and magnetic components. These components
oscillate at right angles to each other and to the direction of propagation, and are in phase
with each other. Electromagnetic radiation is classified into types according to the frequency of
the wave: these types include, in order of increasing frequency, radio waves, microwaves,
infrared radiation, visible light, ultraviolet radiation, X-rays and gamma rays.


file_data: 30.2|Particle/wave nature of electromagnetic radiation|625
If you watch a colony of ants walking up the wall, they look like a thin continuous black line.
But as you look closer, you see that the line is made up of thousands of separated black ants.
Light and all other types of electromagnetic radiation seems like a continuous wave at first, but
when one performs experiments on the light, one can notice that the light can have both wave
and particle like properties. Just like the individual ants, the light can also be made up of
individual bundles of energy, or quanta of light.
Light has both wave-like and particle-like properties (wave–particle duality), but only shows one
or the other, depending on the kind of experiment we perform. A wave-type experiment shows
the wave nature, and a particle-type experiment shows particle nature. One cannot test the
wave and the particle nature at the same time. A particle of light is called a photon.
Definition: Photon
A photon is a quantum (energy packet) of light.
The particle nature of light can be demonstrated by the interaction of photons with matter.
One way in which light interacts with matter is via the photoelectric effect, which will be
studied in detail in Chapter 31.


file_data: 30.3|The wave nature of electromagnetic radiation|626
Accelerating charges emit electromagnetic waves. We have seen that a changing electric field
generates a magnetic field and a changing magnetic field generates an electric field. This is the
principle behind the propagation of electromagnetic waves, because electromagnetic waves,
unlike sound waves, do not need a medium to travel through. EM waves propagate when an
electric field oscillating in one plane produces a magnetic field oscillating in a plane at right
angles to it, which produces an oscillating electric field, and so on. The propagation of
electromagnetic waves can be described as mutual induction.
These mutually regenerating fields travel through space at a constant speed of 3 × 108m · s−1,
represented by c.


file_data: 30.4|Electromagnetic spectrum|626
Observe the things around you, your friend sitting next to you, a large tree across the field.
How is it that you are able to see these things? What is it that is leaving your friend’s arm and
entering your eye so that you can see his arm? It is light. The light originally comes from the
sun, or possibly a light bulb or burning fire. In physics, light is given the more technical term
electromagnetic radiation, which includes all forms of light, not just the form which you can see
with your eyes.
Electromagnetic radiation allows us to observe the world around us. It is this radiation which
reflects off of the objects around you and into your eye. The radiation your eye is sensitive to is
only a small fraction of the total radiation emitted in the physical universe. All of the different
fractions taped together make up the electromagnetic spectrum.
When white light is split into its component colours by a prism, you are looking
at a portion of the electromagnetic spectrum.
The wavelength of a particular electromagnetic radiation will depend on how it was created.
The radiation can take on any wavelength, which means that the spectrum is continuous.
Physicists broke down this continuous band into sections. Each section is defined by how the
radiation is created, not the radiations wavelength. But each category is continuous within the
min and max wavelength of that category, meaning there are no wavelengths excluded within
some range.
The spectrum is in order of wavelength, with the shortest wavelength at one end and the
longest wavelength at the other. The spectrum is then broken down into categories as detailed
in Table 30.1.
Since an electromagnetic wave is still a wave, the following equation that you learnt in Grade
10 still applies:
c = f · λ
In theory the spectrum is infinite, although realistically we can only observe wavelengths from a
few hundred kilometers to those of gamma rays due to experimental limitations.
Humans experience electromagnetic waves differently depending on their wavelength. Our eyes
are sensitive to visible light while our skin is sensitive to infrared, and many wavelengths we do
not detect at all.



file_data: 30.5|The particle nature of electromagnetic radiation|629
When we talk of electromagnetic radiation as a particle, we refer to photons, which are packets
of energy. The energy of the photon is related to the wavelength of electromagnetic radiation
according to: h is called Planck’s constant.
Definition: Planck’s constant
Planck’s constant is a physical constant named after Max Planck.
h = 6,626 × 10−34 J · s
The energy of a photon can be calculated using the formula: E = hf or E = h c
λ. Where E is
the energy of the photon in joules (J), h is planck’s constant, c is the speed of light, f is the
frequency in hertz (Hz) and λ is the wavelength in metres (m).



file_data: 30.5.1|Exercise - particle nature of EM waves|630


file_data: 30.6|Penetrating ability of electromagnetic radiation|631
Different kinds of electromagnetic radiation have different penetrabilities. For example, if we
take the human body as the object. Infrared light is emitted by the human body. Visible light
is reflected off the surface of the human body, ultra-violet light (from sunlight) damages the
skin, but X-rays are able to penetrate the skin and bone and allows for pictures of the inside of
the human body to be taken.
If we compare the energy of visible light to the energy of X-rays, we find that X-rays have a
much higher energy. Usually, kinds of electromagnetic radiation with higher energy have higher
penetrabilities than those with low energies.
Certain kinds of electromagnetic radiation such as ultra-violet radiation, X-rays and gamma
rays are very dangerous. Radiation such as these are called ionising radiation. Ionising radiation
loses energy as it passes through matter, breaking molecular bonds and creating ions.
Excessive exposure to radiation, including sunlight, X-rays and all nuclear radiations, can cause
destruction of biological tissue.



file_data: 30.6.1|Ultraviolet(UV) radiation and the skin|631
UVA and UVB are different ranges of frequencies for ultraviolet (UV) light. UVA and UVB can
damage collagen fibres which results in the speeding up skin aging. In general, UVA is the least
harmful, but it can contribute to the aging of skin, DNA damage and possibly skin cancer. It
penetrates deeply and does not cause sunburn. Because it does not cause reddening of the skin
(erythema) it cannot be measured in the SPF testing. There is no good clinical measurement
of the blocking of UVA radiation, but it is important that sunscreen block both UVA and UVB.
UVB light can cause skin cancer. The radiation excites DNA molecules in skin cells, resulting
in possible mutations, which can cause cancer. This cancer connection is one reason for
concern about ozone depletion and the ozone hole.
As a defense against UV radiation, the body tans when exposed to moderate (depending on
skin type) levels of radiation by releasing the brown pigment melanin. This helps to block UV
penetration and prevent damage to the vulnerable skin tissues deeper down. Suntan lotion,
often referred to as sunblock or sunscreen, partly blocks UV and is widely available. Most of
these products contain an SPF rating that describes the amount of protection given. This
protection, however, applies only to UVB rays responsible for sunburn and not to UVA rays
that penetrate more deeply into the skin and may also be responsible for causing cancer and
wrinkles. Some sunscreen lotion now includes compounds such as titanium dioxide which helps
protect against UVA rays. Other UVA blocking compounds found in sunscreen include zinc
oxide and avobenzone.




file_data: 30.6.2|Ultraviolet radiation and the eyes|632
High intensities of UVB light are hazardous to the eyes, and exposure can cause welder’s flash
(photo keratitis or arc eye) and may lead to cataracts, pterygium and pinguecula formation.
Protective eyewear is beneficial to those who are working with or those who might be exposed
to ultraviolet radiation, particularly short wave UV. Given that light may reach the eye from the
sides, full coverage eye protection is usually warranted if there is an increased risk of exposure,
as in high altitude mountaineering. Mountaineers are exposed to higher than ordinary levels of
UV radiation, both because there is less atmospheric filtering and because of reflection from
snow and ice.
Ordinary, untreated eyeglasses give some protection. Most plastic lenses give more protection
than glass lenses. Some plastic lens materials, such as polycarbonate, block most UV. There
are protective treatments available for eyeglass lenses that need it which will give better
protection. But even a treatment that completely blocks UV will not protect the eye from light
that arrives around the lens. To convince yourself of the potential dangers of stray UV light,
cover your lenses with something opaque, like aluminum foil, stand next to a bright light, and
consider how much light you see, despite the complete blockage of the lenses. Most contact
lenses help to protect the retina by absorbing UV radiation.




file_data: 30.6.3|X-rays|632
While x-rays are used significantly in medicine, prolonged exposure to X-rays can lead to cell
damage and cancer.
For example, a mammogram is an x-ray of the human breast to detect breast cancer, but if a
woman starts having regular mammograms when she is too young, her chances of getting
breast cancer increases.




file_data: 30.6.4|Gamma-rays|632
Due to the high energy of gamma-rays, they are able to cause serious damage when absorbed
by living cells.
Gamma-rays are not stopped by the skin and can induce DNA alteration by interfering with the
genetic material of the cell. DNA double-strand breaks are generally accepted to be the most
biologically significant lesion by which ionising radiation causes cancer and hereditary disease.
A study done on Russian nuclear workers exposed to external whole-body gamma-radiation at
high cumulative doses shows a link between radiation exposure and death from leukaemia,
lung, liver, skeletal and other solid cancers.
Extension: Cellphones and electromagnetic radiation
Cellphone radiation and health concerns have been raised, especially following
the enormous increase in the use of wireless mobile telephony throughout the
world. This is because mobile phones use electromagnetic waves in the microwave
range. These concerns have induced a large body of research. Concerns about
effects on health have also been raised regarding other digital wireless systems,
such as data communication networks.
The World Health Organization has officially ruled out adverse health effects
from cellular base stations and wireless data networks, and expects to make
recommendations about mobile phones in 2007-08.
Cellphone users are recommended to minimise radiation, by for example:
1. Use hands-free to decrease the radiation to the head.
2. Keep the mobile phone away from the body.
3. Do not telephone in a car without an external antenna.


file_data: 30.6.5|Exercise - Penetrating ability of EM radiation|633


file_data: 30.7|Summary|633


file_data: 30.8|End of chapter exercise|633






file_data: 31|Optical Phenomena and Properties of Matter - Grade 12|635



file_data: 31.1|Introduction|635
For centuries physicists argued about whether light was a particle or a wave. It was assumed
that light could only be one or the other, but not both.
In earlier chapters on waves (Chapters 6, 24, 25, 26) and optics (Chapters 7 and 13), you
studied how light or other electromagnetic radiation propagates like a wave. The wave nature
of light of was demonstrated by the propagation of light in examples such as diffraction,
interference, and polarisation of light.
You also saw in Chapter 30 on electromagnetic radiation how light sometimes behaves as a
particle. This chapter looks at evidence supporting the particle model of light. The idea that
light can have both wave and particle properties was one of the most important discoveries of
the twentieth century.


file_data: 31.2|The transmission and scattering of light|635


file_data: 31.2.1|Energy levels of an electron|635
We have seen that the electrons in an atom have different energy levels. When the electron
receives enough energy, it can jump up to a higher energy level. This is called ’exciting’ the
electron. When the electron in a high energy level sheds some energy, it drops to a lower
energy level.
We have also seen that the energy associated with light at a specific wavelength is given by:
E =
hc
λ
.
In the particle model of light, this means that each packet of light (photon) at a wavelength λ
has energy:
E =
hc
λ
.
For the electron to receive energy, it absorbs a photon and gets its energy. When an electron
loses energy to drop to a lower level, it emits (gives off) a photon with that energy.



file_data: 31.2.2|Interaction of light with metals|636
When light encounters or passes through a material, the photons of the light interact with the
atoms or molecules of the material. Depending on the strength of the interactions and how
often they happen, the light will pass through the material or be scattered in some other
direction.
Each wavelength of light relates to a particular energy, and the closer that energy is to the
energy difference between two of the levels of the atom, the likelier the photon is to interact
with the atom.
When visible or ultraviolet (UV) radiation shines on a metal, the photons are absorbed by the
electrons in the metal. The electrons are then excited up to a higher energy level. When an
electron returns to a lower energy level, another photon is emitted. This is how light is
reflected off a metal surface.
In previous chapters, you have studied geometrical optics, which tells us what happens to rays
of light when they are reflected off a surface or refracted through a lens. That tells us what
happens to light rays, made up of many photons, on a large scale. If you look at a smaller
level, i.e. on a microscopic scale, then reflection and refraction happen by all the photons
interacting with the atoms of the lens or mirror. The photons get absorbed and re-emitted
many times before emerging as the finals rays of light that we see.
Scattering of light is responsible for many effects in everyday life. We see that certain materials
are red or blue, for example, since they contain materials that have energy level differences that
correspond to the energies of the photons that make up red or blue light. These materials then
reflect the red or blue light and absorb the other wavelengths in the visible spectrum. White
objects reflect photons of all wavelengths in the visual spectrum, while black objects absorb
these photons.
Because a truly black object absorbs all the visual wavelengths of light, and
does not re-emit photons at visual wavelengths, we can say that ’black’ is not a
colour itself, but rather a lack of colour! Also, since black objects absorb visual
light, they heat up more than objects of other colours which reflect light at
certain wavelengths.
Metals generally reflect most wavelengths of visible light, but they will reflect the light in a
certain direction, given by the laws of reflection in geometrical optics. This is different to most
materials, like wood or fabric, which reflect light in all directions. Metals have this property
since they have electrons that are not bound to atoms and can move freely through the metal.
This is unlike most other materials that have their electrons bound closely to the atoms. These
free electrons in metals can then absorb and reflect photons of a wide range of energies.
Ultraviolet light (which has shorter wavelengths than visible light) will pass through some
substances, such as many plastics, because they do not have the right energy levels to absorb it
and re-emit it. X-rays (also short wavelengths) will also pass through most materials, since the
energies of X-rays correspond to the energy levels of atomic nuclei. Such nuclei are much
smaller than atoms, so it is much less likely for an X-ray to hit a nucleus instead of the whole
atom.
Most materials will absorb infrared radiation (longer wavelengths than visible light), since the
energies of that radiation often correspond to rotational or vibrational energy levels of
molecules.




file_data: 31.2.3|Why is the sky blue?|637
The sun emits light in many different wavelengths, including all of the visible wavelengths.
Light which is made up of all the visible wavelengths appears white. So what causes the sky to
look blue?
The air is not just full of nitrogen and oxygen gases. It is also full of tiny dust grains. The light
from the sun scatters off these many dust grains.
The chance that the light will scatter off one of these dust grains is bigger for shorter
wavelengths. The short wavelength blue light is therefore scattered much more than the other
colors. At noon, when the light from the sun is coming straight down (see the picture below),
the scattered blue light reaches your eyes from all directions and so the sky appears blue. The
other wavelengths do not get scattered much and therefore miss your line of sight. At sunrise
or sunset, the direction of the light coming from the sun is now straight towards your eyes (see
picture below). Therefore the scattered blue light can’t be seen because it is scattered out of
your line of sight. The redder colours (oranges and reds) can now be seen because they are not
scattered as much and still fall in your line of sight.



file_data: 31.3|The photoelectric effect|638
Around the turn of the twentieth century, it was observed by a number of physicists (including
Hertz, Thomson and Von Lenard) that when light was shone on a metal, electrons were
emitted by the metal. This is called the photoelectric effect. (photo- for light, electric- for the
electron.)
Definition: The photoelectric effect
The photoelectric effect is the process whereby an electron is emitted by a metal when light
shines on it.
At that time, light was thought to be purely a wave. Therefore, physicists thought that if a
more intense (i.e. brighter) light was shone on a metal, then the electrons would be knocked
out with greater kinetic energies than if a faint light was shone on them. However, Von Lenard
observed that this did not happen at all. The intensity of the light made no difference to the
kinetic energy of the emitted electrons! Also, it was observed that the electrons were emitted
immediately when light was shone on the metal - there was no time delay.
Einstein solved this problem by proposing that light is made up of packets of energy called
quanta (now called photons) which interacted with the electrons in the metal like particles
instead of waves. Each incident photon would transfer all its energy to one electron in the
metal. For a specific colour of light (i.e. a certain wavelength or frequency), the energy of the
photons is given by E = hf = hc/λ, where h is Planck’s constant. The energy needed to
knock an electron out of the metal is called the work function (symbol φ) of the metal.
Therefore, the amount of energy left over as the kinetic energy (Ek) of the emitted electron
would be the difference between the incoming photon’s energy and the energy needed to knock
out the electron (work function of the metal):
Ek = hf − φ
Increasing the intensity of the light (i.e. making it brighter) did not change the wavelength of
the light and therefore the electrons would be emitted with the same kinetic energy as before!
This solved the paradox and showed that light has both a wave nature and a particle nature.
Einstein won the Nobel prize for this quantum theory and his explanation of the photoelectric
effect.
Increasing the intensity of the light actually means increasing the number of incident photons.
Therefore, since each photon only gives energy to one electron, more incident photons
meansmore electrons would be knocked out of the metal, but their kinetic energies would be
the same as before.
The photoelectric effect was first observed in the experiments of Heinrich Hertz
in 1887. In 1899 J.J. Thomson proved that it was electrons that were emitted.
The photoelectric effect was theoretically explained by Albert Einstein in 1905.
The discovery and understanding of the photoelectric effect was one of the major
breakthroughs in science in the twentieth century as it provided concrete evidence of the
particle nature of light. It overturned previously held views that light was composed purely of a
continuous transverse wave. On the one hand, the wave nature is a good description of
phenomena such as diffraction and interference for light, and on the other hand, the
photoelectric effect demonstrates the particle nature of light. This is now known as the
‘dual-nature’ of light. (dual means two)
While solving problems we need to decide for ourselves whether we should consider the wave
property or the particle property of light. For example, when dealing with interference and
diffraction, light should be treated as a wave, whereas when dealing with photoelectric effect
we consider the particle nature.



file_data: 31.3.1|Applications of the photoelectric effect|640
We have learnt that a metal contains electrons that are free to move between the valence and
conduction bands. When a photon strikes the surface of a metal, it gives all its energy to one
electron in the metal.
• If the photon energy is equal to the energy between two energy levels then the electron is
excited to the higher energy level.
• If the photon energy is greater than or equal to the work function (energy needed to
escape from the metal), then the electron is emitted from the surface of the metal (the
photoelectric effect).
The work function is different for different elements. The smaller the work function, the easier
it is for electrons to be emitted from the metal. Metals with low work functions make good
conductors. This is because the electrons are attached less strongly to their surroundings and
can move more easily through these materials. This reduces the resistance of the material to
the flow of current i.e. it conducts well. Table 31.1 shows the work functions for a range of
elements.
The electron volt is the kinetic energy gained by an electron passing through
a potential difference of one volt (1 V). A volt is not a measure of energy, but
the electron volt is a unit of energy. When you connect a 1.5 Volt battery to
a circuit, you can give 1.5 eV of energy to every electron.




file_data: 31.3.2|Real-life applications|642
Solar Cells
The photo-electric effect may seem like a very easy way to produce electricity from the sun.
This is why people choose to make solar panels out of materials like silicon, to generate
electricity. In real-life however, the amount of electricity generated is less than expected. This
is because not every photon knocks out an electron. Other processes such as reflection or
scattering also happen. This means that only a fraction ≈ 10% (depends on the material) of
the photons produce photoelectrons. This drop in efficiency results in a lower measured current.
Much work is being done in industry to improve this efficiency so that the panels can generate
as high a current as possible, and create as much electricity as possible form the sun. But even
these smaller electrical currents are useful in applications like solar-powered calculators.



file_data: 31.4|Emission and absorption spectra|643


file_data: 31.4.1|Emission Spectra|643
You have learnt previously about the structure of an atom. The electrons surrounding the
atomic nucleus are arranged in a series of levels of increasing energy. Each element has its own
distinct set of energy levels. This arrangement of energy levels serves as the atom’s unique
fingerprint.
In the early 1900s, scientists found that a liquid or solid heated to high temperatures would
give off a broad range of colours of light. However, a gas heated to similar temperatures would
emit light only at certain specific colours (wavelengths). The reason for this observation was
not understood at the time.
Scientists studied this effect using a discharge tube.
Figure 31.3: Diagram of a discharge tube. The tube is filled with a gas. When a high enough
voltage is applied to both ends of the tube, the gas ionises and acts like a conductor, allowing a
current to flow through the circuit. The current excites the atoms of the ionised gas. When the
atoms fall back to their ground state, they emit photons to carry off the excess energy.
A discharge tube (Figure 31.3) is a glass gas-filled tube with a metal plate at both ends. If a
large enough voltage difference is applied between the two metal plates, the gas atoms inside
the tube will absorb enough energy to make some of their electrons come off i.e. the gas atoms
are ionised. These electrons start moving through the gas and create a current, which raises
some electrons in other atoms to higher energy levels. Then as the electrons in the atoms fall
back down, they emit electromagnetic radiation. The amount of light emitted at different
wavelengths, called the emission spectrum, is shown for a discharge tube filled with hydrogen
gas in figure 31.4 below. Only certain wavelengths (i.e. colours) of light are seen as shown by
the thick black lines in the picture.
Figure 31.4: Diagram of the emission spectrum of hydrogen in the visible spectrum. Four lines
are visible, and are labeled with their wavelengths. The three lines in the 400–500 nm range are
in the blue part of the spectrum, while the higher line (656 nm) is in the red/orange part.
Eventually, scientists realized that these lines come from photons of a specific energy, emitted
by electrons making transitions between specific energy levels of the atom. Figure ?? shows an
example of this happening. When an electron in an atom falls from a higher energy level to a
lower energy level, it emits a photon to carry off the extra energy. This photon’s energy is
equal to the energy difference between the two energy levels. As we previously discussed, the
frequency of a photon is related to its energy through the equation E = hf. Since a specific
photon frequency (or wavelength) gives us a specific colour, we can see how each coloured line
is associated with a specific transition.
Figure 31.5: In this diagram are shown some of the electron energy levels for the hydrogen atom.
The arrows show the electron transitions from higher energy levels to lower energy levels. The
energies of the emitted photons are the same as the energy difference between two energy levels.
You can think of absorption as the opposite process. The arrows would point upwards and the
electrons would jump up to higher levels when they absorp a photon of the right energy.
Visible light is not the only kind of electromagnetic radiation emitted. More energetic or less
energetic transitions can produce ultraviolet or infrared radiation. However, because each atom
has its own distinct set of energy levels (its fingerprint!), each atom has its own distinct
emission spectrum.



file_data: 31.4.2|Absorption spectra|644
As you know, atoms do not only emit photons; they also absorb photons. If a photon hits an
atom and the energy of the photon is the same as the gap between two electron energy levels
in the atom, then the electron can absorb the photon and jump up to the higher energy level.
If the atom has no energy level differences that equal the incoming photon’s energy, it cannot
absorb the photon, and can only scatter it.
Using this effect, if we have a source of photons of various energies we can obtain the
absorption spectra for different materials. To get an absorption spectrum, just shine white
light on a sample of the material that you are interested in. White light is made up of all the
different wavelengths of visible light put together. In the absorption spectrum, the energy levels
corresponding to the absorbed photons show up as black lines because the photons of these
wavelengths have been absorbed and don’t show up. Because of this, the absorption spectrum
is the exact inverse of the emission spectrum. Look at the two figures below. In figure 31.6 you
can see the emission lines of hyrodrogen. Figure 31.7 shows the absorption spectrum. It is the
exact opposite of the emission spectrum! Both emission and absorption techniques can be used
to get the same information about the energy levels of an atom.


file_data: 31.4.3|Colours and energies of electromagnetic radiation|646
We saw in the explanation of why the sky is blue that different wavelengths or frequencies of
light correspond to different colours of light. The table below gives the wavelengths and
colours for light in the visible spectrum:
We also know that the energy of a photon of light can be found from:
E = hf =
hc
λ
Therefore if we know the frequency or wavelength of light, we can calculate the photon’s
energy and vice versa.




file_data: 31.4.4|Applications of emission and absorption spectra|648
The study of spectra from stars and galaxies in astronomy is called spectroscopy. Spectroscopy
is a tool widely used in astronomy to learn different things about astronomical objects.
Identifying elements in astronomical objects using their spectra
Measuring the spectrum of light from a star can tell astronomers what the star is made of!
Since each element emits or absorbs light only at particular wavelengths, astronomers can
identify what elements are in the stars from the lines in their spectra. From studying the
spectra of many stars we know that there are many different types of stars which contain
different elements and in different amounts.
Determining velocities of galaxies using spectroscopy
You have already learned in Chapter 24 about the Doppler effect and how the frequency (and
wavelength) of sound waves changes depending on whether the object emitting the sound is
moving towards or away from you. The same thing happens to electromagnetic radiation. If
the object emitting the light is moving towards us, then the wavelength of the light appears
shorter (called blue-shifted). If the object is moving away from us, then the wavelength of its
light appears stretched out (called red-shifted).
The Doppler effect affects the spectra of objects in space depending on their motion relative to
us on the earth. For example, the light from a distant galaxy, which is moving away from us at
some velocity, will appear red-shifted. This means that the emission and absorption lines in the
galaxy’s spectrum will be shifted to a longer wavelength (lower frequency). Knowing where
each line in the spectrum would normally be if the galaxy was not moving, and comparing to
their red-shifted positions, allows astronomers to precisely measure the velocity of the galaxy
relative to the earth!
Global warming and greenhouse gases
The sun emits radiation (light) over a range of wavelengths which are mainly in the visible part
of the spectrum. Radiation at these wavelengths passes through the gases of the atmosphere
to warm the land and the oceans below. The warm earth then radiates this heat at longer
infrared wavelengths. Carbon-dioxide (one of the main greenhouse gases) in the atmosphere
has energy levels which correspond to the infrared wavelengths which allow it to absorb the
infrared radiation. It then also emits at infrared wavelengths in all directions. This effect stops
a large amount of the infrared radiation getting out of the atmosphere, which causes the
atmosphere and the earth to heat up. More radiation is coming in than is getting back out.
Therefore increasing the amount of greenhouse gases in the atmosphere increases the amount
of trapped infrared radiation and therefore the overall temperature of the earth. The earth is a
very sensitive and complicated system upon which life depends and changing the delicate
balances of temperature and atmospheric gas content may have disastrous consequences if we
are not careful.



file_data: 31.5|Lasers|650
A laser is a device that produces a special type of light: all the laser photons are identical!
They all have the same wavelength (and frequency), amplitude and phase. Since they all have
the same wavelength, this means they all have the same colour and the light is called
monochromatic. (Note: mono means ”one” or ”single” and chromatic means ”colour”.)
This is very different to most other light sources which produce light with a range of
wavelengths (e.g. white light from the sun consists of all the visible wavelengths.)
Laser light is highly directional and can be focused very well. This focus allows laser beams to
be used over long distances, and to pack a lot of energy into the beam while still requiring
reasonably small amounts of energy to be generated. Each centimetre of a typical laser beam
contains many billions of photons. These special properties of laser light come from the way in
which the laser photons are created and the energy levels of the material that makes up the
laser. These properties make laser light extremely useful in many applications from CD players
to eye surgery.
The term LASER stands for Light Amplification by the Stimulated Emission of Radiation.
This stimulated emission is different to the spontaneous emission already discussed earlier.
Let’s review the absorption and emission processes which can occur in atoms.
• Absorption: As you can see in the picture above, absorption happens when an electron
jumps up to a higher energy level by absorbing a photon which has an energy equal to
the energy difference between the two energy levels.
• Spontaneous emission: Spontaneous emission is when an electron in a higher energy
level drops down to a lower energy level and a photon is emitted with an energy equal to
the energy difference between the two levels. There is no interference in this process
from outside factors. Usually spontaneous emission happens very quickly after an
electron gets into an excited state. In other words, the lifetime of the excited state is
very short. However, there are some excited states where an electron can remain in the
higher energy level for a longer time than usual before dropping down to a lower level.
These excited states are called metastable states.
• Stimulated emission: As the picture above shows, stimulated emission happens when
a photon with an energy equal to the energy difference between two levels interacts with
an electron in the higher level. This stimulates the electron to emit an identical photon
and drop down to the lower energy level. This process results in two photons at the end.
Definition: Spontaneous Emission
Spontaneous emission occurs when an atom is in an unstable excited state and randomly
decays to a less energetic state, emitting a photon to carry off the excess energy. The
unstable state decays in a characteristic time, called the lifetime.
Definition: Meta-stable state
A meta-stable state is an excited atomic state that has an unusually long lifetime, compared
to the lifetimes of other excited states of that atom. While most excited states have lifetimes
measured in microseconds and nanoseconds (10−6 s and 10−9 s), meta-stable states can
have lifetimes of milliseconds (10−3 s) or even seconds.
Definition: Stimulated emission
Stimulated emission occurs when a photon interacts with an excited atom, causing the atom
to decay and emit another identical photon.



file_data: 31.5.1|How a laser works|652
The important process involved in how a laser works is stimulated emission - as you can tell
from what ‘laser’ stands for! You can imagine that stimulated emission can lead to more and
more identical photons being released in the following way: Imagine we have an electron in an
excited metastable state and it drops down to the ground state by emitting a photon. If this
photon then travels through the material and meets another electron in the metastable excited
state this will cause the electron to drop down to the lower energy level and another photon to
be emitted. Now there are two photons of the same energy. If these photons then both move
through the material and each interacts with another electron in a metastable state, this will
result in them each causing an additional photon to be released. i.e. from 2 photons we then
get 4, and so on! This is how laser light is produced.
Figure 31.8: Spontaneous emission is a two step process, as shown here. First, energy from
an external source is applied to an atom in the laser medium, raising its energy to an excited
(metastable) state. After some time, it will decay back down to its ground state and emit the
excess energy in the form of a photon. This is the first stage in the formation of a laser beam.
Figure 31.9: Stimulated emission is also a two step process, as shown here. First, a laser photon
encounters an atom that has been raised to an excited state, just like in the case of spontaneous
emission. The photon then causes the atom to decay to its ground state and emit another
photon identical to the incoming photon. This is the second step in the creation of a laser beam.
It happens many, many times as the laser photons pass through the optical cavity until the laser
beam builds up to full strength.
This can only happen if there are many electrons in a metastable state. If most of the electrons
are in the ground state, then they will just absorb the photons and no extra photons will be
emitted. However, if more electrons are in the excited metastable state than in the ground
state, then the process of stimulated emission will be able to continue. Usually in atoms, most
of the electrons are in the lower energy levels and only a few are in excited states. When most
of the electrons are in the excited metastable state and only a few are in the ground state, this
is called population inversion (the populations are swapped around) and this is when
stimulated emission can occur. To start off the process, the electrons first have to be excited
up into the metastable state. This is done using an external energy source.
Definition: Population inversion
Population inversion is when more atoms are in an excited state than in their ground state.
It is a necessary condition to sustain a laser beam, so that there are enough excited atoms
that can be stimulated to emit more photons.
Therefore, materials used to make laser light must must have metastable states which can
allow population inversion to occur when an external energy source is applied. Some
substances which are used to make lasers are listed in table 31.3. You can see that gases (such
as Helium-Neon mixture), liquids (such as dyes), and solids (such as the precious stone ruby)
are all used to make lasers.
Material Type Wavelength Uses
Helium–Neon gas 632,8 nm scientific research, holography
Argon ion gas 488,0 nm medicine,
Carbon dioxide gas 10,6 μm industry (cutting, welding), surgery
Helium–Cadmium vapor 325 nm printing, scientific research
Ruby solid–state 694,3 nm holography
Neodymium YAG solid–state 1,064 μm industry, surgery, research
(Yttrium Aluminium
Garnet)
Titanium–Sapphire solid–state 650–1100 nm research
Laser diode semiconductor 375–1080 nm telecommunications, industry,
printing, CD players, laser pointers
Table 31.3: A selection of different lasers. The laser material and general type of each laser is
given, along with typical wavelengths of the laser light they create. Examples of the real-world
applications it is used for are also given. All these materials allow a population inversion to be
set up.
The first working laser, using synthetic ruby as the laser material, was made by
Theodore H. Maiman at Hughes Research Laboratories in Malibu, California.
Later in the same year the Iranian physicist Ali Javan, together with William
Bennet and Donald Herriot, made the first gas laser using helium and neon.
Javan received the Albert Einstein Award in 1993.


file_data: 31.5.2|A simple laser|654
A laser consists of a number of different parts that work together to create the laser beam.
Figure 31.10 shows the different parts of the laser, while Figure 31.11 shows how they create
the laser beam.
The basis of the laser is the laser material. The laser material consists of the atoms that are
used to create the laser beam. Many different materials can be used as laser material, and their
energy levels determine the characteristics of the laser. Some examples of different lasers are
shown in Table 31.3. The laser material is contained in the optical cavity.
Before the laser is turned on, all the atoms in the laser material are in their ground state. The
first step in creating a laser beam is to add energy to the laser material to raise most of the
electrons into an excited metastable state. This is called pumping the laser.
The creation of the laser beam starts through the process of spontaneous emission, shown in
Figure 31.8. An electron drops down to the ground state and emits a photon with energy equal
to the energy difference of the two energy levels. This laser photon is the beginning of the laser
Figure 31.11: Diagram of a laser showing the process of creating a laser beam. (1) A source
of external energy is applied to the laser medium, raising the atoms to an excited state. (2)
An excited atom decays though spontaneous emission, emitting a photon. (3) The photon
encounters another excited atom and causes it to decay through stimulated emission, creating
another photon. (4) The photons bounce back and forth through the laser medium between
the mirrors, building up more and more photons. (5) A small percentage of the photons pass
through the partially-silvered mirror to become the laser beam we see.
beam.
Sometimes a laser photon runs into another excited electron. Then stimulated emission occurs
and the electron drops down to the ground state and emits an additional identical photon as
shown in Figure 31.9. Since the laser material typically has a large number of atoms, one laser
photon passing through this material will rapidly cause a large number of photons just like it to
be emitted.
The optical cavity keeps the laser photons inside the laser cavity so they can build up the laser
beam. At each end is a concave mirror; one is a full mirror and one is a partial mirror. The full
mirror is totally reflective. The partial mirror transmits a small amount of the light that hits
it(less than 1%). The mirrors are carefully aligned so that photons that reflect off one mirror
become “trapped”, and bounce back and forth between the mirrors many times causing more
and more stimulated emission. The photons that eventually escape through the
partially-silvered mirror become the laser beam that we see.
As the photons bounce between mirrors, they continually pass through the laser material,
stimulating those atoms to emit more photons. This creates an ever increasing beam of
photons, all with the same characteristics, all traveling in the same direction. In this way, the
optical cavity helps to amplify the original laser photons into a concentrated, intense beam of
photons.
The laser cavity also helps to narrow the frequency range of laser light emitted. The distance
between the two mirrors defines the cavity mode which only allows light of a narrow range of
frequencies to continue being reflected back and forth. Light of other frequencies damped out.
(This is just like in the chapter on the physics of music where a pipe of a certain length
corresponds to a particular wavelength of sound.) Therefore only a narrow frequency of light
can be emitted.
In 1953, Charles H. Townes and graduate students James P. Gordon and
Herbert J. Zeiger produced the first maser, a device operating on similar
principles to the laser, but producing microwave rather than optical radiation.
Townes’s maser was incapable of making a continuous beam. Nikolay Basov
and Aleksandr Prokhorov of the former Soviet Union worked independently and
developed a method of making a continuous beam using more than two energy
levels. Townes, Basov and Prokhorov shared the Nobel Prize in Physics in 1964.


file_data: 31.5.3|Laser applications and safety|655
Although the first working laser was only produced in 1958, lasers are now found in many
household items. For example, lasers are well-known through their use as cheap laser pointers.
However, lasers can be very dangerous to the human eye since a large amount of energy is
focused into a very narrow beam. NEVER POINT A LASER POINTER INTO
SOMEBODY’S EYES - it can blind them.
Other uses include:
• Semiconductor lasers which are small, efficient and cheap to make are found in CD
players.
• He-Ne Lasers are used in most grocery shops to read in the price of items using their
barcodes. This makes the cashiers’ job much quicker and easier.
• High energy lasers are used in medicine as a cutting and welding tool. Eye surgery in
particular make use of the precision of lasers to reattach the retinas of patients’ eyes.
The heat from cutting lasers also helps to stop the bleeding on a wound by burning the
edges (called cauterising).



file_data: 31.6|Summary|656


file_data: 31.7|End of chapter exercise|657


