{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data from various files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_content_file = \"required_data/physics_book_content.csv\"\n",
    "labeled_pairs_file = \"required_data/physics_labeled_pairs.csv\"\n",
    "wikipedia_data_file = \"required_data/physics_correct_wikipedia_data.csv\"\n",
    "concepts_file = \"required_data/physics_concepts_ambiguity.csv\"\n",
    "\n",
    "def read_concepts_file():\n",
    "    df = pd.read_csv(concepts_file, encoding = \"utf-8\")\n",
    "    all_data = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        all_data[i] = {\n",
    "            \"concept\": df[[\"concept\"]].iloc[i].values[0],\n",
    "            \"key_terms\": df[[\"key_terms\"]].iloc[i].values[0]\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def read_book_data():\n",
    "    df = pd.read_csv(book_content_file, encoding = \"utf-8\")\n",
    "    all_data = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        if df[[\"content\"]].iloc[i].isna().values[0]:\n",
    "            content = \"\"\n",
    "        else:\n",
    "            content = df[[\"content\"]].iloc[i].values[0]\n",
    "        all_data[i] = {\n",
    "            \"section\": df[[\"section\"]].iloc[i].values[0],\n",
    "            \"title\": df[[\"title\"]].iloc[i].values[0],\n",
    "            \"page_no\": df[[\"page_no\"]].iloc[i].values[0],\n",
    "            \"content\": content\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def read_labeled_pairs():\n",
    "    df = pd.read_csv(labeled_pairs_file, encoding = \"utf-8\")\n",
    "    all_data = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        all_data[i] = {\n",
    "            \"topic_a\": df[[\"topic_a\"]].iloc[i].values[0],\n",
    "            \"topic_b\": df[[\"topic_b\"]].iloc[i].values[0],\n",
    "            \"relation\": df[[\"relation\"]].iloc[i].values[0],\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def read_wikipedia_data():\n",
    "    df = pd.read_csv(wikipedia_data_file, encoding = \"utf-8\")\n",
    "    all_data = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        all_data[i] = {\n",
    "            'topic': df[[\"topic\"]].iloc[i].values[0],\n",
    "            'wiki_title': df[[\"wiki_title\"]].iloc[i].values[0],\n",
    "            'wiki_summary': df[[\"wiki_summary\"]].iloc[i].values[0],\n",
    "            'wiki_content': df[[\"wiki_content\"]].iloc[i].values[0],\n",
    "            'wiki_links': df[[\"wiki_links\"]].iloc[i].values[0],\n",
    "        }\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def read_concept_match(output_file):\n",
    "    df = pd.read_csv(output_file, encoding = \"utf-8\")\n",
    "    data = {}\n",
    "    for i in range(df.shape[0]):\n",
    "        concept = df[[\"concept\"]].iloc[i].values[0]\n",
    "        if df[[\"index\"]].iloc[i].isna().values[0]:\n",
    "            index = []\n",
    "        else:\n",
    "            index = df[[\"index\"]].iloc[i].values[0].split(\"|\")\n",
    "        data[concept] = {\n",
    "            \"index\" : index,\n",
    "            \"type\" : df[[\"type\"]].iloc[i].values[0]\n",
    "        }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def porter_stemming(text):\n",
    "    porter_stemmer  = PorterStemmer()\n",
    "    word_tokens = text.split(\" \")\n",
    "    words = [porter_stemmer.stem(word) for word in word_tokens]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def wordnet_lemmatization(text):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    word_tokens = text.split(\" \")\n",
    "    words = [wordnet_lemmatizer.lemmatize(word) for word in word_tokens]\n",
    "    new_text = \" \".join(words)\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(w)\n",
    "    sentence = \" \".join(filtered_sentence)\n",
    "    return sentence\n",
    "\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    new_text = \"\"\n",
    "    punctuations = \"!\\\"#$%&()*+-.,:;<=>?@[\\]^_'{|}~\"\n",
    "    for ch in text:\n",
    "        if ch not in punctuations:\n",
    "            new_text += ch\n",
    "    return new_text\n",
    "\n",
    "\n",
    "def clean_text(content):\n",
    "    content = content.lower()\n",
    "    content = re.sub(r'\\d+', '', content)\n",
    "    content = remove_punctuations(content)\n",
    "    content = remove_stopwords(content)\n",
    "    content = porter_stemming(content)\n",
    "    # content = wordnet_lemmatization(content)\n",
    "    content = content.strip()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching concept title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_match_data(matching_data, output_file):\n",
    "    df_match_data = pd.DataFrame(columns = [\"concept\", \"index\", \"type\"])\n",
    "    for i in range(len(matching_data)):\n",
    "        df_match_data = df_match_data.append(matching_data[i], ignore_index = True)\n",
    "    df_match_data.to_csv(output_file)\n",
    "    return True\n",
    "\n",
    "\n",
    "def direct_matching(title, concept):\n",
    "    title = clean_text(title).split(\" \")\n",
    "    concept = clean_text(concept).split(\" \")\n",
    "    if set(concept).issubset(set(title)) and len(concept) == len(title):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def concept_in_title(title, concept):\n",
    "    title = clean_text(title).split(\" \")\n",
    "    concept = clean_text(concept).split(\" \")\n",
    "    if set(concept).issubset(set(title)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def title_in_concept(title, concept):\n",
    "    title = clean_text(title).split(\" \")\n",
    "    concept = clean_text(concept).split(\" \")\n",
    "    if set(title).issubset(set(concept)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def matching_function(title, concept, key_terms, func_type):\n",
    "    if func_type == 1:\n",
    "        if direct_matching(title, concept):\n",
    "            return True\n",
    "        else:\n",
    "            flag = 0\n",
    "            for key_term in key_terms:\n",
    "                if direct_matching(title, key_term):\n",
    "                    flag = 1\n",
    "                    break\n",
    "            if flag: return True\n",
    "            else: return False\n",
    "\n",
    "    elif func_type == 2:\n",
    "        if concept_in_title(title, concept):\n",
    "            return True\n",
    "        else:\n",
    "            flag = 0\n",
    "            for key_term in key_terms:\n",
    "                if concept_in_title(title, key_term):\n",
    "                    flag = 1\n",
    "                    break\n",
    "            if flag: return True\n",
    "            else: return False\n",
    "\n",
    "    elif func_type == 3:\n",
    "        if title_in_concept(title, concept):\n",
    "            return True\n",
    "        else:\n",
    "            flag = 0\n",
    "            for key_term in key_terms:\n",
    "                if title_in_concept(title, key_term):\n",
    "                    flag = 1\n",
    "                    break\n",
    "            if flag: return True\n",
    "            else: return False\n",
    "\n",
    "#--------------------------------------------------------------------#\n",
    "\n",
    "def match_title_concept():\n",
    "    book_data = read_book_data()\n",
    "    concept_data = read_concepts_file()\n",
    "    matching_data = {}\n",
    "    index = 0\n",
    "\n",
    "    for i in range(len(concept_data)):\n",
    "        concept = concept_data[i][\"concept\"]\n",
    "        key_terms = concept_data[i][\"key_terms\"].split(\"|\")\n",
    "        matched_index = []\n",
    "\n",
    "        for j in range(len(book_data)):\n",
    "            title = book_data[j][\"title\"]\n",
    "            if matching_function(title, concept, key_terms, func_type = 1):\n",
    "                section = book_data[j][\"section\"]\n",
    "                matched_index.append(section)\n",
    "\n",
    "        if len(matched_index) == 0:\n",
    "            for j in range(len(book_data)):\n",
    "                title = book_data[j][\"title\"]\n",
    "                if matching_function(title, concept, key_terms, func_type = 2):\n",
    "                    section = book_data[j][\"section\"]\n",
    "                    matched_index.append(section)\n",
    "            if len(matched_index) == 0:\n",
    "                for j in range(len(book_data)):\n",
    "                    title = book_data[j][\"title\"]\n",
    "                    if matching_function(title, concept, key_terms, func_type = 3):\n",
    "                        section = book_data[j][\"section\"]\n",
    "                        matched_index.append(section)\n",
    "                if len(matched_index) == 0:\n",
    "                    concept_type = 0\n",
    "                else:\n",
    "                    concept_type = 3\n",
    "            else:\n",
    "                concept_type = 2\n",
    "        else:\n",
    "            concept_type = 1\n",
    "\n",
    "        matching_data[index] = {\n",
    "            \"concept\": concept,\n",
    "            \"index\": \"|\".join(matched_index),\n",
    "            \"type\": concept_type\n",
    "        }\n",
    "        index += 1\n",
    "    return matching_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_data = match_title_concept()\n",
    "output_file = \"required_data/concept_title_match.csv\"\n",
    "save_match_data(matching_data, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_match_data(matching_data, output_file):\n",
    "    df_match_data = pd.DataFrame(columns = [\"concept\", \"index\", \"type\"])\n",
    "    for i in range(len(matching_data)):\n",
    "        df_match_data = df_match_data.append(matching_data[i], ignore_index = True)\n",
    "    df_match_data.to_csv(output_file)\n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(concept_type):\n",
    "    index = 0\n",
    "    for i in range(len(matching_data)):\n",
    "        concept = matching_data[i][\"concept\"]\n",
    "        conc_type = matching_data[i][\"type\"]\n",
    "        concept_len = len(matching_data[i][\"index\"])\n",
    "        if conc_type == concept_type:\n",
    "            print(concept, concept_len)\n",
    "            index += 1\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle of incidence 0\n",
      "Real image 0\n",
      "Crystallinity 0\n",
      "Hardness 0\n",
      "Virtual image 0\n",
      "Electrical polarity 0\n",
      "Hertz 0\n",
      "Stiffness 0\n",
      "Tangential and normal components 0\n",
      "Joule 0\n",
      "Planet 0\n",
      "Temperature 0\n",
      "Kilogram 0\n",
      "Friction 0\n",
      "Gravitational constant 0\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "get_stats(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absorption spectroscopy 1\n",
      "Refraction 1\n",
      "Emission spectrum 1\n",
      "Potential energy 1\n",
      "Newton's laws of motion 1\n",
      "Relative velocity 1\n",
      "Electric potential 1\n",
      "Hooke's law 1\n",
      "Resonance (particle physics) 1\n",
      "Work (physics) 1\n",
      "Gravitational acceleration 1\n",
      "Diffraction 1\n",
      "Transverse wave 1\n",
      "Electroscope 1\n",
      "Torque 1\n",
      "Photoelectric effect 1\n",
      "Laser 1\n",
      "Sound intensity 1\n",
      "Dielectric 1\n",
      "Standing wave 1\n",
      "Refracting telescope 1\n",
      "Telescope 1\n",
      "Newton's law of universal gravitation 1\n",
      "Elastic collision 1\n",
      "Position (vector) 1\n",
      "Optical microscope 1\n",
      "Snell's law 1\n",
      "Insulator (electricity) 1\n",
      "Inelastic collision 1\n",
      "Electromotive force 1\n",
      "Huygens–Fresnel principle 1\n",
      "Magnetic field 1\n",
      "Plane mirror 1\n",
      "Gravitational field 1\n",
      "Electromagnetic radiation 1\n",
      "Capacitance 1\n",
      "Specular reflection 1\n",
      "Electromagnetic spectrum 1\n",
      "Direction (geometry) 1\n",
      "Energy 1\n",
      "Power (physics) 1\n",
      "Reflection (physics) 1\n",
      "Euclidean vector 1\n",
      "Free fall 1\n",
      "Interference (wave propagation) 1\n",
      "Acceleration 1\n",
      "Ohmmeter 1\n",
      "Musical tone 1\n",
      "Pitch (music) 1\n",
      "Capacitor 1\n",
      "Voltmeter 1\n",
      "Kinetic energy 1\n",
      "Physics 1\n",
      "Free body diagram 1\n",
      "Ammeter 1\n",
      "Magnification 1\n",
      "Scalar multiplication 1\n",
      "Total internal reflection 1\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "concept_type = 1\n",
    "index = 0\n",
    "for i in range(len(matching_data)):\n",
    "    concept = matching_data[i][\"concept\"]\n",
    "    conc_type = matching_data[i][\"type\"]\n",
    "    concept_len = len(matching_data[i][\"index\"])\n",
    "    if conc_type == concept_type and concept_len == 1:\n",
    "        print(concept, concept_len)\n",
    "        index += 1\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnet 11\n",
      "Gravity 3\n",
      "Wavelength 4\n",
      "Motion (physics) 18\n",
      "Plasticity (physics) 2\n",
      "Velocity 6\n",
      "Light 8\n",
      "Motion graphs and derivatives 2\n",
      "Frequency 2\n",
      "Mass 2\n",
      "Amplitude 3\n",
      "Speed 6\n",
      "Sound 7\n",
      "Elasticity (physics) 3\n",
      "Electric field 3\n",
      "Doppler effect 4\n",
      "Le Sage's theory of gravitation 3\n",
      "Wave 23\n",
      "Geometrical optics 5\n",
      "Creep (deformation) 2\n",
      "Fracture 2\n",
      "Color 11\n",
      "Lever 3\n",
      "Distance 2\n",
      "Electron 7\n",
      "Collision 3\n",
      "Magnetism 11\n",
      "Displacement (vector) 3\n",
      "Electric charge 11\n",
      "Pigment 2\n",
      "Scalar (mathematics) 2\n",
      "Electrostatics 3\n",
      "Ray (optics) 3\n",
      "Ohm 5\n",
      "Projectile motion 2\n",
      "Electrical conductor 2\n",
      "Field (physics) 12\n",
      "Gravity of Earth 3\n",
      "Compass 2\n",
      "Motion 18\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "concept_type = 2\n",
    "index = 0\n",
    "for i in range(len(matching_data)):\n",
    "    concept = matching_data[i][\"concept\"]\n",
    "    conc_type = matching_data[i][\"type\"]\n",
    "    concept_len = len(matching_data[i][\"index\"].split(\"|\"))\n",
    "    if conc_type == concept_type and concept_len > 1:\n",
    "        print(concept, concept_len)\n",
    "        index += 1\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absorption spectroscopy 1\n",
      "Refraction 1\n",
      "Emission spectrum 1\n",
      "Potential energy 1\n",
      "Newton's laws of motion 1\n",
      "Relative velocity 1\n",
      "Electric potential 1\n",
      "Hooke's law 1\n",
      "Resonance (particle physics) 1\n",
      "Work (physics) 1\n",
      "Gravitational acceleration 1\n",
      "Diffraction 1\n",
      "Transverse wave 1\n",
      "Electroscope 1\n",
      "Torque 1\n",
      "Photoelectric effect 1\n",
      "Laser 1\n",
      "Sound intensity 1\n",
      "Dielectric 1\n",
      "Standing wave 1\n",
      "Refracting telescope 1\n",
      "Telescope 1\n",
      "Newton's law of universal gravitation 1\n",
      "Elastic collision 1\n",
      "Position (vector) 1\n",
      "Optical microscope 1\n",
      "Snell's law 1\n",
      "Insulator (electricity) 1\n",
      "Inelastic collision 1\n",
      "Electromotive force 1\n",
      "Huygens–Fresnel principle 1\n",
      "Magnetic field 1\n",
      "Plane mirror 1\n",
      "Gravitational field 1\n",
      "Electromagnetic radiation 1\n",
      "Capacitance 1\n",
      "Specular reflection 1\n",
      "Electromagnetic spectrum 1\n",
      "Direction (geometry) 1\n",
      "Energy 1\n",
      "Power (physics) 1\n",
      "Reflection (physics) 1\n",
      "Euclidean vector 1\n",
      "Free fall 1\n",
      "Interference (wave propagation) 1\n",
      "Acceleration 1\n",
      "Ohmmeter 1\n",
      "Musical tone 1\n",
      "Pitch (music) 1\n",
      "Capacitor 1\n",
      "Voltmeter 1\n",
      "Kinetic energy 1\n",
      "Physics 1\n",
      "Free body diagram 1\n",
      "Ammeter 1\n",
      "Magnification 1\n",
      "Scalar multiplication 1\n",
      "Total internal reflection 1\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "concept_type = 3\n",
    "index = 0\n",
    "for i in range(len(matching_data)):\n",
    "    concept = matching_data[i][\"concept\"]\n",
    "    conc_type = matching_data[i][\"type\"]\n",
    "    concept_len = len(matching_data[i][\"index\"])\n",
    "    if conc_type == concept_type and concept_len == 1:\n",
    "        print(concept, concept_len)\n",
    "        index += 1\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extraction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiki_data(concept):\n",
    "    wiki_data = read_wikipedia_data()\n",
    "    for i in range(len(wiki_data)):\n",
    "        title = wiki_data[i][\"topic\"]\n",
    "        if title == concept:\n",
    "            break\n",
    "    summary = wiki_data[i][\"wiki_summary\"]\n",
    "    content = wiki_data[i][\"wiki_content\"]\n",
    "    return (summary, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_data(book_data):\n",
    "    section_list = [book_data[i][\"section\"] for i in range(len(book_data))]\n",
    "    section_data = {}\n",
    "\n",
    "    for i in range(len(section_list)):\n",
    "        current_collection = [section_list[i]]\n",
    "        for j in range(i+1, len(section_list)):\n",
    "            x1 = len(section_list[i].split(\".\"))\n",
    "            x2 = len(section_list[j].split(\".\"))\n",
    "            if x2 > x1:\n",
    "                current_collection.append(section_list[j])\n",
    "            else:\n",
    "                section = section_list[i]\n",
    "                section_data[section] = \"|\".join(current_collection)\n",
    "                break\n",
    "        if section_list[i] == '31':\n",
    "            section_data['31'] = \"|\".join(current_collection)\n",
    "    return section_data\n",
    "\n",
    "\n",
    "def get_data(book_data, section):\n",
    "    for i in range(len(book_data)):\n",
    "        if book_data[i][\"section\"] == section:\n",
    "            break\n",
    "    title = str(book_data[i][\"title\"])\n",
    "    content = str(book_data[i][\"content\"])\n",
    "    text = title + \"\\n\" + content\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_section_content(section, section_data, book_data):\n",
    "    req_sections = section_data[section].split(\"|\")\n",
    "    content = \"\"\n",
    "    for section in req_sections:\n",
    "        content += get_data(book_data, section)\n",
    "        content += \"\\n\"\n",
    "    return content\n",
    "\n",
    "\n",
    "def get_book_data(section):\n",
    "    book_data = read_book_data()\n",
    "    section_data = get_section_data(book_data)\n",
    "    print(section_data[section])\n",
    "    content = get_section_content(section, section_data, book_data)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_sections(concept):\n",
    "    file_name = \"required_data/concept_title_match.csv\"\n",
    "    matched_data = read_concept_match(file_name)\n",
    "    data = matched_data[concept]\n",
    "    return data            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index': ['25',\n",
       "  '25.2',\n",
       "  '25.3.1',\n",
       "  '25.3.2',\n",
       "  '25.3.3',\n",
       "  '25.3.4',\n",
       "  '25.3.5',\n",
       "  '25.4.1',\n",
       "  '25.4.2',\n",
       "  '25.4.3',\n",
       "  '31.4.3'],\n",
       " 'type': 2}"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_matched_sections(\"Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document matching code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_document_similarity(documents):\n",
    "    tfidf_vectorizer = TfidfVectorizer(tokenizer = text_cleaning)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
    "    doc_similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix)\n",
    "    return doc_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36651513 1.         0.72875508 0.50699287]]\n"
     ]
    }
   ],
   "source": [
    "documents = (\n",
    "    \"The sky is blue\",\n",
    "    \"The sun is bright\",\n",
    "    \"The sun in the sky is bright\",\n",
    "    \"We can see the shining sun, the bright sun\"\n",
    ")\n",
    "print(tfidf_document_similarity(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = get_matched_sections(\"Inertial frame of reference\")[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.2.1', '21.5', '21.5.2']"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_summary, wiki_content = get_wiki_data(\"Gravity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "documents.append(wiki_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in index_list:\n",
    "    content = get_book_data(index)\n",
    "    documents.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tfidf_document_similarity(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.45095139, 0.5676293 , 0.47035654])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'End of Chapter Exercises: Gravity and Mechanical Energy\\n\\n'"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_data(\"4.8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['24', '24.1', '25', '25.2', '25.3.1', '25.3.2', '25.3.3', '25.3.4', '25.3.5', '25.4.1', '25.4.2', '25.4.3', '31.4.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['3.2.1', '21.5', '21.5.2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_sections(arr):\n",
    "    all_data = []\n",
    "    current_arr = [arr[0]]\n",
    "    i = 1\n",
    "    while i < len(arr):\n",
    "        if current_arr[0] in arr[i]:\n",
    "            current_arr.append(arr[i])        \n",
    "            i += 1\n",
    "        else:\n",
    "            all_data.append(current_arr)\n",
    "            current_arr = [arr[i]]\n",
    "            i += 1\n",
    "    all_data.append(current_arr)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3.2.1'], ['21.5', '21.5.2']]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_sections(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sort_sections(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('1.2',)\n",
      "('2,1',)\n",
      "('3.4',)\n",
      "('1.2', '2,1')\n",
      "('1.2', '3.4')\n",
      "('2,1', '3.4')\n",
      "('1.2', '2,1', '3.4')\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "stuff = [\"1.2\", \"2,1\", \"3.4\"]\n",
    "for L in range(0, len(stuff)+1):\n",
    "    for subset in itertools.combinations(stuff, L):\n",
    "        print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [\"1.2\", \"2,1\", \"3.4\"]\n",
    "def get_section_combination(arr):\n",
    "    subsets = []\n",
    "    for l in range(0, len(arr) + 1):\n",
    "        for subset in itertools.combinations(arr, l):\n",
    "            subsets.append(subset)\n",
    "    subsets = [subsets[i] for i in range(1, len(subsets))]\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.2',),\n",
       " ('2,1',),\n",
       " ('3.4',),\n",
       " ('1.2', '2,1'),\n",
       " ('1.2', '3.4'),\n",
       " ('2,1', '3.4'),\n",
       " ('1.2', '2,1', '3.4')]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_section_combination(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = ['12.3', '3.4', '4.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz(arr):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
