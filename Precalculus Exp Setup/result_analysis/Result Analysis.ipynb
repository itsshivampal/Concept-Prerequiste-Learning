{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_state(val, theta):\n",
    "    if val >= theta: return 1\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "def compare_result(result, truth):\n",
    "    if truth == 1:\n",
    "        if result == 1: return 1\n",
    "        elif result == 0: return 2\n",
    "    elif truth == 0:\n",
    "        if result == 1: return 3\n",
    "        elif result == 0: return 4\n",
    "\n",
    "\n",
    "def estimation_measures(TP, FN, FP, TN):\n",
    "    if TP == 0 and FP == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = TP/(TP + FP)\n",
    "\n",
    "    if TP == 0 and FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP/(TP + FN)\n",
    "\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1_score = 0\n",
    "    else:\n",
    "        f1_score = 2*precision*recall/(precision + recall)\n",
    "    return f1_score\n",
    "\n",
    "\n",
    "\n",
    "def check_estimation(y_estimate, y_truth, theta):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(len(y_estimate)):\n",
    "        estimated = y_estimate[i]\n",
    "        truth = y_truth[i]\n",
    "        result = check_state(estimated, theta)\n",
    "        score_state = compare_result(result, truth)\n",
    "        if score_state == 1: TP += 1\n",
    "        elif score_state == 2: FN += 1\n",
    "        elif score_state == 3: FP += 1\n",
    "        elif score_state == 4: TN += 1\n",
    "    data = estimation_measures(TP, FN, FP, TN)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_theta(est_val, ground_val):\n",
    "    theta_values = [float(\"{0:.2f}\".format((0.0 + 0.02*i))) for i in range(50)]\n",
    "    f1_score = []\n",
    "    for theta in theta_values:\n",
    "        f1 = check_estimation(est_val, ground_val, theta)\n",
    "        f1_score.append(f1)\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(1, len(theta_values)):\n",
    "        if f1_score[index] < f1_score[i]:\n",
    "            index = i\n",
    "#     print(theta_values[index], f1_score[index])\n",
    "#     plt.plot(theta_values, f1_score)\n",
    "#     plt.show()\n",
    "    print(theta_values[index])\n",
    "    return theta_values[index]\n",
    "\n",
    "\n",
    "def get_predicted_value(X, theta):\n",
    "    pred = []\n",
    "    for i in range(len(X)):\n",
    "        if X[i] < theta:\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result):\n",
    "    print(\"Precision: %.1f\" % result[0])\n",
    "    print(\"Recall: %.1f\" % result[1])\n",
    "    print(\"F1 Score: %.1f\" % result[2])\n",
    "    print(\"Area Under Curve: %.1f\" % result[3])\n",
    "    \n",
    "\n",
    "def evaluation_results(y_test, y_predict):\n",
    "    recall = recall_score(y_test, y_predict)*100\n",
    "    precision = precision_score(y_test, y_predict)*100\n",
    "    f1 = f1_score(y_test, y_predict)*100\n",
    "    auc = roc_auc_score(y_test, y_predict)*100\n",
    "    return [precision, recall, f1, auc]\n",
    "\n",
    "\n",
    "def k_fold_testing(X, Y):\n",
    "    results = []\n",
    "    kf = KFold(n_splits = 5)\n",
    "    kf.get_n_splits(X)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        x_train, x_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        opt_theta = get_optimal_theta(x_train, y_train)\n",
    "        y_predict = get_predicted_value(x_test, opt_theta)\n",
    "        result = evaluation_results(y_test, y_predict)\n",
    "        results.append(result)\n",
    "    results = np.array(results)\n",
    "    final_result = np.mean(results, axis = 0)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>topic_a</th>\n",
       "      <th>topic_b</th>\n",
       "      <th>relation</th>\n",
       "      <th>tfidf_score</th>\n",
       "      <th>wiki_tfidf_score</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>refd_equal</th>\n",
       "      <th>refd_tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Differential equation</td>\n",
       "      <td>Number</td>\n",
       "      <td>1</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0.006426</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.082802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Partial fraction decomposition</td>\n",
       "      <td>Arithmetic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>-0.001364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Equation</td>\n",
       "      <td>Quadratic equation</td>\n",
       "      <td>0</td>\n",
       "      <td>0.186873</td>\n",
       "      <td>0.186873</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.030000</td>\n",
       "      <td>-0.120911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Linear inequality</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>-0.032310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Binomial theorem</td>\n",
       "      <td>Addition</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>0.035118</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.171053</td>\n",
       "      <td>0.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>Limit (mathematics)</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.627841</td>\n",
       "      <td>0.909152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>Sine</td>\n",
       "      <td>Inverse trigonometric functions</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2050</td>\n",
       "      <td>2050</td>\n",
       "      <td>-0.218045</td>\n",
       "      <td>-0.638182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>Quadratic equation</td>\n",
       "      <td>Rational number</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>2051</td>\n",
       "      <td>2051</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.393114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>Summation</td>\n",
       "      <td>Arithmetic</td>\n",
       "      <td>1</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>0.047547</td>\n",
       "      <td>2053</td>\n",
       "      <td>2053</td>\n",
       "      <td>0.054377</td>\n",
       "      <td>-0.217233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>917</td>\n",
       "      <td>Equation</td>\n",
       "      <td>Zero of a function</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2054</td>\n",
       "      <td>2054</td>\n",
       "      <td>-0.232500</td>\n",
       "      <td>-0.875958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0_x                         topic_a  \\\n",
       "0               0           Differential equation   \n",
       "1               1  Partial fraction decomposition   \n",
       "2               2                        Equation   \n",
       "3               3                     Mathematics   \n",
       "4               4                Binomial theorem   \n",
       "..            ...                             ...   \n",
       "913           913             Limit (mathematics)   \n",
       "914           914                            Sine   \n",
       "915           915              Quadratic equation   \n",
       "916           916                       Summation   \n",
       "917           917                        Equation   \n",
       "\n",
       "                             topic_b  relation  tfidf_score  wiki_tfidf_score  \\\n",
       "0                             Number         1     0.006426          0.006426   \n",
       "1                         Arithmetic         1     0.047547          0.000000   \n",
       "2                 Quadratic equation         0     0.186873          0.186873   \n",
       "3                  Linear inequality         0     0.000000          0.000000   \n",
       "4                           Addition         1     0.035118          0.035118   \n",
       "..                               ...       ...          ...               ...   \n",
       "913                      Mathematics         1     1.000000          1.000000   \n",
       "914  Inverse trigonometric functions         0     0.000000          0.000000   \n",
       "915                  Rational number         0     0.022569          0.022569   \n",
       "916                       Arithmetic         1     0.047547          0.047547   \n",
       "917               Zero of a function         0     0.000000          0.000000   \n",
       "\n",
       "     Unnamed: 0_y  Unnamed: 0.1  refd_equal  refd_tfidf  \n",
       "0               0             0    0.054299    0.082802  \n",
       "1               3             3    0.076923   -0.001364  \n",
       "2               8             8   -0.030000   -0.120911  \n",
       "3               9             9   -0.666667   -0.032310  \n",
       "4              10            10    0.171053    0.064591  \n",
       "..            ...           ...         ...         ...  \n",
       "913          2048          2048    0.627841    0.909152  \n",
       "914          2050          2050   -0.218045   -0.638182  \n",
       "915          2051          2051    0.308333    0.393114  \n",
       "916          2053          2053    0.054377   -0.217233  \n",
       "917          2054          2054   -0.232500   -0.875958  \n",
       "\n",
       "[918 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_propose = pd.read_csv(\"predicted_prereq.csv\")\n",
    "df_refd = pd.read_csv(\"refd_estimated_results.csv\")\n",
    "df_final = pd.merge(df_propose, df_refd, how = 'inner', on = ['topic_a', 'topic_b', 'relation'])\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propose = df_final[[\"topic_a\", \"topic_b\", \"relation\", \"tfidf_score\", \"wiki_tfidf_score\"]]\n",
    "df_propose.to_csv(\"final_propose.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refd = df_final[[\"topic_a\", \"topic_b\", \"relation\", \"refd_equal\", \"refd_tfidf\"]]\n",
    "df_refd.to_csv(\"final_refd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - Proposed Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propose = pd.read_csv(\"final_propose.csv\")\n",
    "X_propose1 = df_propose[[\"tfidf_score\"]].to_numpy().ravel()\n",
    "X_propose2 = df_propose[[\"wiki_tfidf_score\"]].to_numpy().ravel()\n",
    "y_propose = df_propose[[\"relation\"]].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n",
      "0.04\n",
      "0.04\n",
      "0.04\n",
      "0.04\n",
      "Precision: 68.6\n",
      "Recall: 54.4\n",
      "F1 Score: 60.4\n",
      "Area Under Curve: 69.9\n"
     ]
    }
   ],
   "source": [
    "# Proposed book tfidf\n",
    "result = k_fold_testing(X_propose1, y_propose)\n",
    "print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Precision: 41.1\n",
      "Recall: 88.3\n",
      "F1 Score: 52.1\n",
      "Area Under Curve: 52.4\n"
     ]
    }
   ],
   "source": [
    "# Proposed book + wikipedia tfidf\n",
    "result = k_fold_testing(X_propose2, y_propose)\n",
    "print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - RefD Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propose = pd.read_csv(\"final_refd.csv\")\n",
    "X_propose1 = df_propose[[\"refd_equal\"]].to_numpy().ravel()\n",
    "X_propose2 = df_propose[[\"refd_tfidf\"]].to_numpy().ravel()\n",
    "y_propose = df_propose[[\"relation\"]].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04\n",
      "0.02\n",
      "0.02\n",
      "0.0\n",
      "0.0\n",
      "Precision: 62.1\n",
      "Recall: 82.4\n",
      "F1 Score: 70.7\n",
      "Area Under Curve: 76.6\n"
     ]
    }
   ],
   "source": [
    "# RefD with Equal Method\n",
    "result = k_fold_testing(X_propose1, y_propose)\n",
    "print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.02\n",
      "Precision: 54.0\n",
      "Recall: 73.4\n",
      "F1 Score: 61.8\n",
      "Area Under Curve: 68.2\n"
     ]
    }
   ],
   "source": [
    "# RefD with TFIDF Method\n",
    "result = k_fold_testing(X_propose2, y_propose)\n",
    "print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results - RefD Given Vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_propose = pd.read_csv(\"refd_given_vals.csv\")\n",
    "X_propose1 = df_propose[[\"refd_val\"]].to_numpy().ravel()\n",
    "# X_propose2 = df_propose[[\"refd_tfidf\"]].to_numpy().ravel()\n",
    "y_propose = df_propose[[\"output\"]].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 61.5\n",
      "Recall: 82.9\n",
      "F1 Score: 70.4\n",
      "Area Under Curve: 78.0\n"
     ]
    }
   ],
   "source": [
    "# RefD with Equal Method\n",
    "result = k_fold_testing(X_propose1, y_propose)\n",
    "print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
