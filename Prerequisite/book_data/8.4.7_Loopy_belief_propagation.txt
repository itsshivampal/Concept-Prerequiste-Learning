For many problems of practical interest, it will not be feasible to use exact in-
ference, and so we need to exploit effective approximation methods. An important
class of such approximations, that can broadly be called variational methods, will be
discussed in detail in Chapter 10. Complementing these deterministic approaches is
a wide range of sampling methods, also called Monte Carlo methods, that are based
on stochastic numerical sampling from distributions and that will be discussed at
length in Chapter 11.
Here we consider one simple approach to approximate inference in graphs with
loops, which builds directly on the previous discussion of exact inference in trees.
The idea is simply to apply the sum-product algorithm even though there is no guar-
antee that it will yield good results. This approach is known as loopy belief propa-
gation (Frey and MacKay, 1998) and is possible because the message passing rules
(8.66) and (8.69) for the sum-product algorithm are purely local. However, because
the graph now has cycles, information can flow many times around the graph. For
some models, the algorithm will converge, whereas for others it will not.
In order to apply this approach, we need to define a message passing schedule.
Let us assume that one message is passed at a time on any given link and in any
given direction. Each message sent from a node replaces any previous message sent
in the same direction across the same link and will itself be a function only of the
most recent messages received by that node at previous steps of the algorithm.
We have seen that a message can only be sent across a link from a node when
all other messages have been received by that node across its other links. Because
there are loops in the graph, this raises the problem of how to initiate the message
passing algorithm. To resolve this, we suppose that an initial message given by the
unit function has been passed across every link in each direction. Every node is then
in a position to send a message.
There are now many possible ways to organize the message passing schedule.
For example, the flooding schedule simultaneously passes a message across every
link in both directions at each time step, whereas schedules that pass one message at
a time are called serial schedules.
Following Kschischnang et al. (2001), we will say that a (variable or factor)
node a has a message pending on its link to a node b if node a has received any
message on any of its other links since the last time it send a message to b. Thus,
when a node receives a message on one of its links, this creates pending messages
on all of its other links. Only pending messages need to be transmitted because
418
8. GRAPHICAL MODELS
Exercise 8.29
other messages would simply duplicate the previous message on the same link. For
graphs that have a tree structure, any schedule that sends only pending messages
will eventually terminate once a message has passed in each direction across every
link. At this point, there are no pending messages, and the product of the received
messages at every variable give the exact marginal. In graphs having loops, however,
the algorithm may never terminate because there might always be pending messages,
although in practice it is generally found to converge within a reasonable time for
most applications. Once the algorithm has converged, or once it has been stopped
if convergence is not observed, the (approximate) local marginals can be computed
using the product of the most recently received incoming messages to each variable
node or factor node on every link.
In some applications, the loopy belief propagation algorithm can give poor re-
sults, whereas in other applications it has proven to be very effective. In particular,
state-of-the-art algorithms for decoding certain kinds of error-correcting codes are
equivalent to loopy belief propagation (Gallager, 1963; Berrou et al., 1993; McEliece
et al., 1998; MacKay and Neal, 1999; Frey, 1998).
