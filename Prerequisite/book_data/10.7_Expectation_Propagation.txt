505
We also need to optimize the variational parameters ξn, and this is also done by
L(q, ξ). Omitting terms that are independent of ξ, and
maximizing the lower bound
integrating over α, we have
L(q, ξ) =
q(w) ln h(w, ξ) dw + const.
(10.180)
Note that this has precisely the same form as (10.159), and so we can again appeal
to our earlier result (10.163), which can be obtained by direct optimization of the
marginal likelihood function, leading to re-estimation equations of the form
(ξnew
n )2 = φT
n
ΣN + µN µT
N
φn.
(10.181)
Appendix B
We have obtained re-estimation equations for the three quantities q(w), q(α),
and ξ, and so after making suitable initializations, we can cycle through these quan-
tities, updating each in turn. The required moments are given by
E [α] = aN
bN
wTw
E
= ΣN + µT
N µN .
(10.182)
(10.183)
10.7. Expectation Propagation
We conclude this chapter by discussing an alternative form of deterministic approx-
imate inference, known as expectation propagation or EP (Minka, 2001a; Minka,
2001b). As with the variational Bayes methods discussed so far, this too is based
on the minimization of a Kullback-Leibler divergence but now of the reverse form,
which gives the approximation rather different properties.
Consider for a moment the problem of minimizing KL(pq) with respect to q(z)
when p(z) is a fixed distribution and q(z) is a member of the exponential family and
so, from (2.194), can be written in the form
q(z) = h(z)g(η) exp
ηTu(z)
(10.184)
As a function of η, the Kullback-Leibler divergence then becomes
KL(pq) = − ln g(η) − ηTEp(z)[u(z)] + const
(10.185)
where the constant terms are independent of the natural parameters η. We can mini-
mize KL(pq) within this family of distributions by setting the gradient with respect
to η to zero, giving
(10.186)
However, we have already seen in (2.226) that the negative gradient of ln g(η) is
given by the expectation of u(z) under the distribution q(z). Equating these two
results, we obtain
−∇ ln g(η) = Ep(z)[u(z)].
Eq(z)[u(z)] = Ep(z)[u(z)].
(10.187)
1
p(D)
i
i
i
506
10. APPROXIMATE INFERENCE
We see that the optimum solution simply corresponds to matching the expected suf-
ficient statistics. So, for instance, if q(z) is a Gaussian N (z|µ, Σ) then we minimize
the Kullback-Leibler divergence by setting the mean µ of q(z) equal to the mean of
the distribution p(z) and the covariance Σ equal to the covariance of p(z). This is
sometimes called moment matching. An example of this was seen in Figure 10.3(a).
Now let us exploit this result to obtain a practical algorithm for approximate
inference. For many probabilistic models, the joint distribution of data D and hidden
variables (including parameters) θ comprises a product of factors in the form
p(D, θ) =
fi(θ).
(10.188)
This would arise, for example, in a model for independent, identically distributed
data in which there is one factor fn(θ) = p(xn|θ) for each data point xn, along
with a factor f0(θ) = p(θ) corresponding to the prior. More generally, it would also
apply to any model defined by a directed probabilistic graph in which each factor is a
conditional distribution corresponding to one of the nodes, or an undirected graph in
which each factor is a clique potential. We are interested in evaluating the posterior
distribution p(θ|D) for the purpose of making predictions, as well as the model
evidence p(D) for the purpose of model comparison. From (10.188) the posterior is
given by
(10.189)
fi(θ)
p(θ|D) =
and the model evidence is given by
p(D) =
fi(θ) dθ.
(10.190)
Here we are considering continuous variables, but the following discussion applies
equally to discrete variables with integrals replaced by summations. We shall sup-
pose that the marginalization over θ, along with the marginalizations with respect to
the posterior distribution required to make predictions, are intractable so that some
form of approximation is required.
Expectation propagation is based on an approximation to the posterior distribu-
tion which is also given by a product of factors
q(θ) =
1
Z
fi(θ)
i
(10.191)
fi(θ) in the approximation corresponds to one of the factors
in which each factor
fi(θ) in the true posterior (10.189), and the factor 1/Z is the normalizing constant
needed to ensure that the left-hand side of (10.191) integrates to unity. In order to
fi(θ) in some way,
obtain a practical algorithm, we need to constrain the factors
and in particular we shall assume that they come from the exponential family. The
product of the factors will therefore also be from the exponential family and so can
''''' 1
q\j(θ) = q(θ)
fj(θ)
fj(θ)
fi(θ)
fi(θ)
i=j
Z
i
i
1
p(D)
fj(θ)
507
fi(θ)
(10.193)
(10.194)
(10.195)
10.7. Expectation Propagation
be described by a finite set of sufficient statistics. For example, if each of the
is a Gaussian, then the overall approximation q(θ) will also be Gaussian.
Ideally we would like to determine the
fi(θ) by minimizing the Kullback-Leibler
divergence between the true posterior and the approximation given by
KL (pq) = KL
fi(θ)
(10.192)
Note that this is the reverse form of KL divergence compared with that used in varia-
tional inference. In general, this minimization will be intractable because the KL di-
vergence involves averaging with respect to the true distribution. As a rough approx-
imation, we could instead minimize the KL divergences between the corresponding
pairs fi(θ) and
fi(θ) of factors. This represents a much simpler problem to solve,
and has the advantage that the algorithm is noniterative. However, because each fac-
tor is individually approximated, the product of the factors could well give a poor
approximation.
Expectation propagation makes a much better approximation by optimizing each
factor in turn in the context of all of the remaining factors. It starts by initializing
fi(θ), and then cycles through the factors refining them one at a time.
the factors
This is similar in spirit to the update of factors in the variational Bayes framework
fj(θ). We first remove this
considered earlier. Suppose we wish to refine factor
fi(θ). Conceptually, we will now determine a
factor from the product to give
revised form of the factor
fj(θ) by ensuring that the product
i=j
qnew(θ) ∝
fi(θ)
is as close as possible to
i=j
fi(θ) for i = j. This ensures that the
in which we keep fixed all of the factors
approximation is most accurate in the regions of high posterior probability as defined
by the remaining factors. We shall see an example of this effect when we apply EP
fj(θ) from the
to the ‘clutter problem’. To achieve this, we first remove the factor
current approximation to the posterior by defining the unnormalized distribution
Section 10.7.1
Note that we could instead find q\j(θ) from the product of factors i = j, although
in practice division is usually easier. This is now combined with the factor fj(θ) to
give a distribution
1
Zj
fj(θ)q\j(θ)
(10.196)
40
30
20
10
0
−2
508
10. APPROXIMATE INFERENCE
1
0.8
0.6
0.4
0.2
0
−2
−1
0
1
2
3
4
Figure 10.14 Illustration of the expectation propagation approximation using a Gaussian distribution for the
example considered earlier in Figures 4.14 and 10.1. The left-hand plot shows the original distribution (yellow)
along with the Laplace (red), global variational (green), and EP (blue) approximations, and the right-hand plot
shows the corresponding negative logarithms of the distributions. Note that the EP distribution is broader than
that variational inference, as a consequence of the different form of KL divergence.
−1
0
1
2
3
4
where Zj is the normalization constant given by
Zj =
fj(θ)q\j(θ) dθ.
(10.197)
We now determine a revised factor
gence
fj(θ) by minimizing the Kullback-Leibler diver-
KL
fj(θ)q\j(θ)
Zj
qnew(θ)
(10.198)
This is easily solved because the approximating distribution qnew(θ) is from the ex-
ponential family, and so we can appeal to the result (10.187), which tells us that the
parameters of qnew(θ) are obtained by matching its expected sufficient statistics to
the corresponding moments of (10.196). We shall assume that this is a tractable oper-
ation. For example, if we choose q(θ) to be a Gaussian distribution N (θ|µ, Σ), then
µ is set equal to the mean of the (unnormalized) distribution fj(θ)q\j(θ), and Σ is
set to its covariance. More generally, it is straightforward to obtain the required ex-
pectations for any member of the exponential family, provided it can be normalized,
because the expected statistics can be related to the derivatives of the normalization
coefficient, as given by (2.226). The EP approximation is illustrated in Figure 10.14.
From (10.193), we see that the revised factor
qnew(θ) and dividing out the remaining factors so that
fj(θ) can be found by taking
fj(θ) = K
qnew(θ)
q\j(θ)
(10.199)
where we have used (10.195). The coefficient K is determined by multiplying both
q\j(θ) = q(θ)
fj(θ)q\j(θ) dθ
q(θ) ∝
fi(θ).
fi(θ).
fi(θ)
1
Z
i
i
i
sides of (10.199) by q\i(θ) and integrating to give
K =
10.7. Expectation Propagation
509
(10.200)
where we have used the fact that qnew(θ) is normalized. The value of K can therefore
be found by matching zeroth-order moments
fj(θ)q\j(θ) dθ =
fj(θ)q\j(θ) dθ.
(10.201)
Combining this with (10.197), we then see that K = Zj and so can be found by
evaluating the integral in (10.197).
In practice, several passes are made through the set of factors, revising each
factor in turn. The posterior distribution p(θ|D) is then approximated using (10.191),
and the model evidence p(D) can be approximated by using (10.190) with the factors
fi(θ) replaced by their approximations
fi(θ).
Expectation Propagation
We are given a joint distribution over observed data D and stochastic variables
θ in the form of a product of factors
p(D, θ) =
(10.202)
and we wish to approximate the posterior distribution p(θ|D) by a distribution
of the form
(10.203)
q(θ) =
We also wish to approximate the model evidence p(D).
fi(θ).
1. Initialize all of the approximating factors
2. Initialize the posterior approximation by setting
3. Until convergence:
(a) Choose a factor
(b) Remove
fj(θ) to refine.
fj(θ) from the posterior by division
(10.204)
(10.205)
fj(θ)
Zj =
q\j(θ)fj(θ) dθ.
(d) Evaluate and store the new factor
qnew(θ)
q\j(θ) .
4. Evaluate the approximation to the model evidence
fj(θ) = Zj
p(D) 
fi(θ) dθ.
i
(10.206)
(10.207)
(10.208)
510
10. APPROXIMATE INFERENCE
(c) Evaluate the new posterior by setting the sufficient statistics (moments)
of qnew(θ) equal to those of q\j(θ)fj(θ), including evaluation of the
normalization constant
A special case of EP, known as assumed density filtering (ADF) or moment
matching (Maybeck, 1982; Lauritzen, 1992; Boyen and Koller, 1998; Opper and
Winther, 1999), is obtained by initializing all of the approximating factors except
the first to unity and then making one pass through the factors updating each of them
once. Assumed density filtering can be appropriate for on-line learning in which data
points are arriving in a sequence and we need to learn from each data point and then
discard it before considering the next point. However, in a batch setting we have the
opportunity to re-use the data points many times in order to achieve improved ac-
curacy, and it is this idea that is exploited in expectation propagation. Furthermore,
if we apply ADF to batch data, the results will have an undesirable dependence on
the (arbitrary) order in which the data points are considered, which again EP can
overcome.
One disadvantage of expectation propagation is that there is no guarantee that
the iterations will converge. However, for approximations q(θ) in the exponential
family, if the iterations do converge, the resulting solution will be a stationary point
of a particular energy function (Minka, 2001a), although each iteration of EP does
not necessarily decrease the value of this energy function. This is in contrast to
variational Bayes, which iteratively maximizes a lower bound on the log marginal
likelihood, in which each iteration is guaranteed not to decrease the bound. It is
possible to optimize the EP cost function directly, in which case it is guaranteed
to converge, although the resulting algorithms can be slower and more complex to
implement.
Another difference between variational Bayes and EP arises from the form of
KL divergence that is minimized by the two algorithms, because the former mini-
mizes KL(qp) whereas the latter minimizes KL(pq). As we saw in Figure 10.3,
for distributions p(θ) which are multimodal, minimizing KL(pq) can lead to poor
approximations. In particular, if EP is applied to mixtures the results are not sen-
sible because the approximation tries to capture all of the modes of the posterior
distribution. Conversely, in logistic-type models, EP often out-performs both local
variational methods and the Laplace approximation (Kuss and Rasmussen, 2006).
10.7. Expectation Propagation
511
Figure 10.15 Illustration of the clutter problem
for a data space dimensionality of
D = 1. Training data points, de-
noted by the crosses, are drawn
from a mixture of two Gaussians
with components shown in red
and green. The goal is to infer the
mean of the green Gaussian from
the observed data.
−5
N
0
5
x
10
