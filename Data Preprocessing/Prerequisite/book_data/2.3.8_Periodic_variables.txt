Although Gaussian distributions are of great practical significance, both in their
own right and as building blocks for more complex probabilistic models, there are
situations in which they are inappropriate as density models for continuous vari-
ables. One important case, which arises in practical applications, is that of periodic
variables.
An example of a periodic variable would be the wind direction at a particular
geographical location. We might, for instance, measure values of wind direction on a
number of days and wish to summarize this using a parametric distribution. Another
example is calendar time, where we may be interested in modelling quantities that
are believed to be periodic over 24 hours or over an annual cycle. Such quantities
can conveniently be represented using an angular (polar) coordinate 0 � θ < 2π.
We might be tempted to treat periodic variables by choosing some direction
as the origin and then applying a conventional distribution such as the Gaussian.
Such an approach, however, would give results that were strongly dependent on the
arbitrary choice of origin. Suppose, for instance, that we have two observations at
θ1 = 1◦ and θ2 = 359◦, and we model them using a standard univariate Gaussian
distribution. If we choose the origin at 0◦, then the sample mean of this data set
will be 180◦ with standard deviation 179◦, whereas if we choose the origin at 180◦,
then the mean will be 0◦ and the standard deviation will be 1◦. We clearly need to
develop a special approach for the treatment of periodic variables.
Let us consider the problem of evaluating the mean of a set of observations
D = {θ1, . . . , θN} of a periodic variable. From now on, we shall assume that θ is
measured in radians. We have already seen that the simple average (θ1+···+θN )/N
will be strongly coordinate dependent. To find an invariant measure of the mean, we
note that the observations can be viewed as points on the unit circle and can therefore
be described instead by two-dimensional unit vectors x1, . . . , xN where xn = 1
for n = 1, . . . , N, as illustrated in Figure 2.17. We can average the vectors {xn}
1
N
n=1
N
N
x2
N
106
2. PROBABILITY DISTRIBUTIONS
Figure 2.17 Illustration of the representation of val-
ues θn of a periodic variable as two-
dimensional vectors xn living on the unit
circle. Also shown is the average x of
those vectors.
x4
xn
x3
¯x
¯r
x2
x1
x1
(2.167)
instead to give
x =
and then find the corresponding angle θ of this average. Clearly, this definition will
ensure that the location of the mean is independent of the origin of the angular coor-
dinate. Note that x will typically lie inside the unit circle. The Cartesian coordinates
of the observations are given by xn = (cos θn, sin θn), and we can write the Carte-
sian coordinates of the sample mean in the form x = (r cos θ, r sin θ). Substituting
into (2.167) and equating the x1 and x2 components then gives
r cos θ =
1
N
cos θn,
n=1
r sin θ =
1
N
sin θn.
(2.168)
n=1
Taking the ratio, and using the identity tan θ = sin θ/ cos θ, we can solve for θ to
give
θ = tan−1
(2.169)
n sin θn
n cos θn
Shortly, we shall see how this result arises naturally as the maximum likelihood
estimator for an appropriately defined distribution over a periodic variable.
We now consider a periodic generalization of the Gaussian called the von Mises
distribution. Here we shall limit our attention to univariate distributions, although
periodic distributions can also be found over hyperspheres of arbitrary dimension.
For an extensive discussion of periodic distributions, see Mardia and Jupp (2000).
By convention, we will consider distributions p(θ) that have period 2π. Any
probability density p(θ) defined over θ must not only be nonnegative and integrate
x2
107
p(x)
x1
(2.170)
(2.171)
(2.172)
(2.174)
(2.175)
(2.176)
2.3. The Gaussian Distribution
Figure 2.18 The von Mises distribution can be derived by considering
a two-dimensional Gaussian of the form (2.173), whose
density contours are shown in blue and conditioning on
the unit circle shown in red.
to one, but it must also be periodic. Thus p(θ) must satisfy the three conditions
r = 1
p(θ) � 0
p(θ) dθ = 1
2π
0
p(θ + 2π) = p(θ).
From (2.172), it follows that p(θ + M2π) = p(θ) for any integer M.
We can easily obtain a Gaussian-like distribution that satisfies these three prop-
erties as follows. Consider a Gaussian distribution over two variables x = (x1, x2)
having mean µ = (µ1, µ2) and a covariance matrix Σ = σ2I where I is the 2 × 2
identity matrix, so that
p(x1, x2) =
1
2πσ2 exp
(x1 − µ1)2 + (x2 − µ2)2
2σ2
(2.173)
The contours of constant p(x) are circles, as illustrated in Figure 2.18. Now suppose
we consider the value of this distribution along a circle of fixed radius. Then by con-
struction this distribution will be periodic, although it will not be normalized. We can
determine the form of this distribution by transforming from Cartesian coordinates
(x1, x2) to polar coordinates (r, θ) so that
x2 = r sin θ.
We also map the mean µ into polar coordinates by writing
x1 = r cos θ,
µ1 = r0 cos θ0,
µ2 = r0 sin θ0.
Next we substitute these transformations into the two-dimensional Gaussian distribu-
tion (2.173), and then condition on the unit circle r = 1, noting that we are interested
only in the dependence on θ. Focussing on the exponent in the Gaussian distribution
we have
1
2σ2
= r0
(r cos θ − r0 cos θ0)2 + (r sin θ − r0 sin θ0)2
1
2σ2
σ2 cos(θ − θ0) + const
0 − 2r0 cos θ cos θ0 − 2r0 sin θ sin θ0
1 + r2
N
108
2. PROBABILITY DISTRIBUTIONS
m = 5, θ0 = π/4
m = 1, θ0 = 3π/4
3π/4
π/4
0
2π
m = 5, θ0 = π/4
m = 1, θ0 = 3π/4
Figure 2.19 The von Mises distribution plotted for two different parameter values, shown as a Cartesian plot
on the left and as the corresponding polar plot on the right.
Exercise 2.51
Exercise 2.52
where ‘const’ denotes terms independent of θ, and we have made use of the following
trigonometrical identities
cos2 A + sin2 A = 1
(2.177)
(2.178)
If we now define m = r0/σ2, we obtain our final expression for the distribution of
p(θ) along the unit circle r = 1 in the form
cos A cos B + sin A sin B = cos(A − B).
p(θ|θ0, m) =
2πI0(m)
exp{m cos(θ − θ0)}
1
(2.179)
which is called the von Mises distribution, or the circular normal. Here the param-
eter θ0 corresponds to the mean of the distribution, while m, which is known as
the concentration parameter, is analogous to the inverse variance (precision) for the
Gaussian. The normalization coefficient in (2.179) is expressed in terms of I0(m),
which is the zeroth-order Bessel function of the first kind (Abramowitz and Stegun,
1965) and is defined by
I0(m) =
1
2π
2π
0
exp{m cos θ} dθ.
(2.180)
For large m, the distribution becomes approximately Gaussian. The von Mises dis-
tribution is plotted in Figure 2.19, and the function I0(m) is plotted in Figure 2.20.
Now consider the maximum likelihood estimators for the parameters θ0 and m
for the von Mises distribution. The log likelihood function is given by
ln p(D|θ0, m) = −N ln(2π) − N ln I0(m) + m
cos(θn − θ0).
n=1
(2.181)
2.3. The Gaussian Distribution
n=1
N
1
0.5
n=1
N
0
0
0
N
5
m
N
I0(m)
3000
2000
1000
0
0
5
m
A(m)
10
Figure 2.20 Plot of the Bessel function I0(m) defined by (2.180), together with the function A(m) defined by
(2.186).
Setting the derivative with respect to θ0 equal to zero gives
sin(θn − θ0) = 0.
To solve for θ0, we make use of the trigonometric identity
Exercise 2.53
from which we obtain
sin(A − B) = cos B sin A − cos A sin B
0 = tan−1
θML
n sin θn
n cos θn
which we recognize as the result (2.169) obtained earlier for the mean of the obser-
vations viewed in a two-dimensional Cartesian space.
Similarly, maximizing (2.181) with respect to m, and making use of I0(m) =
I1(m) (Abramowitz and Stegun, 1965), we have
where we have substituted for the maximum likelihood solution for θML
that we are performing a joint optimization over θ and m), and we have defined
0
(recalling
A(m) =
1
N
cos(θn − θML
A(m) = I1(m)
I0(m) .
The function A(m) is plotted in Figure 2.20. Making use of the trigonometric iden-
tity (2.178), we can write (2.185) in the form
A(mML) =
1
N
cos θn
cos θML
0 −
n=1
sin θn
sin θML
0
(2.187)
n=1
1
N
109
10
(2.182)
(2.183)
(2.184)
(2.185)
(2.186)
110
2. PROBABILITY DISTRIBUTIONS
100
80
60
40
1
On the left
Figure 2.21 Plots of the ‘old faith-
ful’ data in which the blue curves
show contours of constant proba-
bility density.
is a
single Gaussian distribution which
has been fitted to the data us-
ing maximum likelihood. Note that
this distribution fails to capture the
two clumps in the data and indeed
places much of its probability mass
in the central region between the
clumps where the data are relatively
sparse. On the right the distribution
is given by a linear combination of
two Gaussians which has been fitted
to the data by maximum likelihood
using techniques discussed Chap-
ter 9, and which gives a better rep-
resentation of the data.
100
80
60
40
1
2
3
4
5
6
2
3
4
5
6
The right-hand side of (2.187) is easily evaluated, and the function A(m) can be
inverted numerically.
For completeness, we mention briefly some alternative techniques for the con-
struction of periodic distributions. The simplest approach is to use a histogram of
observations in which the angular coordinate is divided into fixed bins. This has the
virtue of simplicity and flexibility but also suffers from significant limitations, as we
shall see when we discuss histogram methods in more detail in Section 2.5. Another
approach starts, like the von Mises distribution, from a Gaussian distribution over a
Euclidean space but now marginalizes onto the unit circle rather than conditioning
(Mardia and Jupp, 2000). However, this leads to more complex forms of distribution
and will not be discussed further. Finally, any valid distribution over the real axis
(such as a Gaussian) can be turned into a periodic distribution by mapping succes-
sive intervals of width 2π onto the periodic variable (0, 2π), which corresponds to
‘wrapping’ the real axis around unit circle. Again, the resulting distribution is more
complex to handle than the von Mises distribution.
One limitation of the von Mises distribution is that it is unimodal. By forming
mixtures of von Mises distributions, we obtain a flexible framework for modelling
periodic variables that can handle multimodality. For an example of a machine learn-
ing application that makes use of von Mises distributions, see Lawrence et al. (2002),
and for extensions to modelling conditional densities for regression problems, see
Bishop and Nabney (1996).
