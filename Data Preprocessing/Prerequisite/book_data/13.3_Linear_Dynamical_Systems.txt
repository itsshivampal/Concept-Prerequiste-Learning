635
and so we can transform the model into an equivalent standard HMM having a single
chain of latent variables each of which has KM latent states. We can then run the
standard forward-backward recursions in the E step. This has computational com-
plexity O(N K 2M ) that is exponential in the number M of latent chains and so will
be intractable for anything other than small values of M. One solution would be
to use sampling methods (discussed in Chapter 11). As an elegant deterministic al-
ternative, Ghahramani and Jordan (1997) exploited variational inference techniques
to obtain a tractable algorithm for approximate inference. This can be done using
a simple variational posterior distribution that is fully factorized with respect to the
latent variables, or alternatively by using a more powerful approach in which the
variational distribution is described by independent Markov chains corresponding to
the chains of latent variables in the original model. In the latter case, the variational
inference algorithms involves running independent forward and backward recursions
along each chain, which is computationally efficient and yet is also able to capture
correlations between variables within the same chain.
Clearly, there are many possible probabilistic structures that can be constructed
according to the needs of particular applications. Graphical models provide a general
technique for motivating, describing, and analysing such structures, and variational
methods provide a powerful framework for performing inference in those models for
which exact solution is intractable.
13.3. Linear Dynamical Systems
In order to motivate the concept of linear dynamical systems, let us consider the
following simple problem, which often arises in practical settings. Suppose we wish
to measure the value of an unknown quantity z using a noisy sensor that returns a
observation x representing the value of z plus zero-mean Gaussian noise. Given a
single measurement, our best guess for z is to assume that z = x. However, we
can improve our estimate for z by taking lots of measurements and averaging them,
because the random noise terms will tend to cancel each other. Now let’s make the
situation more complicated by assuming that we wish to measure a quantity z that
is changing over time. We can take regular measurements of x so that at some point
in time we have obtained x1, . . . , xN and we wish to find the corresponding values
z1, . . . , xN . If we simply average the measurements, the error due to random noise
will be reduced, but unfortunately we will just obtain a single averaged estimate, in
which we have averaged over the changing value of z, thereby introducing a new
source of error.
Intuitively, we could imagine doing a bit better as follows. To estimate the value
of zN , we take only the most recent few measurements, say xN−L, . . . , xN and just
average these. If z is changing slowly, and the random noise level in the sensor is
high, it would make sense to choose a relatively long window of observations to
average. Conversely, if the signal is changing quickly, and the noise levels are small,
we might be better just to use xN directly as our estimate of zN . Perhaps we could
do even better if we take a weighted average, in which more recent measurements
636
13. SEQUENTIAL DATA
make a greater contribution than less recent ones.
Although this sort of intuitive argument seems plausible, it does not tell us how
to form a weighted average, and any sort of hand-crafted weighing is hardly likely
to be optimal. Fortunately, we can address problems such as this much more sys-
tematically by defining a probabilistic model that captures the time evolution and
measurement processes and then applying the inference and learning methods devel-
oped in earlier chapters. Here we shall focus on a widely used model known as a
linear dynamical system.
As we have seen, the HMM corresponds to the state space model shown in
Figure 13.5 in which the latent variables are discrete but with arbitrary emission
probability distributions. This graph of course describes a much broader class of
probability distributions, all of which factorize according to (13.6). We now consider
extensions to other distributions for the latent variables. In particular, we consider
continuous latent variables in which the summations of the sum-product algorithm
become integrals. The general form of the inference algorithms will, however, be
the same as for the hidden Markov model. It is interesting to note that, historically,
hidden Markov models and linear dynamical systems were developed independently.
Once they are both expressed as graphical models, however, the deep relationship
between them immediately becomes apparent.
One key requirement is that we retain an efficient algorithm for inference which
is linear in the length of the chain. This requires that, for instance, when we take
α(zn−1), representing the posterior probability of zn given observations
a quantity
x1, . . . , xn, and multiply by the transition probability p(zn|zn−1) and the emission
probability p(xn|zn) and then marginalize over zn−1, we obtain a distribution over
α(zn−1). That is to say, the
zn that is of the same functional form as that over
distribution must not become more complex at each stage, but must only change in
its parameter values. Not surprisingly, the only distributions that have this property
of being closed under multiplication are those belonging to the exponential family.
Here we consider the most important example from a practical perspective,
which is the Gaussian. In particular, we consider a linear-Gaussian state space model
so that the latent variables {zn}, as well as the observed variables {xn}, are multi-
variate Gaussian distributions whose means are linear functions of the states of their
parents in the graph. We have seen that a directed graph of linear-Gaussian units
is equivalent to a joint Gaussian distribution over all of the variables. Furthermore,
α(zn) are also Gaussian, so that the functional form of the mes-
marginals such as
sages is preserved and we will obtain an efficient inference algorithm. By contrast,
suppose that the emission densities p(xn|zn) comprise a mixture of K Gaussians
α(z1) is Gaussian, the
each of which has a mean that is linear in zn. Then even if
α(z3) will be a mixture of K 2
quantity
Gaussians, and so on, and exact inference will not be of practical value.
α(z2) will be a mixture of K Gaussians,
We have seen that the hidden Markov model can be viewed as an extension of
the mixture models of Chapter 9 to allow for sequential correlations in the data.
In a similar way, we can view the linear dynamical system as a generalization of the
continuous latent variable models of Chapter 12 such as probabilistic PCA and factor
analysis. Each pair of nodes {zn, xn} represents a linear-Gaussian latent variable
13.3. Linear Dynamical Systems
637
model for that particular observation. However, the latent variables {zn} are no
longer treated as independent but now form a Markov chain.
Because the model is represented by a tree-structured directed graph, inference
problems can be solved efficiently using the sum-product algorithm. The forward re-
cursions, analogous to the α messages of the hidden Markov model, are known as the
Kalman filter equations (Kalman, 1960; Zarchan and Musoff, 2005), and the back-
ward recursions, analogous to the β messages, are known as the Kalman smoother
equations, or the Rauch-Tung-Striebel (RTS) equations (Rauch et al., 1965). The
Kalman filter is widely used in many real-time tracking applications.
Because the linear dynamical system is a linear-Gaussian model, the joint distri-
bution over all variables, as well as all marginals and conditionals, will be Gaussian.
It follows that the sequence of individually most probable latent variable values is
the same as the most probable latent sequence. There is thus no need to consider the
analogue of the Viterbi algorithm for the linear dynamical system.
Because the model has linear-Gaussian conditional distributions, we can write
the transition and emission distributions in the general form
p(zn|zn−1) = N (zn|Azn−1, Γ)
p(xn|zn) = N (xn|Czn, Σ).
The initial latent variable also has a Gaussian distribution which we write as
p(z1) = N (z1|µ0, V0).
(13.75)
(13.76)
(13.77)
Exercise 13.19
Exercise 13.24
Note that in order to simplify the notation, we have omitted additive constant terms
from the means of the Gaussians. In fact, it is straightforward to include them if
desired. Traditionally, these distributions are more commonly expressed in an equiv-
alent form in terms of noisy linear equations given by
zn = Azn−1 + wn
xn = Czn + vn
z1 = µ0 + u
(13.78)
(13.79)
(13.80)
where the noise terms have the distributions
w ∼ N (w|0, Γ)
v ∼ N (v|0, Σ)
u ∼ N (u|0, V0).
(13.81)
(13.82)
(13.83)
The parameters of the model, denoted by θ = {A, Γ, C, Σ, µ0, V0}, can be
determined using maximum likelihood through the EM algorithm. In the E step, we
need to solve the inference problem of determining the local posterior marginals for
the latent variables, which can be solved efficiently using the sum-product algorithm,
as we discuss in the next section.
638
13. SEQUENTIAL DATA
