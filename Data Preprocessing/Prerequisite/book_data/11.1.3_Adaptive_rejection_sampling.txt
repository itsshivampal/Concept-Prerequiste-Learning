In many instances where we might wish to apply rejection sampling, it proves
difficult to determine a suitable analytic form for the envelope distribution q(z). An
alternative approach is to construct the envelope function on the fly based on mea-
sured values of the distribution p(z) (Gilks and Wild, 1992). Construction of an
envelope function is particularly straightforward for cases in which p(z) is log con-
cave, in other words when ln p(z) has derivatives that are nonincreasing functions
of z. The construction of a suitable envelope function is illustrated graphically in
Figure 11.6.
The function ln p(z) and its gradient are evaluated at some initial set of grid
points, and the intersections of the resulting tangent lines are used to construct the
envelope function. Next a sample value is drawn from the envelope distribution.
This is straightforward because the log of the envelope distribution is a succession
Exercise 11.9
Figure 11.6 In the case of distributions that are
log concave, an envelope function
for use in rejection sampling can be
constructed using the tangent lines
computed at a set of grid points. If a
sample point is rejected, it is added
to the set of grid points and used to
refine the envelope distribution.
ln p(z)
z1
z2
z3
z
530
11. SAMPLING METHODS
Figure 11.5 Plot showing the gamma distribu-
tion given by (11.15) as the green
curve, with a scaled Cauchy pro-
posal distribution shown by the red
curve. Samples from the gamma
distribution can be obtained by
sampling from the Cauchy and
then applying the rejection sam-
pling criterion.
p(z)
0.15
0.1
0.05
0
0
11.1. Basic Sampling Algorithms
531
Figure 11.7 Illustrative example of
rejection
sampling involving sampling from a
Gaussian distribution p(z) shown by
the green curve, by using rejection
sampling from a proposal distri-
bution q(z) that
is also Gaussian
and whose scaled version kq(z) is
shown by the red curve.
0.5
p(z)
0.25
0
−5
0
z
5
of linear functions, and hence the envelope distribution itself comprises a piecewise
exponential distribution of the form
q(z) = kiλi exp{−λi(z − zi−1)}
zi−1 < z � zi.
(11.17)
Once a sample has been drawn, the usual rejection criterion can be applied. If the
sample is accepted, then it will be a draw from the desired distribution. If, however,
the sample is rejected, then it is incorporated into the set of grid points, a new tangent
line is computed, and the envelope function is thereby refined. As the number of
grid points increases, so the envelope function becomes a better approximation of
the desired distribution p(z) and the probability of rejection decreases.
A variant of the algorithm exists that avoids the evaluation of derivatives (Gilks,
1992). The adaptive rejection sampling framework can also be extended to distri-
butions that are not log concave, simply by following each rejection sampling step
with a Metropolis-Hastings step (to be discussed in Section 11.2.2), giving rise to
adaptive rejection Metropolis sampling (Gilks et al., 1995).
Clearly for rejection sampling to be of practical value, we require that the com-
parison function be close to the required distribution so that the rate of rejection is
kept to a minimum. Now let us examine what happens when we try to use rejection
sampling in spaces of high dimensionality. Consider, for the sake of illustration,
a somewhat artificial problem in which we wish to sample from a zero-mean mul-
pI, where I is the unit matrix, by
tivariate Gaussian distribution with covariance σ2
rejection sampling from a proposal distribution that is itself a zero-mean Gaussian
p in order that
distribution having covariance σ2
there exists a k such that kq(z) � p(z). In D-dimensions the optimum value of k
is given by k = (σq/σp)D, as illustrated for D = 1 in Figure 11.7. The acceptance
rate will be the ratio of volumes under p(z) and kq(z), which, because both distribu-
tions are normalized, is just 1/k. Thus the acceptance rate diminishes exponentially
with dimensionality. Even if σq exceeds σp by just one percent, for D = 1, 000 the
acceptance ratio will be approximately 1/20, 000. In this illustrative example the
comparison function is close to the required distribution. For more practical exam-
ples, where the desired distribution may be multimodal and sharply peaked, it will
be extremely difficult to find a good proposal distribution and comparison function.
qI. Obviously, we must have σ2
q � σ2
532
11. SAMPLING METHODS
Figure 11.8 Importance sampling addresses the prob-
lem of evaluating the expectation of a func-
tion f (z) with respect to a distribution p(z)
from which it is difficult to draw samples di-
Instead, samples {z(l)} are drawn
rectly.
from a simpler distribution q(z), and the
corresponding terms in the summation are
weighted by the ratios p(z(l))/q(z(l)).
p(z)
q(z)
f(z)
z
L
Furthermore, the exponential decrease of acceptance rate with dimensionality is a
generic feature of rejection sampling. Although rejection can be a useful technique
in one or two dimensions it is unsuited to problems of high dimensionality. It can,
however, play a role as a subroutine in more sophisticated algorithms for sampling
in high dimensional spaces.
