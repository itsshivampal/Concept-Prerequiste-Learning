For dynamical systems which do not have a linear-Gaussian, for example, if
they use a non-Gaussian emission density, we can turn to sampling methods in order
to find a tractable inference algorithm. In particular, we can apply the sampling-
importance-resampling formalism of Section 11.1.5 to obtain a sequential Monte
Carlo algorithm known as the particle filter.
Consider the class of distributions represented by the graphical model in Fig-
ure 13.5, and suppose we are given the observed values Xn = (x1, . . . , xn) and
we wish to draw L samples from the posterior distribution p(zn|Xn). Using Bayes’
theorem, we have
f(zn)p(zn|Xn) dzn
f(zn)p(zn|xn, Xn−1) dzn
f(zn)p(xn|zn)p(zn|Xn−1) dzn
p(xn|zn)p(zn|Xn−1) dzn
E[f(zn)] =
w(l)
n f(z(l)
n )
(13.117)
where {z(l)
n } is a set of samples drawn from p(zn|Xn−1) and we have made use of
the conditional independence property p(xn|zn, Xn−1) = p(xn|zn), which follows
from the graph in Figure 13.5. The sampling weights {w(l)
n } are defined by
w(l)
n =
p(xn|z(l)
n )
m=1 p(xn|z(m)
n )
L
(13.118)
l w(l)
where the same samples are used in the numerator as in the denominator. Thus the
posterior distribution p(zn|xn) is represented by the set of samples {z(l)
n } together
n }. Note that these weights satisfy 0 � w(l)
with the corresponding weights {w(l)
n 1
and
Because we wish to find a sequential sampling scheme, we shall suppose that
a set of samples and weights have been obtained at time step n, and that we have
subsequently observed the value of xn+1, and we wish to find the weights and sam-
ples at time step n + 1. We first sample from the distribution p(zn+1|Xn). This is
n = 1.
p(zn+1|Xn) =
p(zn+1|zn, Xn)p(zn|Xn) dzn
p(zn+1|zn)p(zn|Xn) dzn
p(zn+1|zn)p(zn|xn, Xn−1) dzn
p(zn+1|zn)p(xn|zn)p(zn|Xn−1) dzn
p(xn|zn)p(zn|Xn−1) dzn
n p(zn+1|z(l)
n )
w(l)
l
(13.119)
(13.120)
(13.121)
646
13. SEQUENTIAL DATA
straightforward since, again using Bayes’ theorem
where we have made use of the conditional independence properties
p(zn+1|zn, Xn) = p(zn+1|zn)
p(xn|zn, Xn−1) = p(xn|zn)
which follow from the application of the d-separation criterion to the graph in Fig-
ure 13.5. The distribution given by (13.119) is a mixture distribution, and samples
can be drawn by choosing a component l with probability given by the mixing coef-
ficients w(l) and then drawing a sample from the corresponding component.
In summary, we can view each step of the particle filter algorithm as comprising
two stages. At time step n, we have a sample representation of the posterior dis-
n } with corresponding weights {w(l)
tribution p(zn|Xn) expressed as samples {z(l)
n }.
This can be viewed as a mixture representation of the form (13.119). To obtain the
corresponding representation for the next time step, we first draw L samples from
the mixture distribution (13.119), and then for each sample we use the new obser-
vation xn+1 to evaluate the corresponding weights w(l)
n+1). This is
illustrated, for the case of a single variable z, in Figure 13.23.
n+1 ∝ p(xn+1|z(l)
The particle filtering, or sequential Monte Carlo, approach has appeared in the
literature under various names including the bootstrap filter (Gordon et al., 1993),
survival of the fittest (Kanazawa et al., 1995), and the condensation algorithm (Isard
and Blake, 1998).
Exercises
13.1 () www Use the technique of d-separation, discussed in Section 8.2, to verify
that the Markov model shown in Figure 13.3 having N nodes in total satisfies the
conditional independence properties (13.3) for n = 2, . . . , N. Similarly, show that
a model described by the graph in Figure 13.4 in which there are N nodes in total
p(zn|Xn)
p(zn+1|Xn)
p(xn+1|zn+1)
p(zn+1|Xn+1)
Exercises
647
z
Figure 13.23 Schematic illustration of the operation of the particle filter for a one-dimensional latent
space. At time step n, the posterior p(zn|xn) is represented as a mixture distribution,
shown schematically as circles whose sizes are proportional to the weights w(l)
n . A set of
L samples is then drawn from this distribution and the new weights w(l)
n+1 evaluated using
p(xn+1|z(l)
n+1).
satisfies the conditional independence properties
p(xn|x1, . . . , xn−1) = p(xn|xn−1, xn−2)
(13.122)
for n = 3, . . . , N.
13.2 ( ) Consider the joint probability distribution (13.2) corresponding to the directed
graph of Figure 13.3. Using the sum and product rules of probability, verify that
this joint distribution satisfies the conditional independence property (13.3) for n =
2, . . . , N. Similarly, show that the second-order Markov model described by the
joint distribution (13.4) satisfies the conditional independence property
p(xn|x1, . . . , xn−1) = p(xn|xn−1, xn−2)
(13.123)
for n = 3, . . . , N.
13.3 () By using d-separation, show that the distribution p(x1, . . . , xN ) of the observed
data for the state space model represented by the directed graph in Figure 13.5 does
not satisfy any conditional independence properties and hence does not exhibit the
Markov property at any finite order.
13.4 ( ) www Consider a hidden Markov model in which the emission densities are
represented by a parametric model p(x|z, w), such as a linear regression model or
a neural network, in which w is a vector of adaptive parameters. Describe how the
parameters w can be learned from data using maximum likelihood.
648
13. SEQUENTIAL DATA
13.5 ( ) Verify the M-step equations (13.18) and (13.19) for the initial state probabili-
ties and transition probability parameters of the hidden Markov model by maximiza-
tion of the expected complete-data log likelihood function (13.17), using appropriate
Lagrange multipliers to enforce the summation constraints on the components of π
and A.
13.6 ()
Show that if any elements of the parameters π or A for a hidden Markov
model are initially set to zero, then those elements will remain zero in all subsequent
updates of the EM algorithm.
13.7 () Consider a hidden Markov model with Gaussian emission densities. Show that
maximization of the function Q(θ, θold) with respect to the mean and covariance
parameters of the Gaussians gives rise to the M-step equations (13.20) and (13.21).
13.8 ( ) www For a hidden Markov model having discrete observations governed by
a multinomial distribution, show that the conditional distribution of the observations
given the hidden variables is given by (13.22) and the corresponding M step equa-
tions are given by (13.23). Write down the analogous equations for the conditional
distribution and the M step equations for the case of a hidden Markov with multiple
binary output variables each of which is governed by a Bernoulli conditional dis-
tribution. Hint: refer to Sections 2.1 and 2.2 for a discussion of the corresponding
maximum likelihood solutions for i.i.d. data if required.
13.9 ( ) www Use the d-separation criterion to verify that the conditional indepen-
dence properties (13.24)–(13.31) are satisfied by the joint distribution for the hidden
Markov model defined by (13.6).
13.10 (  ) By applying the sum and product rules of probability, verify that the condi-
tional independence properties (13.24)–(13.31) are satisfied by the joint distribution
for the hidden Markov model defined by (13.6).
13.11 ( ) Starting from the expression (8.72) for the marginal distribution over the vari-
ables of a factor in a factor graph, together with the results for the messages in the
sum-product algorithm obtained in Section 13.2.3, derive the result (13.43) for the
joint posterior distribution over two successive latent variables in a hidden Markov
model.
13.12 ( ) Suppose we wish to train a hidden Markov model by maximum likelihood
using data that comprises R independent sequences of observations, which we de-
note by X(r) where r = 1, . . . , R. Show that in the E step of the EM algorithm,
we simply evaluate posterior probabilities for the latent variables by running the α
and β recursions independently for each of the sequences. Also show that in the
M step, the initial probability and transition probability parameters are re-estimated
n=1
n=2
n=2
r=1
r=1
r=1
j=1
r=1
l=1
K
N
R
K
R
N
r=1
R
N
R
using modified forms of (13.18 ) and (13.19) given by
Exercises
649
(13.124)
(13.125)
R
γ(z(r)
1k )
γ(z(r)
1j )
πk =
Ajk =
ξ(z(r)
n−1,j, z(r)
n,k)
ξ(z(r)
n−1,j, z(r)
n,l)
γ(z(r)
nk )x(r)
n
where, for notational convenience, we have assumed that the sequences are of the
same length (the generalization to sequences of different lengths is straightforward).
Similarly, show that the M-step equation for re-estimation of the means of Gaussian
emission models is given by
µk =
R
N
(13.126)
γ(z(r)
nk )
r=1
n=1
Note that the M-step equations for other emission model parameters and distributions
take an analogous form.
13.13 ( ) www Use the definition (8.64) of the messages passed from a factor node
to a variable node in a factor graph, together with the expression (13.6) for the joint
distribution in a hidden Markov model, to show that the definition (13.50) of the
alpha message is the same as the definition (13.34).
13.14 ( ) Use the definition (8.67) of the messages passed from a factor node to a
variable node in a factor graph, together with the expression (13.6) for the joint
distribution in a hidden Markov model, to show that the definition (13.52) of the
beta message is the same as the definition (13.35).
13.15 ( ) Use the expressions (13.33) and (13.43) for the marginals in a hidden Markov
model to derive the corresponding results (13.64) and (13.65) expressed in terms of
re-scaled variables.
13.16 (  )
In this exercise, we derive the forward message passing equation for the
Viterbi algorithm directly from the expression (13.6) for the joint distribution. This
involves maximizing over all of the hidden variables z1, . . . , zN . By taking the log-
arithm and then exchanging maximizations and summations, derive the recursion
650
13. SEQUENTIAL DATA
(13.68) where the quantities ω(zn) are defined by (13.70). Show that the initial
condition for this recursion is given by (13.69).
13.17 () www Show that the directed graph for the input-output hidden Markov model,
given in Figure 13.18, can be expressed as a tree-structured factor graph of the form
shown in Figure 13.15 and write down expressions for the initial factor h(z1) and
for the general factor fn(zn−1, zn) where 2 � n � N.
13.18 (  ) Using the result of Exercise 13.17, derive the recursion equations, includ-
ing the initial conditions, for the forward-backward algorithm for the input-output
hidden Markov model shown in Figure 13.18.
13.19 () www The Kalman filter and smoother equations allow the posterior distribu-
tions over individual latent variables, conditioned on all of the observed variables,
to be found efficiently for linear dynamical systems. Show that the sequence of
latent variable values obtained by maximizing each of these posterior distributions
individually is the same as the most probable sequence of latent values. To do this,
simply note that the joint distribution of all latent and observed variables in a linear
dynamical system is Gaussian, and hence all conditionals and marginals will also be
Gaussian, and then make use of the result (2.98).
13.20 ( ) www Use the result (2.115) to prove (13.87).
13.21 ( ) Use the results (2.115) and (2.116), together with the matrix identities (C.5)
and (C.7), to derive the results (13.89), (13.90), and (13.91), where the Kalman gain
matrix Kn is defined by (13.92).
13.22 ( ) www Using (13.93), together with the definitions (13.76) and (13.77) and
the result (2.115), derive (13.96).
13.23 ( ) Using (13.93), together with the definitions (13.76) and (13.77) and the result
(2.116), derive (13.94), (13.95) and (13.97).
13.24 ( ) www Consider a generalization of (13.75) and (13.76) in which we include
constant terms a and c in the Gaussian means, so that
p(zn|zn−1) = N (zn|Azn−1 + a, Γ)
p(xn|zn) = N (xn|Czn + c, Σ).
(13.127)
(13.128)
Show that this extension can be re-case in the framework discussed in this chapter by
defining a state vector z with an additional component fixed at unity, and then aug-
menting the matrices A and C using extra columns corresponding to the parameters
a and c.
13.25 ( )
In this exercise, we show that when the Kalman filter equations are applied
to independent observations, they reduce to the results given in Section 2.3 for the
maximum likelihood solution for a single Gaussian distribution. Consider the prob-
lem of finding the mean µ of a single Gaussian random variable x, in which we are
given a set of independent observations {x1, . . . , xN}. To model this we can use
Exercises
651
a linear dynamical system governed by (13.75) and (13.76), with latent variables
{z1, . . . , zN} in which C becomes the identity matrix and where the transition prob-
ability A = 0 because the observations are independent. Let the parameters m0
and V0 of the initial state be denoted by µ0 and σ2
0, respectively, and suppose that
Σ becomes σ2. Write down the corresponding Kalman filter equations starting from
the general results (13.89) and (13.90), together with (13.94) and (13.95). Show that
these are equivalent to the results (2.141) and (2.142) obtained directly by consider-
ing independent data.
13.26 (  ) Consider a special case of the linear dynamical system of Section 13.3 that is
equivalent to probabilistic PCA, so that the transition matrix A = 0, the covariance
Γ = I, and the noise covariance Σ = σ2I. By making use of the matrix inversion
identity (C.7) show that, if the emission density matrix C is denoted W, then the
posterior distribution over the hidden states defined by (13.89) and (13.90) reduces
to the result (12.42) for probabilistic PCA.
13.27 () www Consider a linear dynamical system of the form discussed in Sec-
tion 13.3 in which the amplitude of the observation noise goes to zero, so that Σ = 0.
Show that the posterior distribution for zn has mean xn and zero variance. This
accords with our intuition that if there is no noise, we should just use the current
observation xn to estimate the state variable zn and ignore all previous observations.
13.28 (  ) Consider a special case of the linear dynamical system of Section 13.3 in
which the state variable zn is constrained to be equal to the previous state variable,
which corresponds to A = I and Γ = 0. For simplicity, assume also that V0 → ∞
so that the initial conditions for z are unimportant, and the predictions are determined
purely by the data. Use proof by induction to show that the posterior mean for state
zn is determined by the average of x1, . . . , xn. This corresponds to the intuitive
result that if the state variable is constant, our best estimate is obtained by averaging
the observations.
13.29 (  )
Starting from the backwards recursion equation (13.99), derive the RTS
smoothing equations (13.100) and (13.101) for the Gaussian linear dynamical sys-
tem.
13.30 ( ) Starting from the result (13.65) for the pairwise posterior marginal in a state
space model, derive the specific form (13.103) for the case of the Gaussian linear
dynamical system.
13.31 ( ) Starting from the result (13.103) and by substituting for
α(zn) using (13.84),
verify the result (13.104) for the covariance between zn and zn−1.
13.32 ( ) www Verify the results (13.110) and (13.111) for the M-step equations for
µ0 and V0 in the linear dynamical system.
13.33 ( ) Verify the results (13.113) and (13.114) for the M-step equations for A and Γ
in the linear dynamical system.
652
13. SEQUENTIAL DATA
13.34 ( ) Verify the results (13.115) and (13.116) for the M-step equations for C and Σ
in the linear dynamical system.
