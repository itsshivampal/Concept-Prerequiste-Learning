1 Introduction
The problem of searching for patterns in data is a fundamental one and has a long and
successful history. For instance, the extensive astronomical observations of Tycho
Brahe in the 16th century allowed Johannes Kepler to discover the empirical laws of
planetary motion, which in turn provided a springboard for the development of clas-
sical mechanics. Similarly, the discovery of regularities in atomic spectra played a
key role in the development and verification of quantum physics in the early twenti-
eth century. The field of pattern recognition is concerned with the automatic discov-
ery of regularities in data through the use of computer algorithms and with the use of
these regularities to take actions such as classifying the data into different categories.
Consider the example of recognizing handwritten digits, illustrated in Figure 1.1.
Each digit corresponds to a 28×28 pixel image and so can be represented by a vector
x comprising 784 real numbers. The goal is to build a machine that will take such a
vector x as input and that will produce the identity of the digit 0, . . . , 9 as the output.
This is a nontrivial problem due to the wide variability of handwriting. It could be
1
2
1. INTRODUCTION
Figure 1.1 Examples of hand-written dig-
its taken from US zip codes.
tackled using handcrafted rules or heuristics for distinguishing the digits based on
the shapes of the strokes, but in practice such an approach leads to a proliferation of
rules and of exceptions to the rules and so on, and invariably gives poor results.
Far better results can be obtained by adopting a machine learning approach in
which a large set of N digits {x1, . . . , xN} called a training set is used to tune the
parameters of an adaptive model. The categories of the digits in the training set
are known in advance, typically by inspecting them individually and hand-labelling
them. We can express the category of a digit using target vector t, which represents
the identity of the corresponding digit. Suitable techniques for representing cate-
gories in terms of vectors will be discussed later. Note that there is one such target
vector t for each digit image x.
The result of running the machine learning algorithm can be expressed as a
function y(x) which takes a new digit image x as input and that generates an output
vector y, encoded in the same way as the target vectors. The precise form of the
function y(x) is determined during the training phase, also known as the learning
phase, on the basis of the training data. Once the model is trained it can then de-
termine the identity of new digit images, which are said to comprise a test set. The
ability to categorize correctly new examples that differ from those used for train-
ing is known as generalization. In practical applications, the variability of the input
vectors will be such that the training data can comprise only a tiny fraction of all
possible input vectors, and so generalization is a central goal in pattern recognition.
For most practical applications, the original input variables are typically prepro-
cessed to transform them into some new space of variables where, it is hoped, the
pattern recognition problem will be easier to solve. For instance, in the digit recogni-
tion problem, the images of the digits are typically translated and scaled so that each
digit is contained within a box of a fixed size. This greatly reduces the variability
within each digit class, because the location and scale of all the digits are now the
same, which makes it much easier for a subsequent pattern recognition algorithm
to distinguish between the different classes. This pre-processing stage is sometimes
also called feature extraction. Note that new test data must be pre-processed using
the same steps as the training data.
Pre-processing might also be performed in order to speed up computation. For
example, if the goal is real-time face detection in a high-resolution video stream,
the computer must handle huge numbers of pixels per second, and presenting these
directly to a complex pattern recognition algorithm may be computationally infeasi-
ble. Instead, the aim is to find useful features that are fast to compute, and yet that
1. INTRODUCTION
3
also preserve useful discriminatory information enabling faces to be distinguished
from non-faces. These features are then used as the inputs to the pattern recognition
algorithm. For instance, the average value of the image intensity over a rectangular
subregion can be evaluated extremely efficiently (Viola and Jones, 2004), and a set of
such features can prove very effective in fast face detection. Because the number of
such features is smaller than the number of pixels, this kind of pre-processing repre-
sents a form of dimensionality reduction. Care must be taken during pre-processing
because often information is discarded, and if this information is important to the
solution of the problem then the overall accuracy of the system can suffer.
Applications in which the training data comprises examples of the input vectors
along with their corresponding target vectors are known as supervised learning prob-
lems. Cases such as the digit recognition example, in which the aim is to assign each
input vector to one of a finite number of discrete categories, are called classification
problems. If the desired output consists of one or more continuous variables, then
the task is called regression. An example of a regression problem would be the pre-
diction of the yield in a chemical manufacturing process in which the inputs consist
of the concentrations of reactants, the temperature, and the pressure.
In other pattern recognition problems, the training data consists of a set of input
vectors x without any corresponding target values. The goal in such unsupervised
learning problems may be to discover groups of similar examples within the data,
where it is called clustering, or to determine the distribution of data within the input
space, known as density estimation, or to project the data from a high-dimensional
space down to two or three dimensions for the purpose of visualization.
Finally, the technique of reinforcement learning (Sutton and Barto, 1998) is con-
cerned with the problem of finding suitable actions to take in a given situation in
order to maximize a reward. Here the learning algorithm is not given examples of
optimal outputs, in contrast to supervised learning, but must instead discover them
by a process of trial and error. Typically there is a sequence of states and actions in
which the learning algorithm is interacting with its environment. In many cases, the
current action not only affects the immediate reward but also has an impact on the re-
ward at all subsequent time steps. For example, by using appropriate reinforcement
learning techniques a neural network can learn to play the game of backgammon to a
high standard (Tesauro, 1994). Here the network must learn to take a board position
as input, along with the result of a dice throw, and produce a strong move as the
output. This is done by having the network play against a copy of itself for perhaps a
million games. A major challenge is that a game of backgammon can involve dozens
of moves, and yet it is only at the end of the game that the reward, in the form of
victory, is achieved. The reward must then be attributed appropriately to all of the
moves that led to it, even though some moves will have been good ones and others
less so. This is an example of a credit assignment problem. A general feature of re-
inforcement learning is the trade-off between exploration, in which the system tries
out new kinds of actions to see how effective they are, and exploitation, in which
the system makes use of actions that are known to yield a high reward. Too strong
a focus on either exploration or exploitation will yield poor results. Reinforcement
learning continues to be an active area of machine learning research. However, a
4
1. INTRODUCTION
Figure 1.2 Plot of a training data set of N =
10 points, shown as blue circles,
each comprising an observation
of the input variable x along with
the corresponding target variable
t. The green curve shows the
function sin(2πx) used to gener-
ate the data. Our goal is to pre-
dict the value of t for some new
value of x, without knowledge of
the green curve.
t
1
0
−1
0
1
x
detailed treatment lies beyond the scope of this book.
Although each of these tasks needs its own tools and techniques, many of the
key ideas that underpin them are common to all such problems. One of the main
goals of this chapter is to introduce, in a relatively informal way, several of the most
important of these concepts and to illustrate them using simple examples. Later in
the book we shall see these same ideas re-emerge in the context of more sophisti-
cated models that are applicable to real-world pattern recognition applications. This
chapter also provides a self-contained introduction to three important tools that will
be used throughout the book, namely probability theory, decision theory, and infor-
mation theory. Although these might sound like daunting topics, they are in fact
straightforward, and a clear understanding of them is essential if machine learning
techniques are to be used to best effect in practical applications.
