Given a training data set comprising N observations {xn}, where n = 1, . . . , N,
together with corresponding target values {tn}, the goal is to predict the value of t
for a new value of x. In the simplest approach, this can be done by directly con-
structing an appropriate function y(x) whose values for new inputs x constitute the
predictions for the corresponding values of t. More generally, from a probabilistic
perspective, we aim to model the predictive distribution p(t|x) because this expresses
our uncertainty about the value of t for each value of x. From this conditional dis-
tribution we can make predictions of t, for any new value of x, in such a way as to
minimize the expected value of a suitably chosen loss function. As discussed in Sec-
tion 1.5.5, a common choice of loss function for real-valued variables is the squared
loss, for which the optimal solution is given by the conditional expectation of t.
Although linear models have significant limitations as practical techniques for
pattern recognition, particularly for problems involving input spaces of high dimen-
sionality, they have nice analytical properties and form the foundation for more so-
phisticated models to be discussed in later chapters.
Mâˆ’1
j=1
