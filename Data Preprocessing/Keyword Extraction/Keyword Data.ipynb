{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "import collections\n",
    "\n",
    "import wikipedia\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting keywords with their abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"bprml_updated.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_class = df[[\"Parent Class\"]]\n",
    "sub_class = df[[\"Sub Class\"]]\n",
    "reference = df[[\"Reference\"]]\n",
    "index_length = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    }
   ],
   "source": [
    "print(index_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_topics = []\n",
    "topics_abbr = []\n",
    "\n",
    "different_terms = []\n",
    "\n",
    "for i in range(index_length):\n",
    "    x1 = parent_class.iloc[i].values[0]\n",
    "    x2 = sub_class.iloc[i].values[0]\n",
    "    x3 = reference.iloc[i].values[0]\n",
    "    if x1 == x2:\n",
    "        relevant_topics.append(x1)\n",
    "        if x1 != x3:\n",
    "            topics_abbr.append(x3)\n",
    "        else: topics_abbr.append(\"\")\n",
    "    else:\n",
    "        terms = [x1, x2]\n",
    "        different_terms.append(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "647\n"
     ]
    }
   ],
   "source": [
    "print(len(topics_abbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyphrase Extraction from Book Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17242\n",
      "16025\n"
     ]
    }
   ],
   "source": [
    "def extract_candidate_keywords(chunkGram, text):\n",
    "    chunkParser = nltk.RegexpParser(chunkGram)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "\n",
    "    chunked = chunkParser.parse(tagged)\n",
    "    candidate_keywords = []\n",
    "\n",
    "    for tree in chunked.subtrees():\n",
    "        if tree.label() == 'PHRASE':\n",
    "            candidate_keyword = ' '.join([x for x,y in tree.leaves()])\n",
    "            candidate_keywords.append(candidate_keyword)\n",
    "    \n",
    "    return candidate_keywords\n",
    "\n",
    "def clean_phrase(phrase):\n",
    "    new_string = \"\"\n",
    "    for word in phrase.split(\" \"):\n",
    "        word = porter.stem(word)\n",
    "        new_string += word + \" \"\n",
    "    return new_string[:-1]\n",
    "\n",
    "\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "chapter_file = \"chapter_text/bprml.txt\"\n",
    "\n",
    "raw = open(chapter_file).read()\n",
    "\n",
    "max_length = 6\n",
    "\n",
    "chunkGram1 = r\"\"\"\n",
    "    NBAR:\n",
    "        {<NN.*|JJ>*<NN.*>}\n",
    "        \n",
    "    PHRASE:\n",
    "        {<NBAR>}\n",
    "        {<NBAR><IN><NBAR>}\n",
    "\"\"\"\n",
    "\n",
    "chunkGram2 = r\"\"\" PHRASE: \n",
    "                {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "candidate_keywords = extract_candidate_keywords(chunkGram1, raw)\n",
    "\n",
    "candidate_keywords = [word.lower() for word in candidate_keywords]\n",
    "\n",
    "candidate_keywords = set(candidate_keywords)\n",
    "candidate_keywords = [w for w in candidate_keywords if len(w.split(' ')) < max_length]\n",
    "\n",
    "print(len(candidate_keywords))\n",
    "\n",
    "filtered_keywords = [clean_phrase(w) for w in candidate_keywords]\n",
    "\n",
    "filtered_keywords = set(filtered_keywords)\n",
    "\n",
    "print(len(filtered_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Parent and Sub Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between-class covariance\n",
      "within-class covariance\n",
      "partitioned covariance matrix\n",
      "conditional entropy\n",
      "differential entropy\n",
      "relative entropy\n",
      "functional derivative\n",
      "conditional gaussian\n",
      "gaussian marginal\n",
      "gaussian mixture\n",
      "directed graphical model\n",
      "undirected graphical model\n",
      "autoregressive hidden markov model\n",
      "factorial hidden markov model\n",
      "input-output hidden markov model\n",
      "left-to-right hidden markov model\n",
      "extended kalman ﬁlter\n",
      "gaussian kernel function\n",
      "fisher linear discriminant\n",
      "linear regression problem\n",
      "variational linear regression\n",
      "bayesian logistic regression\n",
      "logistic regression mixture model\n",
      "multiclass logistic regression\n",
      "margin error\n",
      "soft margin\n",
      "homogeneous markov chain\n",
      "message passing schedule\n",
      "variational message passing\n",
      "conditional mixture model\n",
      "logistic regression mixture model\n",
      "convolutional neural network\n",
      "perceptron convergence theorem\n",
      "perceptron hardware\n",
      "conjugate prior\n",
      "consistent gaussian prior\n",
      "improper prior\n",
      "noninformative prior\n",
      "bayesian probability\n",
      "probability density\n",
      "probability mass function\n",
      "prior probability\n",
      "probability sum rule\n",
      "probability theory\n",
      "tikhonov regularization\n"
     ]
    }
   ],
   "source": [
    "def find_best_string(all_strings):\n",
    "    return max(set(all_strings), key = all_strings.count)\n",
    "\n",
    "\n",
    "def matching_pattern(keyword1, keyword2, phrase):\n",
    "#     phrase = clean_phrase(phrase)\n",
    "    stem1 = clean_phrase(keyword1)\n",
    "    stem2 = clean_phrase(keyword2)\n",
    "    if stem1 in phrase and stem2 in phrase:\n",
    "        len1 = phrase.index(stem1)\n",
    "        len2 = phrase.index(stem2)\n",
    "        \n",
    "        if len1 > len2:\n",
    "            start = len2 + len(stem2)\n",
    "            end = len1\n",
    "            string = keyword2 + phrase[start:end] + keyword1\n",
    "        else:\n",
    "            start = len1 + len(stem1)\n",
    "            end = len2\n",
    "            string = keyword1 + phrase[start:end] + keyword2\n",
    "        return 1, string\n",
    "    else: return 0, \"\"\n",
    "\n",
    "count = 0\n",
    "successful_phrases = []\n",
    "unsuccessful_phrases = []\n",
    "\n",
    "\n",
    "for pair in different_terms:\n",
    "    match_count = 0\n",
    "    possible_strings = []\n",
    "    for phrase in filtered_keywords:\n",
    "        result, string = matching_pattern(pair[0], pair[1], phrase)\n",
    "        if result != 0:\n",
    "            possible_strings.append(string)\n",
    "            match_count += 1\n",
    "    if match_count > 0:\n",
    "        main_keyword = find_best_string(possible_strings)\n",
    "        successful_phrases.append(main_keyword)\n",
    "        count += 1\n",
    "        print(main_keyword)\n",
    "    else:\n",
    "        unsuccessful_phrases.append(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "print(len(successful_phrases))\n",
    "print(len(unsuccessful_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_phrases = []\n",
    "for phrase_pair in unsuccessful_phrases:\n",
    "    phrase = phrase_pair[1] + \" \" + phrase_pair[0]\n",
    "    combine_phrases.append(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in successful_phrases:\n",
    "    relevant_topics.append(x)\n",
    "    topics_abbr.append(\"\")\n",
    "\n",
    "for x in combine_phrases:\n",
    "    relevant_topics.append(x)\n",
    "    topics_abbr.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance criterion   \n",
      "activation function   \n",
      "active constraint   \n",
      "adaboost   \n",
      "adaline   \n",
      "adaptive rejection sampling   \n",
      "assumed density ﬁltering   \n",
      "akaike information criterion   aic\n",
      "akaike information criterion   \n",
      "ancestral sampling   \n",
      "annular ﬂow   \n",
      "autoregressive model   ar model\n",
      "arc   \n",
      "automatic relevance determination   ard\n",
      "autoregressive moving average   arma\n",
      "assumed density ﬁltering   \n",
      "autoassociative networks   \n",
      "automatic relevance determination   \n",
      "autoregressive hidden markov model   \n",
      "autoregressive model   \n",
      "autoregressive moving average   \n",
      "back-tracking   \n",
      "backgammon   \n",
      "backpropagation   \n",
      "bagging   \n",
      "basis function   \n",
      "batch training   \n",
      "baum-welch algorithm   \n",
      "bayes’ theorem   \n",
      "bayes   \n",
      "bayesian analysis   \n",
      "bayesian information criterion   \n",
      "bayesian model comparison   \n",
      "bayesian network   \n",
      "bayesian probability   \n",
      "belief propagation   \n",
      "bernoulli distribution   \n",
      "bernoulli   \n",
      "beta distribution   \n",
      "beta recursion   \n",
      "between-class covariance   \n",
      "bias   \n",
      "bias parameter   \n",
      "bias-variance trade-off   \n",
      "bayesian information criterion   bic\n",
      "binary entropy   \n",
      "binomial distribution   \n",
      "biological sequence   \n",
      "bipartite graph   \n",
      "bits   \n",
      "blind source separation   \n",
      "blocked path   \n",
      "boltzmann distribution   \n",
      "boltzmann   \n",
      "boolean logic   \n",
      "boosting   \n",
      "bootstrap   \n",
      "bootstrap ﬁlter   \n",
      "box constraints   \n",
      "box-muller method   \n",
      "calculus of variations   \n",
      "canonical correlation analysis   \n",
      "canonical link function   \n",
      "classiﬁcation and regression trees   cart\n",
      "cauchy distribution   \n",
      "causality   \n",
      "canonical correlation analysis   cca\n",
      "central differences   \n",
      "central limit theorem   \n",
      "chain graph   \n",
      "chaining   \n",
      "chapman-kolmogorov equations   \n",
      "child node   \n",
      "cholesky decomposition   \n",
      "chunking   \n",
      "circular normal   \n",
      "classical probability   \n",
      "classiﬁcation   \n",
      "classiﬁcation and regression trees   \n",
      "clique   \n",
      "clustering   \n",
      "clutter problem   \n",
      "co-parents   \n",
      "code-book vectors   \n",
      "combining models   \n",
      "committee   \n",
      "complete data set   \n",
      "completing the square   \n",
      "computational learning theory   \n",
      "concave function   \n",
      "concentration parameter   \n",
      "condensation algorithm   \n",
      "conditional entropy   \n",
      "conditional expectation   \n",
      "conditional independence   \n",
      "conditional mixture model   \n",
      "conditional probability   \n",
      "conjugate prior   \n",
      "convex duality   \n",
      "convex function   \n",
      "convolutional neural network   \n",
      "correlation matrix   \n",
      "cost function   \n",
      "covariance   \n",
      "covariance matrix   \n",
      "cox’s axioms   \n",
      "credit assignment   \n",
      "cross-entropy error function   \n",
      "cross-validation   \n",
      "cumulative distribution function   \n",
      "curse of dimensionality   \n",
      "curve ﬁtting   \n",
      "directed acyclic graph   dag\n",
      "dagsvm   \n",
      "data augmentation   \n",
      "data compression   \n",
      "decision boundary   \n",
      "decision region   \n",
      "decision surface   \n",
      "decision theory   \n",
      "decision tree   \n",
      "decomposition methods   \n",
      "degrees of freedom   \n",
      "degrees-of-freedom parameter   \n",
      "density estimation   \n",
      "density network   \n",
      "dependency map   \n",
      "descendant node   \n",
      "design matrix   \n",
      "differential entropy   \n",
      "digamma function   \n",
      "directed acyclic graph   \n",
      "directed cycle   \n",
      "directed factorization   \n",
      "dirichlet distribution   \n",
      "dirichlet   \n",
      "discriminant function   \n",
      "discriminative model   \n",
      "distortion measure   \n",
      "distributive law of multiplication   \n",
      "dna   \n",
      "document retrieval   \n",
      "dual representation   \n",
      "dual-energy gamma densitometry   \n",
      "dynamic programming   \n",
      "dynamical system   \n",
      "early stopping   \n",
      "expectation conditional maximization   ecm\n",
      "edge   \n",
      "effective number of observations   \n",
      "effective number of parameters   \n",
      "elliptical k-means   \n",
      "expectation maximization   em\n",
      "emission probability   \n",
      "empirical bayes   \n",
      "energy function   \n",
      "entropy   \n",
      "expectation propagation   ep\n",
      "equality constraint   \n",
      "equivalent kernel   \n",
      "erf function   \n",
      "error backpropagation   \n",
      "error function   \n",
      "error-correcting output codes   \n",
      "euler   \n",
      "euler-lagrange equations   \n",
      "evidence approximation   \n",
      "evidence function   \n",
      "expectation   \n",
      "expectation conditional maximization   \n",
      "expectation maximization   \n",
      "expectation propagation   \n",
      "expectation step   \n",
      "explaining away   \n",
      "exploitation   \n",
      "exploration   \n",
      "exponential distribution   \n",
      "exponential family   \n",
      "extensive variables   \n",
      "face detection   \n",
      "face tracking   \n",
      "factor analysis   \n",
      "factor graph   \n",
      "factor loading   \n",
      "factorial hidden markov model   \n",
      "factorized distribution   \n",
      "feature extraction   \n",
      "feature map   \n",
      "feature space   \n",
      "fisher information matrix   \n",
      "fisher kernel   \n",
      "fisher’s linear discriminant   \n",
      "forward kinematics   \n",
      "forward problem   \n",
      "forward propagation   \n",
      "forward-backward algorithm   \n",
      "fractional belief propagation   \n",
      "frequentist probability   \n",
      "fuel system   \n",
      "function interpolation   \n",
      "functional   \n",
      "gamma densitometry   \n",
      "gamma distribution   \n",
      "gamma function   \n",
      "gating function   \n",
      "gauss   \n",
      "gaussian   \n",
      "gaussian kernel   \n",
      "gaussian process   \n",
      "gaussian random ﬁeld   \n",
      "gaussian-gamma distribution   \n",
      "gaussian-wishart distribution   \n",
      "generalization   \n",
      "generalized linear model   \n",
      "generalized maximum likelihood   \n",
      "generative model   \n",
      "generative topographic mapping   \n",
      "geodesic distance   \n",
      "gibbs sampling   \n",
      "gibbs   \n",
      "gini index   \n",
      "global minimum   \n",
      "gradient descent   \n",
      "gram matrix   \n",
      "graph-cut algorithm   \n",
      "graphical model   \n",
      "green’s function   \n",
      "generative topographic mapping   gtm\n",
      "hamilton   \n",
      "hamiltonian dynamics   \n",
      "hamiltonian function   \n",
      "hammersley-clifford theorem   \n",
      "handwriting recognition   \n",
      "handwritten digit   \n",
      "head-to-head path   \n",
      "head-to-tail path   \n",
      "heaviside step function   \n",
      "hellinger distance   \n",
      "hessian matrix   \n",
      "heteroscedastic   \n",
      "hidden markov model   \n",
      "hidden unit   \n",
      "hidden variable   \n",
      "hierarchical bayesian model   \n",
      "hierarchical mixture of experts   \n",
      "hinge error function   \n",
      "hinton diagram   \n",
      "histogram density estimation   \n",
      "hierarchical mixture of experts   hme\n",
      "hold-out set   \n",
      "homogeneous ﬂow   \n",
      "homogeneous kernel   \n",
      "homogeneous markov chain   \n",
      "hooke’s law   \n",
      "hybrid monte carlo   \n",
      "hyperparameter   \n",
      "hyperprior   \n",
      "independent identically distributed   i.i.d.\n",
      "independent component analysis   ica\n",
      "iterated conditional modes   icm\n",
      "id3   \n",
      "identiﬁability   \n",
      "image de-noising   \n",
      "importance sampling   \n",
      "importance weights   \n",
      "improper prior   \n",
      "imputation step   \n",
      "imputation-posterior algorithm   \n",
      "inactive constraint   \n",
      "incomplete data set   \n",
      "independence map   \n",
      "independent component analysis   \n",
      "independent factor analysis   \n",
      "independent identically distributed   \n",
      "independent variables   \n",
      "independent   \n",
      "induced factorization   \n",
      "inequality constraint   \n",
      "inference   \n",
      "information criterion   \n",
      "information geometry   \n",
      "information theory   \n",
      "input-output hidden markov model   \n",
      "intensive variables   \n",
      "intrinsic dimensionality   \n",
      "invariance   \n",
      "inverse gamma distribution   \n",
      "inverse kinematics   \n",
      "inverse problem   \n",
      "inverse wishart distribution   \n",
      "Imputation posterior algorithm   ip algorithm\n",
      "iterative reweighted least squares   irls\n",
      "ising model   \n",
      "isomap   \n",
      "isometric feature map   \n",
      "iterated conditional modes   \n",
      "iterative reweighted least squares   \n",
      "jacobian matrix   \n",
      "jensen’s inequality   \n",
      "join tree   \n",
      "junction tree algorithm   \n",
      "k nearest neighbours   \n",
      "k-means clustering algorithm   \n",
      "k-medoids algorithm   \n",
      "kalman ﬁlter   \n",
      "kalman gain matrix   \n",
      "kalman smoother   \n",
      "karhunen-lo`eve transform   \n",
      "karush-kuhn-tucker conditions   \n",
      "kernel density estimator   \n",
      "kernel function   \n",
      "kernel pca   \n",
      "kernel regression   \n",
      "kernel substitution   \n",
      "kernel trick   \n",
      "kinetic energy   \n",
      "karush-kuhn-tucker conditions   kkt\n",
      "kullback-leibler divergence   kl divergence\n",
      "kriging   \n",
      "kullback-leibler divergence   \n",
      "lagrange multiplier   \n",
      "lagrange   \n",
      "lagrangian   \n",
      "laminar ﬂow   \n",
      "laplace approximation   \n",
      "laplace   \n",
      "large margin   \n",
      "lasso   \n",
      "latent class analysis   \n",
      "latent trait model   \n",
      "latent variable   \n",
      "lattice diagram   \n",
      "lds   \n",
      "leapfrog discretization   \n",
      "learning   \n",
      "learning rate parameter   \n",
      "least-mean-squares algorithm   \n",
      "leave-one-out   \n",
      "likelihood function   \n",
      "likelihood weighted sampling   \n",
      "linear discriminant   \n",
      "linear dynamical system   \n",
      "linear independence   \n",
      "linear regression   \n",
      "linear smoother   \n",
      "linear-gaussian model   \n",
      "linearly separable   \n",
      "link   \n",
      "link function   \n",
      "liouville’s theorem   \n",
      "locally linear embedding   lle\n",
      "lms algorithm   \n",
      "local minimum   \n",
      "local receptive ﬁeld   \n",
      "locally linear embedding   \n",
      "location parameter   \n",
      "log odds   \n",
      "logic sampling   \n",
      "logistic regression   \n",
      "logistic sigmoid   \n",
      "logit function   \n",
      "loopy belief propagation   \n",
      "loss function   \n",
      "loss matrix   \n",
      "lossless data compression   \n",
      "lossy data compression   \n",
      "lower bound   \n",
      "machine learning   \n",
      "macrostate   \n",
      "mahalanobis distance   \n",
      "manifold   \n",
      "map   \n",
      "margin   \n",
      "marginal likelihood   \n",
      "marginal probability   \n",
      "markov blanket   \n",
      "markov boundary   \n",
      "markov chain   \n",
      "markov chain monte carlo   \n",
      "markov model   \n",
      "markov network   \n",
      "markov random ﬁeld   \n",
      "max-sum algorithm   \n",
      "maximal clique   \n",
      "maximal spanning tree   \n",
      "maximization step   \n",
      "maximum likelihood   \n",
      "maximum margin   \n",
      "maximum posterior   \n",
      "markov chain monte carlo   mcmc\n",
      "mixture density network   mdn\n",
      "multidimensional scaling   mds\n",
      "mean   \n",
      "mean ﬁeld theory   \n",
      "mean value theorem   \n",
      "measure theory   \n",
      "memory-based methods   \n",
      "message passing   \n",
      "metropolis algorithm   \n",
      "metropolis-hastings algorithm   \n",
      "microstate   \n",
      "minimum risk   \n",
      "minkowski loss   \n",
      "missing at random   \n",
      "missing data   \n",
      "mixing coefﬁcient   \n",
      "mixture component   \n",
      "mixture density network   \n",
      "mixture distribution   \n",
      "mixture model   \n",
      "mixture of experts   \n",
      "mixture of gaussians   \n",
      "multilayer perceptron   mlp\n",
      "mnist data   \n",
      "model comparison   \n",
      "model evidence   \n",
      "model selection   \n",
      "moment matching   \n",
      "momentum variable   \n",
      "monte carlo em algorithm   \n",
      "monte carlo sampling   \n",
      "moore-penrose pseudo-inverse   \n",
      "moralization   \n",
      "markov random ﬁeld   mrf\n",
      "multidimensional scaling   \n",
      "multilayer perceptron   \n",
      "multimodality   \n",
      "multinomial distribution   \n",
      "multiplicity   \n",
      "mutual information   \n",
      "nadaraya-watson   \n",
      "naive bayes model   \n",
      "nats   \n",
      "natural language modelling   \n",
      "natural parameters   \n",
      "nearest-neighbour methods   \n",
      "neural network   \n",
      "newton-raphson   \n",
      "node   \n",
      "noiseless coding theorem   \n",
      "nonidentiﬁability   \n",
      "noninformative prior   \n",
      "nonparametric methods   \n",
      "normal distribution   \n",
      "normal equations   \n",
      "normal-gamma distribution   \n",
      "normal-wishart distribution   \n",
      "normalized exponential   \n",
      "novelty detection   \n",
      "ν-svm   \n",
      "object recognition   \n",
      "observed variable   \n",
      "occam factor   \n",
      "oil ﬂow data   \n",
      "old faithful data   \n",
      "on-line learning   \n",
      "one-versus-one classiﬁer   \n",
      "one-versus-the-rest classiﬁer   \n",
      "ordered over-relaxation   \n",
      "ornstein-uhlenbeck process   \n",
      "orthogonal least squares   \n",
      "outlier   \n",
      "outliers   \n",
      "over-ﬁtting   \n",
      "over-relaxation   \n",
      "pac learning   \n",
      "pac-bayesian framework   \n",
      "parameter shrinkage   \n",
      "parent node   \n",
      "particle ﬁlter   \n",
      "partition function   \n",
      "parzen estimator   \n",
      "parzen window   \n",
      "pattern recognition   \n",
      "principal component analysis   pca\n",
      "pending message   \n",
      "perceptron   \n",
      "perceptron criterion   \n",
      "perfect map   \n",
      "periodic variable   \n",
      "phase space   \n",
      "photon noise   \n",
      "plate   \n",
      "polynomial curve ﬁtting   \n",
      "polytree   \n",
      "position variable   \n",
      "positive deﬁnite covariance   \n",
      "positive deﬁnite matrix   \n",
      "positive semideﬁnite covariance   \n",
      "positive semideﬁnite matrix   \n",
      "posterior probability   \n",
      "posterior step   \n",
      "potential energy   \n",
      "potential function   \n",
      "power ep   \n",
      "power method   \n",
      "precision matrix   \n",
      "precision parameter   \n",
      "predictive distribution   \n",
      "preprocessing   \n",
      "principal component analysis   \n",
      "principal curve   \n",
      "principal subspace   \n",
      "principal surface   \n",
      "prior   \n",
      "probabilistic graphical model   \n",
      "probabilistic pca   \n",
      "probability   \n",
      "probably approximately correct   \n",
      "probit function   \n",
      "probit regression   \n",
      "product rule of probability   \n",
      "proposal distribution   \n",
      "protected conjugate gradients   \n",
      "protein sequence   \n",
      "pseudo-inverse   \n",
      "pseudo-random numbers   \n",
      "quadratic discriminant   \n",
      "quality parameter   \n",
      "radial basis function   \n",
      "rauch-tung-striebel equations   \n",
      "regression   \n",
      "regression function   \n",
      "regularization   \n",
      "regularized least squares   \n",
      "reinforcement learning   \n",
      "reject option   \n",
      "rejection sampling   \n",
      "relative entropy   \n",
      "relevance vector   \n",
      "relevance vector machine   \n",
      "responsibility   \n",
      "ridge regression   \n",
      "root-mean-square error   rms error\n",
      "robbins-monro algorithm   \n",
      "robot arm   \n",
      "robustness   \n",
      "root node   \n",
      "root-mean-square error   \n",
      "rosenblatt   \n",
      "rotation invariance   \n",
      "rauch-tung-striebel equations   rts equations\n",
      "running intersection property   \n",
      "relevance vector machine   rvm\n",
      "sample mean   \n",
      "sample variance   \n",
      "sampling-importance-resampling   \n",
      "scale invariance   \n",
      "scale parameter   \n",
      "scaling factor   \n",
      "schwarz criterion   \n",
      "self-organizing map   \n",
      "sequential data   \n",
      "sequential estimation   \n",
      "sequential gradient descent   \n",
      "sequential learning   \n",
      "sequential minimal optimization   \n",
      "serial message passing schedule   \n",
      "shannon   \n",
      "shared parameters   \n",
      "shrinkage   \n",
      "shur complement   \n",
      "sigmoid   \n",
      "simplex   \n",
      "single-class support vector machine   \n",
      "singular value decomposition   \n",
      "sinusoidal data   \n",
      "sampling-importance-resampling   sir\n",
      "skip-layer connection   \n",
      "slack variable   \n",
      "slice sampling   \n",
      "sequential minimal optimization   smo\n",
      "smoother matrix   \n",
      "smoothing parameter   \n",
      "soft margin   \n",
      "soft weight sharing   \n",
      "softmax function   \n",
      "self-organizing map   som\n",
      "sparsity   \n",
      "sparsity parameter   \n",
      "spectrogram   \n",
      "speech recognition   \n",
      "sphereing   \n",
      "spline functions   \n",
      "standard deviation   \n",
      "standardizing   \n",
      "state space model   \n",
      "stationary kernel   \n",
      "statistical bias   \n",
      "statistical independence   \n",
      "statistical learning theory   \n",
      "steepest descent   \n",
      "stirling’s approximation   \n",
      "stochastic   \n",
      "stochastic em   \n",
      "stochastic gradient descent   \n",
      "stochastic process   \n",
      "stratiﬁed ﬂow   \n",
      "student’s t-distribution   \n",
      "subsampling   \n",
      "sufﬁcient statistics   \n",
      "sum rule of probability   \n",
      "sum-of-squares error   \n",
      "sum-product algorithm   \n",
      "supervised learning   \n",
      "support vector   \n",
      "support vector machine   \n",
      "survival of the ﬁttest   \n",
      "singular value decomposition   svd\n",
      "support vector machine   svm\n",
      "switching hidden markov model   \n",
      "switching state space model   \n",
      "synthetic data sets   \n",
      "tail-to-tail path   \n",
      "tangent distance   \n",
      "tangent propagation   \n",
      "tapped delay line   \n",
      "target vector   \n",
      "test set   \n",
      "threshold parameter   \n",
      "tied parameters   \n",
      "tikhonov regularization   \n",
      "time warping   \n",
      "tomography   \n",
      "training   \n",
      "training set   \n",
      "transition probability   \n",
      "translation invariance   \n",
      "tree-reweighted message passing   \n",
      "treewidth   \n",
      "trellis diagram   \n",
      "triangulated graph   \n",
      "type 2 maximum likelihood   \n",
      "undetermined multiplier   \n",
      "undirected graph   \n",
      "uniform distribution   \n",
      "uniform sampling   \n",
      "uniquenesses   \n",
      "unobserved variable   \n",
      "unsupervised learning   \n",
      "utility function   \n",
      "validation set   \n",
      "vapnik-chervonenkis dimension   \n",
      "variance   \n",
      "variational inference   \n",
      "vapnik-chervonenkis dimension   vc dimension\n",
      "soft   \n",
      "between-class covariance   \n",
      "within-class covariance   \n",
      "partitioned covariance matrix   \n",
      "conditional entropy   \n",
      "differential entropy   \n",
      "relative entropy   \n",
      "functional derivative   \n",
      "conditional gaussian   \n",
      "gaussian marginal   \n",
      "gaussian mixture   \n",
      "directed graphical model   \n",
      "undirected graphical model   \n",
      "autoregressive hidden markov model   \n",
      "factorial hidden markov model   \n",
      "input-output hidden markov model   \n",
      "left-to-right hidden markov model   \n",
      "extended kalman ﬁlter   \n",
      "gaussian kernel function   \n",
      "fisher linear discriminant   \n",
      "linear regression problem   \n",
      "variational linear regression   \n",
      "bayesian logistic regression   \n",
      "logistic regression mixture model   \n",
      "multiclass logistic regression   \n",
      "margin error   \n",
      "soft margin   \n",
      "homogeneous markov chain   \n",
      "message passing schedule   \n",
      "variational message passing   \n",
      "conditional mixture model   \n",
      "logistic regression mixture model   \n",
      "convolutional neural network   \n",
      "perceptron convergence theorem   \n",
      "perceptron hardware   \n",
      "conjugate prior   \n",
      "consistent gaussian prior   \n",
      "improper prior   \n",
      "noninformative prior   \n",
      "bayesian probability   \n",
      "probability density   \n",
      "probability mass function   \n",
      "prior probability   \n",
      "probability sum rule   \n",
      "probability theory   \n",
      "tikhonov regularization   \n",
      "hierarchical bayesian analysis   \n",
      "model averaging bayesian analysis   \n",
      "mixture model bernoulli distribution   \n",
      "diagonal covariance matrix   \n",
      "isotropic covariance matrix   \n",
      "positive deﬁnite covariance matrix   \n",
      "gaussian mixture expectation maximization   \n",
      "generalized expectation maximization   \n",
      "sampling methods expectation maximization   \n",
      "mixture model factor analysis   \n",
      "maximum likelihood gaussian   \n",
      "sequential estimation gaussian   \n",
      "sufﬁcient statistics gaussian   \n",
      "wrapped gaussian   \n",
      "directional curvature generative topographic mapping   \n",
      "magniﬁcation factor generative topographic mapping   \n",
      "blocking gibbs sampling   \n",
      "bipartite graphical model   \n",
      "factorization graphical model   \n",
      "fully connected graphical model   \n",
      "inference graphical model   \n",
      "tree graphical model   \n",
      "treewidth graphical model   \n",
      "triangulated graphical model   \n",
      "diagonal approximation hessian matrix   \n",
      "exact evaluation hessian matrix   \n",
      "fast multiplication hessian matrix   \n",
      "ﬁnite differences hessian matrix   \n",
      "inverse hessian matrix   \n",
      "outer product approximation hessian matrix   \n",
      "forward-backward algorithm hidden markov model   \n",
      "maximum likelihood hidden markov model   \n",
      "scaling factor hidden markov model   \n",
      "sum-product algorithm hidden markov model   \n",
      "switching hidden markov model   \n",
      "variational inference hidden markov model   \n",
      "fisher kernel function   \n",
      "homogeneous kernel function   \n",
      "nonvectorial inputs kernel function   \n",
      "stationary kernel function   \n",
      "inference linear dynamical system   \n",
      "mixture model linear regression   \n",
      "ﬁrst order markov chain   \n",
      "second order markov chain   \n",
      "homogeneous markov model   \n",
      "gaussian mixture maximum likelihood   \n",
      "singularities maximum likelihood   \n",
      "type 2 maximum likelihood   \n",
      "pending message message passing   \n",
      "linear regression mixture model   \n",
      "symmetries mixture model   \n",
      "regularization neural network   \n",
      "relation to gaussian process neural network   \n",
      "bayesian principal component analysis   \n",
      "em algorithm principal component analysis   \n",
      "gibbs sampling principal component analysis   \n",
      "mixture distribution principal component analysis   \n",
      "physical analogy principal component analysis   \n",
      "classical probability   \n",
      "frequentist probability   \n",
      "product rule probability   \n",
      "switching state space model   \n",
      "for hidden markov model sum-product algorithm   \n",
      "for regression support vector machine   \n",
      "multiclass support vector machine   \n",
      "for gaussian mixture variational inference   \n",
      "for hidden markov model variational inference   \n",
      "local variational inference   \n",
      "vector quantization vapnik-chervonenkis dimension   \n",
      "vertex vapnik-chervonenkis dimension   \n",
      "visualization vapnik-chervonenkis dimension   \n",
      "viterbi algorithm vapnik-chervonenkis dimension   \n",
      "von mises distribution vapnik-chervonenkis dimension   \n",
      "wavelets vapnik-chervonenkis dimension   \n",
      "weak learner vapnik-chervonenkis dimension   \n",
      "weight decay vapnik-chervonenkis dimension   \n",
      "weight parameter vapnik-chervonenkis dimension   \n",
      "weight sharing vapnik-chervonenkis dimension   \n",
      "weight vector soft   \n",
      "weight-space symmetry soft   \n",
      "weighted least squares soft   \n",
      "well-determined parameters soft   \n",
      "whitening soft   \n",
      "wishart distribution soft   \n",
      "within-class covariance soft   \n",
      "woodbury identity soft   \n",
      "wrapped distribution soft   \n",
      "yellowstone national park soft   \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(relevant_topics)):\n",
    "    print(relevant_topics[i], \" \", topics_abbr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following are functions for extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contain_section(line):\n",
    "    line = line.strip()\n",
    "    if len(line) > 4:\n",
    "        if line[0] == \"=\" and line[1] == \"=\" and line[-2] == \"=\" and line[-1] == \"=\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def wiki_section_extract(content):\n",
    "    lines = content.split(\"\\n\")\n",
    "    sections = \"\"\n",
    "    for line in lines:\n",
    "        if contain_section(line):\n",
    "            sections += line[3:-3] + \"\\n\"\n",
    "    return sections.strip()\n",
    "\n",
    "def keyword_data(topic = \"\", abbr = \"\", wiki_title = \"\", wiki_summary = \"\",\n",
    "                 wiki_content = \"\", wiki_html = \"\", wiki_links = \"\", wiki_sections = \"\"):\n",
    "    data = {\n",
    "        'topic': topic,\n",
    "        \"abbreviation\": abbr,\n",
    "        \"wiki_title\": wiki_title,\n",
    "        \"wiki_summary\": wiki_summary,\n",
    "        \"wiki_content\": wiki_content,\n",
    "        \"wiki_html\": wiki_html,\n",
    "        \"wiki_links\": wiki_links,\n",
    "        \"wiki_sections\": wiki_sections\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_data(topic, abbr = \"\"):\n",
    "    wiki_title = \"\"\n",
    "    wiki_summary = \"\"\n",
    "    wiki_content = \"\"\n",
    "    wiki_html = \"\"\n",
    "    wiki_links = \"\"\n",
    "    wiki_sections = \"\"\n",
    "    try:\n",
    "        wiki = wikipedia.search(topic)[0]        \n",
    "        try:\n",
    "            wiki_data = wikipedia.page(topic)\n",
    "            wiki_summary = wiki_data.summary\n",
    "            wiki_content = wiki_data.content\n",
    "            wiki_html = wiki_data.html()\n",
    "            wiki_links = wiki_data.links\n",
    "            wiki_sections = wiki_section_extract(wiki_content)\n",
    "\n",
    "        except wikipedia.exceptions.DisambiguationError as e:\n",
    "            print(\"blank\")\n",
    "        except wikipedia.exceptions.PageError as e:\n",
    "            print(\"blank\")\n",
    "\n",
    "    except IndexError:\n",
    "        print(\"blank\")\n",
    "    \n",
    "    \n",
    "    data = keyword_data(topic, abbr, wiki_title, wiki_summary,\n",
    "                        wiki_content, wiki_html, wiki_links, wiki_sections)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = extract_data(relevant_topics[70], topics_abbr[70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keyword_data[70] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant topics, Topics abbr and all functions are all defined till this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_len = len(relevant_topics)\n",
    "all_keyword_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shivam/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py:389: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/shivam/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "blank\n",
      "616\n",
      "blank\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "blank\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "blank\n",
      "646\n",
      "647\n",
      "blank\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "blank\n",
      "670\n",
      "blank\n",
      "671\n",
      "blank\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "blank\n",
      "679\n",
      "680\n",
      "681\n",
      "blank\n",
      "682\n",
      "683\n",
      "blank\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "blank\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "blank\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "blank\n",
      "706\n",
      "blank\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "blank\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "blank\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "blank\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "blank\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "blank\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "blank\n",
      "763\n",
      "764\n",
      "blank\n",
      "765\n",
      "blank\n",
      "766\n",
      "blank\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "blank\n",
      "775\n",
      "blank\n",
      "776\n",
      "blank\n",
      "777\n",
      "778\n",
      "blank\n",
      "779\n"
     ]
    }
   ],
   "source": [
    "complete = 577\n",
    "for i in range(list_len - complete):\n",
    "    i += complete\n",
    "    data = extract_data(relevant_topics[i], topics_abbr[i])\n",
    "    all_keyword_data[i] = data\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    }
   ],
   "source": [
    "print(len(all_keyword_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data in JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topic_data.json', 'w') as file:\n",
    "    json.dump(all_keyword_data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['topic', 'abbreviation', 'wiki_title', 'wiki_summary', 'wiki_content', 'wiki_html', 'wiki_links', 'wiki_sections'])\n",
    "\n",
    "for i in range(len(all_keyword_data)):\n",
    "    df = df.append(all_keyword_data[i], ignore_index=True)\n",
    "\n",
    "df.to_csv(\"topic_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
