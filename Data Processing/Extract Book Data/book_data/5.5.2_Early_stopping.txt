An alternative to regularization as a way of controlling the effective complexity
of a network is the procedure of early stopping. The training of nonlinear network
models corresponds to an iterative reduction of the error function defined with re-
spect to a set of training data. For many of the optimization algorithms used for
network training, such as conjugate gradients, the error is a nonincreasing function
of the iteration index. However, the error measured with respect to independent data,
generally called a validation set, often shows a decrease at first, followed by an in-
crease as the network starts to over-fit. Training can therefore be stopped at the point
of smallest error with respect to the validation data set, as indicated in Figure 5.12,
in order to obtain a network having good generalization performance.
The behaviour of the network in this case is sometimes explained qualitatively
in terms of the effective number of degrees of freedom in the network, in which this
number starts out small and then to grows during the training process, corresponding
to a steady increase in the effective complexity of the model. Halting training before
1 = 1, αb
αw
1 = 1, αw
2 = 10, αb
2 = 1
1
−0.5
0
0.5
1
1 = 1000, αb
αw
1 = 1000, αw
2 = 1, αb
2 = 1
260
5. NEURAL NETWORKS
1 = 1, αb
αw
1 = 1, αw
2 = 1, αb
2 = 1
−0.5
0
0.5
1 = 1000, αb
αw
1 = 100, αw
2 = 1, αb
2 = 1
−0.5
0
0.5
4
2
0
−2
−4
−6
−1
5
0
−5
−10
−1
40
20
0
−20
−40
−60
−1
5
0
−5
1
−10
−1
−0.5
0
0.5
1
Figure 5.11 Illustration of the effect of the hyperparameters governing the prior distribution over weights and
biases in a two-layer network having a single input, a single linear output, and 12 hidden units having ‘tanh’
2 , which represent
activation functions. The priors are governed by four hyperparameters αb
the precisions of the Gaussian distributions of the first-layer biases, first-layer weights, second-layer biases, and
2 governs the vertical scale of functions (note
second-layer weights, respectively. We see that the parameter αw
the different vertical axis ranges on the top two diagrams), αw
1 governs the horizontal scale of variations in the
2, whose
function values, and αb
effect is not illustrated here, governs the range of vertical offsets of the functions.
1 governs the horizontal range over which variations occur. The parameter αb
2, and αw
1 , αb
1, αw
a minimum of the training error has been reached then represents a way of limiting
the effective network complexity.
In the case of a quadratic error function, we can verify this insight, and show
that early stopping should exhibit similar behaviour to regularization using a sim-
ple weight-decay term. This can be understood from Figure 5.13, in which the axes
in weight space have been rotated to be parallel to the eigenvectors of the Hessian
matrix. If, in the absence of weight decay, the weight vector starts at the origin and
proceeds during training along a path that follows the local negative gradient vec-
tor, then the weight vector will move initially parallel to the w2 axis through a point
w and then move towards the minimum of the error func-
corresponding roughly to
tion wML. This follows from the shape of the error surface and the widely differing
w is therefore similar to weight
eigenvalues of the Hessian. Stopping at a point near
decay. The relationship between early stopping and weight decay can be made quan-
titative, thereby showing that the quantity τ η (where τ is the iteration index, and η
is the learning rate parameter) plays the role of the reciprocal of the regularization
Exercise 5.25
5.5. Regularization in Neural Networks
261
0.25
0.2
0.15
0
10
20
30
40
50
0.45
0.4
0.35
0
10
20
30
40
50
Figure 5.12 An illustration of the behaviour of training set error (left) and validation set error (right) during a
typical training session, as a function of the iteration step, for the sinusoidal data set. The goal of achieving
the best generalization performance suggests that training should be stopped at the point shown by the vertical
dashed lines, corresponding to the minimum of the validation set error.
parameter λ. The effective number of parameters in the network therefore grows
during the course of training.
