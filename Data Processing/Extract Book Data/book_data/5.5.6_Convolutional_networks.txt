Another approach to creating models that are invariant to certain transformation
of the inputs is to build the invariance properties into the structure of a neural net-
work. This is the basis for the convolutional neural network (Le Cun et al., 1989;
LeCun et al., 1998), which has been widely applied to image data.
Consider the specific task of recognizing handwritten digits. Each input image
comprises a set of pixel intensity values, and the desired output is a posterior proba-
bility distribution over the ten digit classes. We know that the identity of the digit is
invariant under translations and scaling as well as (small) rotations. Furthermore, the
network must also exhibit invariance to more subtle transformations such as elastic
deformations of the kind illustrated in Figure 5.14. One simple approach would be to
treat the image as the input to a fully connected network, such as the kind shown in
Figure 5.1. Given a sufficiently large training set, such a network could in principle
yield a good solution to this problem and would learn the appropriate invariances by
example.
However, this approach ignores a key property of images, which is that nearby
pixels are more strongly correlated than more distant pixels. Many of the modern
approaches to computer vision exploit this property by extracting local features that
depend only on small subregions of the image. Information from such features can
then be merged in later stages of processing in order to detect higher-order features
5.5. Regularization in Neural Networks
267
Exercise 5.27
268
5. NEURAL NETWORKS
Input image
Convolutional layer
Sub-sampling
layer
Figure 5.17 Diagram illustrating part of a convolutional neural network, showing a layer of convolu-
tional units followed by a layer of subsampling units. Several successive pairs of such
layers may be used.
and ultimately to yield information about the image as whole. Also, local features
that are useful in one region of the image are likely to be useful in other regions of
the image, for instance if the object of interest is translated.
These notions are incorporated into convolutional neural networks through three
mechanisms: (i) local receptive fields, (ii) weight sharing, and (iii) subsampling. The
structure of a convolutional network is illustrated in Figure 5.17. In the convolutional
layer the units are organized into planes, each of which is called a feature map. Units
in a feature map each take inputs only from a small subregion of the image, and all
of the units in a feature map are constrained to share the same weight values. For
instance, a feature map might consist of 100 units arranged in a 10 × 10 grid, with
each unit taking inputs from a 5×5 pixel patch of the image. The whole feature map
therefore has 25 adjustable weight parameters plus one adjustable bias parameter.
Input values from a patch are linearly combined using the weights and the bias, and
the result transformed by a sigmoidal nonlinearity using (5.1). If we think of the units
as feature detectors, then all of the units in a feature map detect the same pattern but
at different locations in the input image. Due to the weight sharing, the evaluation
of the activations of these units is equivalent to a convolution of the image pixel
intensities with a ‘kernel’ comprising the weight parameters. If the input image is
shifted, the activations of the feature map will be shifted by the same amount but will
otherwise be unchanged. This provides the basis for the (approximate) invariance of
5.5. Regularization in Neural Networks
269
the network outputs to translations and distortions of the input image. Because we
will typically need to detect multiple features in order to build an effective model,
there will generally be multiple feature maps in the convolutional layer, each having
its own set of weight and bias parameters.
The outputs of the convolutional units form the inputs to the subsampling layer
of the network. For each feature map in the convolutional layer, there is a plane of
units in the subsampling layer and each unit takes inputs from a small receptive field
in the corresponding feature map of the convolutional layer. These units perform
subsampling. For instance, each subsampling unit might take inputs from a 2 × 2
unit region in the corresponding feature map and would compute the average of
those inputs, multiplied by an adaptive weight with the addition of an adaptive bias
parameter, and then transformed using a sigmoidal nonlinear activation function.
The receptive fields are chosen to be contiguous and nonoverlapping so that there
are half the number of rows and columns in the subsampling layer compared with
the convolutional layer. In this way, the response of a unit in the subsampling layer
will be relatively insensitive to small shifts of the image in the corresponding regions
of the input space.
In a practical architecture, there may be several pairs of convolutional and sub-
sampling layers. At each stage there is a larger degree of invariance to input trans-
formations compared to the previous layer. There may be several feature maps in a
given convolutional layer for each plane of units in the previous subsampling layer,
so that the gradual reduction in spatial resolution is then compensated by an increas-
ing number of features. The final layer of the network would typically be a fully
connected, fully adaptive layer, with a softmax output nonlinearity in the case of
multiclass classification.
The whole network can be trained by error minimization using backpropagation
to evaluate the gradient of the error function. This involves a slight modification
of the usual backpropagation algorithm to ensure that the shared-weight constraints
are satisfied. Due to the use of local receptive fields, the number of weights in
the network is smaller than if the network were fully connected. Furthermore, the
number of independent parameters to be learned from the data is much smaller still,
due to the substantial numbers of constraints on the weights.
