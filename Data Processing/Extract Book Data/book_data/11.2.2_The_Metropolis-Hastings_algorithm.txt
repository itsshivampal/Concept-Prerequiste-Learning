Earlier we introduced the basic Metropolis algorithm, without actually demon-
strating that it samples from the required distribution. Before giving a proof, we
first discuss a generalization, known as the Metropolis-Hastings algorithm (Hast-
ings, 1970), to the case where the proposal distribution is no longer a symmetric
function of its arguments. In particular at step τ of the algorithm, in which the cur-
rent state is z(τ ), we draw a sample z from the distribution qk(z|z(τ )) and then
accept it with probability Ak(z, zτ ) where
Ak(z, z(τ )) = min
1,
(11.44)
p(z)qk(z(τ )|z)
p(z(τ ))qk(z|z(τ ))
Here k labels the members of the set of possible transitions being considered. Again,
the evaluation of the acceptance criterion does not require knowledge of the normal-
izing constant Zp in the probability distribution p(z) =
p(z)/Zp. For a symmetric
proposal distribution the Metropolis-Hastings criterion (11.44) reduces to the stan-
dard Metropolis criterion given by (11.33).
We can show that p(z) is an invariant distribution of the Markov chain defined
by the Metropolis-Hastings algorithm by showing that detailed balance, defined by
(11.40), is satisfied. Using (11.44) we have
p(z)qk(z|z)Ak(z, z) = min (p(z)qk(z|z), p(z)qk(z|z))
= min (p(z)qk(z|z), p(z)qk(z|z))
= p(z)qk(z|z)Ak(z, z)
(11.45)
as required.
The specific choice of proposal distribution can have a marked effect on the
performance of the algorithm. For continuous state spaces, a common choice is a
Gaussian centred on the current state, leading to an important trade-off in determin-
ing the variance parameter of this distribution.
If the variance is small, then the
542
11. SAMPLING METHODS
Figure 11.10 Schematic illustration of the use of an isotropic
Gaussian proposal distribution (blue circle) to
sample from a correlated multivariate Gaussian
distribution (red ellipse) having very different stan-
dard deviations in different directions, using the
Metropolis-Hastings algorithm.
In order to keep
the rejection rate low, the scale ρ of the proposal
distribution should be on the order of the smallest
standard deviation σmin, which leads to random
walk behaviour in which the number of steps sep-
arating states that are approximately independent
is of order (σmax/σmin)2 where σmax is the largest
standard deviation.
σmin
σmax
proportion of accepted transitions will be high, but progress through the state space
takes the form of a slow random walk leading to long correlation times. However,
if the variance parameter is large, then the rejection rate will be high because, in the
kind of complex problems we are considering, many of the proposed steps will be
to states for which the probability p(z) is low. Consider a multivariate distribution
p(z) having strong correlations between the components of z, as illustrated in Fig-
ure 11.10. The scale ρ of the proposal distribution should be as large as possible
without incurring high rejection rates. This suggests that ρ should be of the same
order as the smallest length scale σmin. The system then explores the distribution
along the more extended direction by means of a random walk, and so the number
of steps to arrive at a state that is more or less independent of the original state is
of order (σmax/σmin)2. In fact in two dimensions, the increase in rejection rate as ρ
increases is offset by the larger steps sizes of those transitions that are accepted, and
more generally for a multivariate Gaussian the number of steps required to obtain
independent samples scales like (σmax/σ2)2 where σ2 is the second-smallest stan-
dard deviation (Neal, 1993). These details aside, it remains the case that if the length
scales over which the distributions vary are very different in different directions, then
the Metropolis Hastings algorithm can have very slow convergence.
