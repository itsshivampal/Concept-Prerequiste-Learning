Figure 13.2 The simplest approach to
modelling a sequence of ob-
servations is to treat
them
as independent, correspond-
ing to a graph without links.
x1
13.1. Markov Models
607
x3
x4
x2
The easiest way to treat sequential data would be simply to ignore the sequential
aspects and treat the observations as i.i.d., corresponding to the graph in Figure 13.2.
Such an approach, however, would fail to exploit the sequential patterns in the data,
such as correlations between observations that are close in the sequence. Suppose,
for instance, that we observe a binary variable denoting whether on a particular day
it rained or not. Given a time series of recent observations of this variable, we wish
to predict whether it will rain on the next day. If we treat the data as i.i.d., then the
only information we can glean from the data is the relative frequency of rainy days.
However, we know in practice that the weather often exhibits trends that may last for
several days. Observing whether or not it rains today is therefore of significant help
in predicting if it will rain tomorrow.
To express such effects in a probabilistic model, we need to relax the i.i.d. as-
sumption, and one of the simplest ways to do this is to consider a Markov model.
First of all we note that, without loss of generality, we can use the product rule to
express the joint distribution for a sequence of observations in the form
p(x1, . . . , xN ) =
p(xn|x1, . . . , xn−1).
n=1
(13.1)
If we now assume that each of the conditional distributions on the right-hand side
is independent of all previous observations except the most recent, we obtain the
first-order Markov chain, which is depicted as a graphical model in Figure 13.3. The
N
N
n=2
608
13. SEQUENTIAL DATA
Figure 13.3 A first-order Markov chain of ob-
servations {xn} in which the dis-
tribution p(xn|xn−1) of a particu-
lar observation xn is conditioned
on the value of the previous ob-
servation xn−1.
x1
x2
x3
x4
Section 8.2
Exercise 13.1
joint distribution for a sequence of N observations under this model is given by
p(x1, . . . , xN ) = p(x1)
p(xn|xn−1).
(13.2)
From the d-separation property, we see that the conditional distribution for observa-
tion xn, given all of the observations up to time n, is given by
p(xn|x1, . . . , xn−1) = p(xn|xn−1)
(13.3)
which is easily verified by direct evaluation starting from (13.2) and using the prod-
uct rule of probability. Thus if we use such a model to predict the next observation
in a sequence, the distribution of predictions will depend only on the value of the im-
mediately preceding observation and will be independent of all earlier observations.
In most applications of such models, the conditional distributions p(xn|xn−1)
that define the model will be constrained to be equal, corresponding to the assump-
tion of a stationary time series. The model is then known as a homogeneous Markov
chain. For instance, if the conditional distributions depend on adjustable parameters
(whose values might be inferred from a set of training data), then all of the condi-
tional distributions in the chain will share the same values of those parameters.
Although this is more general than the independence model, it is still very re-
strictive. For many sequential observations, we anticipate that the trends in the data
over several successive observations will provide important information in predict-
ing the next value. One way to allow earlier observations to have an influence is to
move to higher-order Markov chains. If we allow the predictions to depend also on
the previous-but-one value, we obtain a second-order Markov chain, represented by
the graph in Figure 13.4. The joint distribution is now given by
p(x1, . . . , xN ) = p(x1)p(x2|x1)
p(xn|xn−1, xn−2).
n=3
(13.4)
Again, using d-separation or by direct evaluation, we see that the conditional distri-
bution of xn given xn−1 and xn−2 is independent of all observations x1, . . . xn−3.
Figure 13.4 A second-order Markov chain, in
which the conditional distribution
of a particular observation xn
depends on the values of the two
previous observations xn−1 and
xn−2.
x1
x2
x3
x4
Figure 13.5 We can represent sequen-
tial data using a Markov chain of latent
variables, with each observation condi-
tioned on the state of the corresponding
latent variable. This important graphical
structure forms the foundation both for the
hidden Markov model and for linear dy-
namical systems.
z1
x1
z2
x2
13.1. Markov Models
609
zn−1
xn−1
zn
xn
zn+1
xn+1
Each observation is now influenced by two previous observations. We can similarly
consider extensions to an M th order Markov chain in which the conditional distri-
bution for a particular variable depends on the previous M variables. However, we
have paid a price for this increased flexibility because the number of parameters in
the model is now much larger. Suppose the observations are discrete variables hav-
ing K states. Then the conditional distribution p(xn|xn−1) in a first-order Markov
chain will be specified by a set of K − 1 parameters for each of the K states of xn−1
giving a total of K(K − 1) parameters. Now suppose we extend the model to an
M th order Markov chain, so that the joint distribution is built up from conditionals
p(xn|xn−M , . . . , xn−1). If the variables are discrete, and if the conditional distri-
butions are represented by general conditional probability tables, then the number
of parameters in such a model will have KM−1(K − 1) parameters. Because this
grows exponentially with M, it will often render this approach impractical for larger
values of M.
For continuous variables, we can use linear-Gaussian conditional distributions
in which each node has a Gaussian distribution whose mean is a linear function
of its parents. This is known as an autoregressive or AR model (Box et al., 1994;
Thiesson et al., 2004). An alternative approach is to use a parametric model for
p(xn|xn−M , . . . , xn−1) such as a neural network. This technique is sometimes
called a tapped delay line because it corresponds to storing (delaying) the previous
M values of the observed variable in order to predict the next value. The number
of parameters can then be much smaller than in a completely general model (for ex-
ample it may grow linearly with M), although this is achieved at the expense of a
restricted family of conditional distributions.
Suppose we wish to build a model for sequences that is not limited by the
Markov assumption to any order and yet that can be specified using a limited number
of free parameters. We can achieve this by introducing additional latent variables to
permit a rich class of models to be constructed out of simple components, as we did
with mixture distributions in Chapter 9 and with continuous latent variable models in
Chapter 12. For each observation xn, we introduce a corresponding latent variable
zn (which may be of different type or dimensionality to the observed variable). We
now assume that it is the latent variables that form a Markov chain, giving rise to the
graphical structure known as a state space model, which is shown in Figure 13.5. It
satisfies the key conditional independence property that zn−1 and zn+1 are indepen-
dent given zn, so that
(13.5)
zn+1 ⊥⊥ zn−1 | zn.
N
p(xn|zn).
n=1
(13.6)
N
610
13. SEQUENTIAL DATA
The joint distribution for this model is given by
p(x1, . . . , xN , z1, . . . , zN ) = p(z1)
n=2
p(zn|zn−1)
Using the d-separation criterion, we see that there is always a path connecting any
two observed variables xn and xm via the latent variables, and that this path is never
blocked. Thus the predictive distribution p(xn+1|x1, . . . , xn) for observation xn+1
given all previous observations does not exhibit any conditional independence prop-
erties, and so our predictions for xn+1 depends on all previous observations. The
observed variables, however, do not satisfy the Markov property at any order. We
shall discuss how to evaluate the predictive distribution in later sections of this chap-
ter.
There are two important models for sequential data that are described by this
graph. If the latent variables are discrete, then we obtain the hidden Markov model,
or HMM (Elliott et al., 1995). Note that the observed variables in an HMM may
be discrete or continuous, and a variety of different conditional distributions can be
used to model them. If both the latent and the observed variables are Gaussian (with
a linear-Gaussian dependence of the conditional distributions on their parents), then
we obtain the linear dynamical system.
Section 13.2
Section 13.3
