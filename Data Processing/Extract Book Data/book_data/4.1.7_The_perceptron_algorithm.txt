Another example of a linear discriminant model is the perceptron of Rosenblatt
(1962), which occupies an important place in the history of pattern recognition al-
gorithms. It corresponds to a two-class model in which the input vector x is first
transformed using a fixed nonlinear transformation to give a feature vector φ(x),
and this is then used to construct a generalized linear model of the form
y(x) = f
wTφ(x)
(4.52)
4.1. Discriminant Functions
193
where the nonlinear activation function f(·) is given by a step function of the form
(4.53)
f(a) =
+1, a � 0
−1, a < 0.
The vector φ(x) will typically include a bias component φ0(x) = 1.
In earlier
discussions of two-class classification problems, we have focussed on a target coding
scheme in which t ∈ {0, 1}, which is appropriate in the context of probabilistic
models. For the perceptron, however, it is more convenient to use target values
t = +1 for class C1 and t = −1 for class C2, which matches the choice of activation
function.
The algorithm used to determine the parameters w of the perceptron can most
easily be motivated by error function minimization. A natural choice of error func-
tion would be the total number of misclassified patterns. However, this does not lead
to a simple learning algorithm because the error is a piecewise constant function
of w, with discontinuities wherever a change in w causes the decision boundary to
move across one of the data points. Methods based on changing w using the gradi-
ent of the error function cannot then be applied, because the gradient is zero almost
everywhere.
We therefore consider an alternative error function known as the perceptron cri-
terion. To derive this, we note that we are seeking a weight vector w such that
patterns xn in class C1 will have wTφ(xn) > 0, whereas patterns xn in class C2
have wTφ(xn) < 0. Using the t ∈ {−1, +1} target coding scheme it follows that
we would like all patterns to satisfy wTφ(xn)tn > 0. The perceptron criterion
associates zero error with any pattern that is correctly classified, whereas for a mis-
classified pattern xn it tries to minimize the quantity −wTφ(xn)tn. The perceptron
criterion is therefore given by
EP(w) = −
n∈M
wTφntn
(4.54)
Frank Rosenblatt
1928–1969
Rosenblatt’s perceptron played an
important role in the history of ma-
chine learning.
Initially, Rosenblatt
simulated the perceptron on an IBM
704 computer at Cornell
in 1957,
but by the early 1960s he had built
special-purpose hardware that provided a direct, par-
allel implementation of perceptron learning. Many of
his ideas were encapsulated in “Principles of Neuro-
dynamics: Perceptrons and the Theory of Brain Mech-
anisms” published in 1962. Rosenblatt’s work was
criticized by Marvin Minksy, whose objections were
published in the book “Perceptrons”, co-authored with
Seymour Papert. This book was widely misinter-
preted at the time as showing that neural networks
were fatally flawed and could only learn solutions for
linearly separable problems.
In fact, it only proved
such limitations in the case of single-layer networks
such as the perceptron and merely conjectured (in-
correctly) that they applied to more general network
models. Unfortunately, however, this book contributed
to the substantial decline in research funding for neu-
ral computing, a situation that was not reversed un-
til the mid-1980s. Today, there are many hundreds,
if not thousands, of applications of neural networks
in widespread use, with examples in areas such as
handwriting recognition and information retrieval be-
ing used routinely by millions of people.
194
4. LINEAR MODELS FOR CLASSIFICATION
Section 3.1.3
where M denotes the set of all misclassified patterns. The contribution to the error
associated with a particular misclassified pattern is a linear function of w in regions
of w space where the pattern is misclassified and zero in regions where it is correctly
classified. The total error function is therefore piecewise linear.
We now apply the stochastic gradient descent algorithm to this error function.
The change in the weight vector w is then given by
w(τ +1) = w(τ ) − η∇EP(w) = w(τ ) + ηφntn
(4.55)
where η is the learning rate parameter and τ is an integer that indexes the steps of
the algorithm. Because the perceptron function y(x, w) is unchanged if we multiply
w by a constant, we can set the learning rate parameter η equal to 1 without of
generality. Note that, as the weight vector evolves during training, the set of patterns
that are misclassified will change.
The perceptron learning algorithm has a simple interpretation, as follows. We
cycle through the training patterns in turn, and for each pattern xn we evaluate the
perceptron function (4.52).
If the pattern is correctly classified, then the weight
vector remains unchanged, whereas if it is incorrectly classified, then for class C1
we add the vector φ(xn) onto the current estimate of weight vector w while for
class C2 we subtract the vector φ(xn) from w. The perceptron learning algorithm is
illustrated in Figure 4.7.
If we consider the effect of a single update in the perceptron learning algorithm,
we see that the contribution to the error from a misclassified pattern will be reduced
because from (4.55) we have
−w(τ +1)Tφntn = −w(τ )Tφntn − (φntn)Tφntn < −w(τ )Tφntn
(4.56)
where we have set η = 1, and made use of φntn2 > 0. Of course, this does
not imply that the contribution to the error function from the other misclassified
patterns will have been reduced. Furthermore, the change in weight vector may have
caused some previously correctly classified patterns to become misclassified. Thus
the perceptron learning rule is not guaranteed to reduce the total error function at
each stage.
However, the perceptron convergence theorem states that if there exists an ex-
act solution (in other words, if the training data set is linearly separable), then the
perceptron learning algorithm is guaranteed to find an exact solution in a finite num-
ber of steps. Proofs of this theorem can be found for example in Rosenblatt (1962),
Block (1962), Nilsson (1965), Minsky and Papert (1969), Hertz et al. (1991), and
Bishop (1995a). Note, however, that the number of steps required to achieve con-
vergence could still be substantial, and in practice, until convergence is achieved,
we will not be able to distinguish between a nonseparable problem and one that is
simply slow to converge.
Even when the data set is linearly separable, there may be many solutions, and
which one is found will depend on the initialization of the parameters and on the or-
der of presentation of the data points. Furthermore, for data sets that are not linearly
separable, the perceptron learning algorithm will never converge.
4.1. Discriminant Functions
195
1
0.5
0
−0.5
−1
−1
1
0.5
0
−0.5
−1
−1
1
0.5
0
−0.5
−1
−1
1
0.5
0
−0.5
−1
−1
−0.5
0
0.5
1
−0.5
0
0.5
1
−0.5
0
0.5
1
−0.5
0
0.5
1
Figure 4.7 Illustration of the convergence of the perceptron learning algorithm, showing data points from two
classes (red and blue) in a two-dimensional feature space (φ1, φ2). The top left plot shows the initial parameter
vector w shown as a black arrow together with the corresponding decision boundary (black line), in which the
arrow points towards the decision region which classified as belonging to the red class. The data point circled
in green is misclassified and so its feature vector is added to the current weight vector, giving the new decision
boundary shown in the top right plot. The bottom left plot shows the next misclassified point to be considered,
indicated by the green circle, and its feature vector is again added to the weight vector giving the decision
boundary shown in the bottom right plot for which all data points are correctly classified.
196
4. LINEAR MODELS FOR CLASSIFICATION
Figure 4.8 Illustration of the Mark 1 perceptron hardware. The photograph on the left shows how the inputs
were obtained using a simple camera system in which an input scene, in this case a printed character, was
illuminated by powerful lights, and an image focussed onto a 20 × 20 array of cadmium sulphide photocells,
giving a primitive 400 pixel image. The perceptron also had a patch board, shown in the middle photograph,
which allowed different configurations of input features to be tried. Often these were wired up at random to
demonstrate the ability of the perceptron to learn without the need for precise wiring, in contrast to a modern
digital computer. The photograph on the right shows one of the racks of adaptive weights. Each weight was
implemented using a rotary variable resistor, also called a potentiometer, driven by an electric motor thereby
allowing the value of the weight to be adjusted automatically by the learning algorithm.
Aside from difficulties with the learning algorithm, the perceptron does not pro-
vide probabilistic outputs, nor does it generalize readily to K > 2 classes. The most
important limitation, however, arises from the fact that (in common with all of the
models discussed in this chapter and the previous one) it is based on linear com-
binations of fixed basis functions. More detailed discussions of the limitations of
perceptrons can be found in Minsky and Papert (1969) and Bishop (1995a).
Analogue hardware implementations of the perceptron were built by Rosenblatt,
based on motor-driven variable resistors to implement the adaptive parameters wj.
These are illustrated in Figure 4.8. The inputs were obtained from a simple camera
system based on an array of photo-sensors, while the basis functions φ could be
chosen in a variety of ways, for example based on simple fixed functions of randomly
chosen subsets of pixels from the input image. Typical applications involved learning
to discriminate simple shapes or characters.
At the same time that the perceptron was being developed, a closely related
system called the adaline, which is short for ‘adaptive linear element’, was being
explored by Widrow and co-workers. The functional form of the model was the same
as for the perceptron, but a different approach to training was adopted (Widrow and
Hoff, 1960; Widrow and Lehr, 1990).
