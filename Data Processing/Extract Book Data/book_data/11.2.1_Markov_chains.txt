Before discussing Markov chain Monte Carlo methods in more detail, it is use-
ful to study some general properties of Markov chains in more detail. In particular,
we ask under what circumstances will a Markov chain converge to the desired dis-
tribution. A first-order Markov chain is defined to be a series of random variables
z(1), . . . , z(M ) such that the following conditional independence property holds for
m ∈ {1, . . . , M − 1}
p(z(m+1)|z(1), . . . , z(m)) = p(z(m+1)|z(m)).
(11.37)
This of course can be represented as a directed graph in the form of a chain, an ex-
ample of which is shown in Figure 8.38. We can then specify the Markov chain by
giving the probability distribution for the initial variable p(z(0)) together with the
z
z(m)
K
540
11. SAMPLING METHODS
conditional probabilities for subsequent variables in the form of transition probabil-
ities Tm(z(m), z(m+1)) ≡ p(z(m+1)|z(m)). A Markov chain is called homogeneous
if the transition probabilities are the same for all m.
The marginal probability for a particular variable can be expressed in terms of
the marginal probability for the previous variable in the chain in the form
p(z(m+1)) =
p(z(m+1)|z(m))p(z(m)).
(11.38)
A distribution is said to be invariant, or stationary, with respect to a Markov chain
if each step in the chain leaves that distribution invariant. Thus, for a homogeneous
Markov chain with transition probabilities T (z, z), the distribution p(z) is invariant
if
p(z) =
T (z, z)p(z).
(11.39)
Note that a given Markov chain may have more than one invariant distribution. For
instance, if the transition probabilities are given by the identity transformation, then
any distribution will be invariant.
A sufficient (but not necessary) condition for ensuring that the required distribu-
tion p(z) is invariant is to choose the transition probabilities to satisfy the property
of detailed balance, defined by
p(z)T (z, z) = p(z)T (z, z)
(11.40)
for the particular distribution p(z).
It is easily seen that a transition probability
that satisfies detailed balance with respect to a particular distribution will leave that
distribution invariant, because
p(z)T (z, z) =
z
z
p(z)T (z, z) = p(z)
p(z|z) = p(z).
(11.41)
z
A Markov chain that respects detailed balance is said to be reversible.
Our goal is to use Markov chains to sample from a given distribution. We can
achieve this if we set up a Markov chain such that the desired distribution is invariant.
However, we must also require that for m → ∞, the distribution p(z(m)) converges
to the required invariant distribution p(z), irrespective of the choice of initial dis-
tribution p(z(0)). This property is called ergodicity, and the invariant distribution
is then called the equilibrium distribution. Clearly, an ergodic Markov chain can
have only one equilibrium distribution. It can be shown that a homogeneous Markov
chain will be ergodic, subject only to weak restrictions on the invariant distribution
and the transition probabilities (Neal, 1993).
In practice we often construct the transition probabilities from a set of ‘base’
transitions B1, . . . , BK. This can be achieved through a mixture distribution of the
form
T (z, z) =
αkBk(z, z)
k=1
(11.42)
11.2. Markov Chain Monte Carlo
541
for some set of mixing coefficients α1, . . . , αK satisfying αk � 0 and
k αk = 1.
Alternatively, the base transitions may be combined through successive application,
so that
T (z, z) =
z1
zn−1
B1(z, z1) . . . BK−1(zK−2, zK−1)BK(zK−1, z).
(11.43)
If a distribution is invariant with respect to each of the base transitions, then obvi-
ously it will also be invariant with respect to either of the T (z, z) given by (11.42)
or (11.43). For the case of the mixture (11.42), if each of the base transitions sat-
isfies detailed balance, then the mixture transition T will also satisfy detailed bal-
ance. This does not hold for the transition probability constructed using (11.43), al-
though by symmetrizing the order of application of the base transitions, in the form
B1, B2, . . . , BK, BK, . . . , B2, B1, detailed balance can be restored. A common ex-
ample of the use of composite transition probabilities is where each base transition
changes only a subset of the variables.
