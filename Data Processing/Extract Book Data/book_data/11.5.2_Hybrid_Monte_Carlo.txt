for achieving this is called the leapfrog discretization and involves alternately updat-
r to the position and momentum variables
ing discrete-time approximations
using
z and
ri(τ + 	/2) =
zi(τ + 	) =
ri(τ + 	) =
z(τ))
∂E
ri(τ) −
2
∂zi
ri(τ + 	/2)
zi(τ) +
∂E
ri(τ + 	/2) −
∂zi
2
z(τ + 	)).
(11.64)
(11.65)
(11.66)
We see that this takes the form of a half-step update of the momentum variables with
step size 	/2, followed by a full-step update of the position variables with step size 	,
followed by a second half-step update of the momentum variables. If several leapfrog
steps are applied in succession, it can be seen that half-step updates to the momentum
variables can be combined into full-step updates with step size 	. The successive
updates to position and momentum variables then leapfrog over each other. In order
to advance the dynamics by a time interval τ , we need to take τ /	 steps. The error
involved in the discretized approximation to the continuous time dynamics will go to
zero, assuming a smooth function E(z), in the limit 	 → 0. However, for a nonzero
as used in practice, some residual error will remain. We shall see in Section 11.5.2
how the effects of such errors can be eliminated in the hybrid Monte Carlo algorithm.
In summary then, the Hamiltonian dynamical approach involves alternating be-
tween a series of leapfrog updates and a resampling of the momentum variables from
their marginal distribution.
Note that the Hamiltonian dynamics method, unlike the basic Metropolis algo-
rithm, is able to make use of information about the gradient of the log probability
distribution as well as about the distribution itself. An analogous situation is familiar
from the domain of function optimization. In most cases where gradient informa-
tion is available, it is highly advantageous to make use of it. Informally, this follows
from the fact that in a space of dimension D, the additional computational cost of
evaluating a gradient compared with evaluating the function itself will typically be a
fixed factor independent of D, whereas the D-dimensional gradient vector conveys
D pieces of information compared with the one piece of information given by the
function itself.
552
11. SAMPLING METHODS
11.5.2 Hybrid Monte Carlo
As we discussed in the previous section, for a nonzero step size 	, the discretiza-
tion of the leapfrog algorithm will introduce errors into the integration of the Hamil-
tonian dynamical equations. Hybrid Monte Carlo (Duane et al., 1987; Neal, 1996)
combines Hamiltonian dynamics with the Metropolis algorithm and thereby removes
any bias associated with the discretization.
Specifically, the algorithm uses a Markov chain consisting of alternate stochastic
updates of the momentum variable r and Hamiltonian dynamical updates using the
leapfrog algorithm. After each application of the leapfrog algorithm, the resulting
candidate state is accepted or rejected according to the Metropolis criterion based
on the value of the Hamiltonian H. Thus if (z, r) is the initial state and (z, r)
is the state after the leapfrog integration, then this candidate state is accepted with
probability
min (1, exp{H(z, r) − H(z, r)}) .
(11.67)
If the leapfrog integration were to simulate the Hamiltonian dynamics perfectly,
then every such candidate step would automatically be accepted because the value
of H would be unchanged. Due to numerical errors, the value of H may sometimes
decrease, and we would like the Metropolis criterion to remove any bias due to this
effect and ensure that the resulting samples are indeed drawn from the required dis-
tribution. In order for this to be the case, we need to ensure that the update equations
corresponding to the leapfrog integration satisfy detailed balance (11.40). This is
easily achieved by modifying the leapfrog scheme as follows.
Before the start of each leapfrog integration sequence, we choose at random,
with equal probability, whether to integrate forwards in time (using step size 	) or
backwards in time (using step size −	). We first note that the leapfrog integration
scheme (11.64), (11.65), and (11.66) is time-reversible, so that integration for L steps
using step size −	 will exactly undo the effect of integration for L steps using step
size 	. Next we show that the leapfrog integration preserves phase-space volume
exactly. This follows from the fact that each step in the leapfrog scheme updates
either a zi variable or an ri variable by an amount that is a function only of the other
variable. As shown in Figure 11.14, this has the effect of shearing a region of phase
space while not altering its volume.
Finally, we use these results to show that detailed balance holds. Consider a
small region R of phase space that, under a sequence of L leapfrog iterations of
step size 	, maps to a region R. Using conservation of volume under the leapfrog
iteration, we see that if R has volume δV then so too will R. If we choose an initial
point from the distribution (11.63) and then update it using L leapfrog interactions,
the probability of the transition going from R to R is given by
1
ZH
exp(−H(R))δV
min{1, exp(−H(R) + H(R))} .
(11.68)
1
2
where the factor of 1/2 arises from the probability of choosing to integrate with a
positive step size rather than a negative one. Similarly, the probability of starting in
11.5. The Hybrid Monte Carlo Algorithm
553
ri
zi
1
ZH
Exercise 11.17
ri
Figure 11.14 Each step of the leapfrog algorithm (11.64)–(11.66) modifies either a position variable zi or a
momentum variable ri. Because the change to one variable is a function only of the other, any region in phase
space will be sheared without change of volume.
zi
region R and integrating backwards in time to end up in region R is given by
exp(−H(R))δV
min{1, exp(−H(R) + H(R))} .
(11.69)
1
2
It is easily seen that the two probabilities (11.68) and (11.69) are equal, and hence
detailed balance holds. Note that this proof ignores any overlap between the regions
R and R but is easily generalized to allow for such overlap.
It is not difficult to construct examples for which the leapfrog algorithm returns
to its starting position after a finite number of iterations. In such cases, the random
replacement of the momentum values before each leapfrog integration will not be
sufficient to ensure ergodicity because the position variables will never be updated.
Such phenomena are easily avoided by choosing the magnitude of the step size at
random from some small interval, before each leapfrog integration.
We can gain some insight into the behaviour of the hybrid Monte Carlo algo-
rithm by considering its application to a multivariate Gaussian. For convenience,
consider a Gaussian distribution p(z) with independent components, for which the
Hamiltonian is given by
H(z, r) =
1
2
i
1
σ2
i
i +
z2
1
2
r2
i .
i
(11.70)
Our conclusions will be equally valid for a Gaussian distribution having correlated
components because the hybrid Monte Carlo algorithm exhibits rotational isotropy.
During the leapfrog integration, each pair of phase-space variables zi, ri evolves in-
dependently. However, the acceptance or rejection of the candidate point is based
on the value of H, which depends on the values of all of the variables. Thus, a
significant integration error in any one of the variables could lead to a high prob-
ability of rejection. In order that the discrete leapfrog integration be a reasonably
554
11. SAMPLING METHODS
good approximation to the true continuous-time dynamics, it is necessary for the
leapfrog integration scale 	 to be smaller than the shortest length-scale over which
the potential is varying significantly. This is governed by the smallest value of σi,
which we denote by σmin. Recall that the goal of the leapfrog integration in hybrid
Monte Carlo is to move a substantial distance through phase space to a new state
that is relatively independent of the initial state and still achieve a high probability of
acceptance. In order to achieve this, the leapfrog integration must be continued for a
number of iterations of order σmax/σmin.
By contrast, consider the behaviour of a simple Metropolis algorithm with an
isotropic Gaussian proposal distribution of variance s2, considered earlier. In order
to avoid high rejection rates, the value of s must be of order σmin. The exploration of
state space then proceeds by a random walk and takes of order (σmax/σmin)2 steps
to arrive at a roughly independent state.
l
