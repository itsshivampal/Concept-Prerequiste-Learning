{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_file = \"index_text/bprml.txt\"\n",
    "chapter_file = \"chapter_text/bprml.txt\"\n",
    "\n",
    "# index_file = \"index_text/iandl.txt\"\n",
    "# chapter_file = \"chapter_text/iandl.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Following functions are use for extracting text file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toggle_state(class_indexing):\n",
    "    if class_indexing: class_indexing = False\n",
    "    else: class_indexing = True\n",
    "    return class_indexing\n",
    "   \n",
    "\n",
    "def line_split(line):\n",
    "    tokens = line.split(\",\")\n",
    "    tokens_length = len(tokens)\n",
    "    keyword = []\n",
    "    keyword.append(tokens[0].strip())\n",
    "    for i in range(tokens_length - 1):\n",
    "        token = tokens[i+1].strip()\n",
    "        if \"see\" in token:\n",
    "            keyword.append(token[4:])\n",
    "    return keyword\n",
    "\n",
    "\n",
    "def data_append(parent_class, keyword):\n",
    "    size = len(keyword)\n",
    "    sub_class = keyword[0]\n",
    "    if size > 1: reference = keyword[1]\n",
    "    else: reference = \"\"\n",
    "    data = {\n",
    "        'Parent Class': parent_class,\n",
    "        'Sub Class': sub_class,\n",
    "        'Reference': reference\n",
    "    }\n",
    "    return (data)\n",
    "\n",
    "\n",
    "def line_operation(line, parent_class, class_indexing):\n",
    "    keyword = line_split(line)\n",
    "    if class_indexing:\n",
    "        data = data_append(parent_class, keyword)\n",
    "    else:\n",
    "        parent_class = keyword[0]\n",
    "        data = data_append(parent_class, keyword)\n",
    "    return (parent_class, data)\n",
    "\n",
    "    \n",
    "def data_extraction(line, parent_class, class_indexing):\n",
    "    line = line.lower()\n",
    "    \n",
    "    if line[0] == ',' or (line[0] >= '0' and line[0] <= '9'):\n",
    "        return (0, parent_class, class_indexing, \"\")\n",
    "    \n",
    "    elif line[0] == '\\n':\n",
    "        class_indexing = toggle_state(class_indexing)\n",
    "        return (0, parent_class, class_indexing, \"\")\n",
    "    \n",
    "    else:\n",
    "        parent_class, data = line_operation(line, parent_class, class_indexing)\n",
    "        return (1, parent_class, class_indexing, data)\n",
    "\n",
    "def print_processed_data(df):\n",
    "    parent_class = df[[\"Parent Class\"]]\n",
    "    sub_class = df[[\"Sub Class\"]]\n",
    "    reference = df[[\"Reference\"]]\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        if parent_class.iloc[i].values[0] == sub_class.iloc[i].values[0]:\n",
    "            print(sub_class.iloc[i].values[0], \",\", reference.iloc[i].values[0])\n",
    "        else:\n",
    "            print(\"\\t\", sub_class.iloc[i].values[0], \",\", reference.iloc[i].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data extraction from index file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_index_data(file_location, df):\n",
    "#     df = pd.DataFrame(columns=['Parent Class', 'Sub Class', 'Reference'])\n",
    "    parent_class = \"\"\n",
    "    class_indexing = False\n",
    "    \n",
    "    file = open(file_location)\n",
    "    for line in file:\n",
    "        state, parent_class, class_indexing, data = data_extraction(line, parent_class, class_indexing)\n",
    "        if state:\n",
    "            df = df.append(data, ignore_index=True)\n",
    "    \n",
    "    save_file = file_location.split(\"/\")[-1].split(\".\")[0] + \".csv\"\n",
    "    df.to_csv(save_file)\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Parent Class', 'Sub Class', 'Reference'])\n",
    "df = extract_index_data(index_file, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# maximum length of keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_class = df[[\"Parent Class\"]]\n",
    "sub_class = df[[\"Sub Class\"]]\n",
    "index_length = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1\n",
    "\n",
    "def cal_max_length(n1, n2):\n",
    "    if n1 > n2: return n1\n",
    "    else: return n2\n",
    "\n",
    "for i in range(index_length):\n",
    "    x1 = parent_class.iloc[i].values[0]\n",
    "    x2 = sub_class.iloc[i].values[0]\n",
    "    if x1 == x2:\n",
    "        max_length = cal_max_length(max_length, len(x2.split(\" \")))\n",
    "    else:\n",
    "        max_length = cal_max_length(max_length, len(x2.split(\" \")) + len(x1.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keywords extraction from CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "133\n"
     ]
    }
   ],
   "source": [
    "singular_terms = []\n",
    "different_terms = []\n",
    "\n",
    "for i in range(index_length):\n",
    "    x1 = parent_class.iloc[i].values[0]\n",
    "    x2 = sub_class.iloc[i].values[0]\n",
    "    if x1 == x2:\n",
    "        singular_terms.append(x2)\n",
    "    else:\n",
    "        terms = [x1, x2]\n",
    "        different_terms.append(terms)\n",
    "\n",
    "print(len(singular_terms))\n",
    "print(len(different_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyphrase Extraction from Book Chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_keywords(chunkGram, text):\n",
    "    chunkParser = nltk.RegexpParser(chunkGram)\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(text))\n",
    "\n",
    "    chunked = chunkParser.parse(tagged)\n",
    "    candidate_keywords = []\n",
    "\n",
    "    for tree in chunked.subtrees():\n",
    "        if tree.label() == 'PHRASE':\n",
    "            candidate_keyword = ' '.join([x for x,y in tree.leaves()])\n",
    "            candidate_keywords.append(candidate_keyword)\n",
    "    \n",
    "    return candidate_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_phrase(phrase):\n",
    "    new_string = \"\"\n",
    "    for word in phrase.split(\" \"):\n",
    "        word = porter.stem(word)\n",
    "        new_string += word + \" \"\n",
    "    return new_string[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "raw = open(chapter_file).read()\n",
    "\n",
    "chunkGram1 = r\"\"\"\n",
    "    NBAR:\n",
    "        {<NN.*|JJ>*<NN.*>}\n",
    "        \n",
    "    PHRASE:\n",
    "        {<NBAR>}\n",
    "        {<NBAR><IN><NBAR>}\n",
    "\"\"\"\n",
    "\n",
    "chunkGram2 = r\"\"\" PHRASE: \n",
    "                {(<JJ>* <NN.*>+ <IN>)? <JJ>* <NN.*>+}\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_keywords = extract_candidate_keywords(chunkGram1, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_keywords = [word.lower() for word in candidate_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"candidate_keyword.txt\", 'w+')\n",
    "\n",
    "for word in candidate_keywords:\n",
    "    f.write(word)\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17242\n"
     ]
    }
   ],
   "source": [
    "candidate_keywords = set(candidate_keywords)\n",
    "candidate_keywords = [w for w in candidate_keywords if len(w.split(' ')) < max_length]\n",
    "\n",
    "print(len(candidate_keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16025\n"
     ]
    }
   ],
   "source": [
    "filtered_keywords = [clean_phrase(w) for w in candidate_keywords]\n",
    "\n",
    "filtered_keywords = set(filtered_keywords)\n",
    "\n",
    "print(len(filtered_keywords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Singular Keywords from Extracted List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matched_words = []\n",
    "unmatched_words = []\n",
    "for w in singular_terms:\n",
    "    count = 0\n",
    "    for w1 in filtered_keywords:\n",
    "        if clean_phrase(w) in w1:\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        unmatched_words.append(w)\n",
    "    else:\n",
    "        matched_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched_words:  524\n",
      "not matched:  124\n"
     ]
    }
   ],
   "source": [
    "print(\"matched_words: \", len(set(matched_words)))\n",
    "print(\"not matched: \", len(unmatched_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acceptance criterion', 'activation function', 'active constraint', 'adaboost', 'adaline', 'adaptive rejection sampling', 'adf', 'aic', 'akaike information criterion', 'ancestral sampling', 'ar model', 'arc', 'ard', 'arma', 'automatic relevance determination', 'autoregressive hidden markov model', 'back-tracking', 'backgammon', 'backpropagation', 'bagging', 'basis function', 'baum-welch algorithm', 'bayes', 'bayesian analysis', 'bayesian information criterion', 'bayesian model comparison', 'bayesian network', 'bayesian probability', 'belief propagation', 'bernoulli distribution', 'bernoulli', 'beta distribution', 'beta recursion', 'between-class covariance', 'bias', 'bias parameter', 'bias-variance trade-off', 'bic', 'binary entropy', 'binomial distribution', 'biological sequence', 'bits', 'boltzmann distribution', 'boltzmann', 'boolean logic', 'boosting', 'bootstrap', 'bootstrap ﬁlter', 'box constraints', 'box-muller method', 'canonical link function', 'cart', 'cauchy distribution', 'causality', 'cca', 'central differences', 'central limit theorem', 'chain graph', 'chaining', 'child node', 'cholesky decomposition', 'classiﬁcation', 'clique', 'clustering', 'clutter problem', 'co-parents', 'code-book vectors', 'combining models', 'committee', 'complete data set', 'computational learning theory', 'concave function', 'concentration parameter', 'condensation algorithm', 'conditional entropy', 'conditional expectation', 'conditional independence', 'conditional mixture model', 'conditional probability', 'conjugate prior', 'convex duality', 'convex function', 'convolutional neural network', 'cost function', 'covariance', 'covariance matrix', 'credit assignment', 'cross-entropy error function', 'cross-validation', 'cumulative distribution function', 'curve ﬁtting', 'dag', 'dagsvm', 'data augmentation', 'data compression', 'decision boundary', 'decision region', 'decision surface', 'decision theory', 'decision tree', 'decomposition methods', 'density estimation', 'density network', 'dependency map', 'design matrix', 'differential entropy', 'digamma function', 'directed acyclic graph', 'directed cycle', 'directed factorization', 'dirichlet distribution', 'dirichlet', 'discriminant function', 'discriminative model', 'distortion measure', 'dna', 'dual representation', 'dynamic programming', 'dynamical system', 'early stopping', 'ecm', 'edge', 'elliptical k-means', 'em', 'emission probability', 'empirical bayes', 'energy function', 'entropy', 'ep', 'equivalent kernel', 'erf function', 'error backpropagation', 'error function', 'euler', 'evidence approximation', 'evidence function', 'expectation', 'expectation conditional maximization', 'expectation maximization', 'expectation propagation', 'expectation step', 'exploitation', 'exploration', 'exponential distribution', 'exponential family', 'face detection', 'factor analysis', 'factor graph', 'factorial hidden markov model', 'factorized distribution', 'feature extraction', 'feature map', 'feature space', 'fisher information matrix', 'fisher kernel', 'forward kinematics', 'forward problem', 'forward propagation', 'forward-backward algorithm', 'fractional belief propagation', 'fuel system', 'functional', 'gamma distribution', 'gamma function', 'gating function', 'gauss', 'gaussian', 'gaussian kernel', 'gaussian process', 'gaussian random ﬁeld', 'gaussian-gamma distribution', 'gaussian-wishart distribution', 'gem', 'generalization', 'generalized linear model', 'generalized maximum likelihood', 'generative model', 'gibbs sampling', 'gibbs', 'gini index', 'global minimum', 'gradient descent', 'gram matrix', 'graph-cut algorithm', 'graphical model', 'hamilton', 'hamiltonian dynamics', 'hamiltonian function', 'hammersley-clifford theorem', 'handwriting recognition', 'handwritten digit', 'head-to-head path', 'heaviside step function', 'hellinger distance', 'hessian matrix', 'heteroscedastic', 'hidden markov model', 'hidden unit', 'hidden variable', 'hierarchical bayesian model', 'hinge error function', 'histogram density estimation', 'hme', 'hold-out set', 'homogeneous kernel', 'homogeneous markov chain', 'hybrid monte carlo', 'hyperparameter', 'hyperprior', 'i.i.d.', 'ica', 'icm', 'id3', 'identiﬁability', 'image de-noising', 'importance sampling', 'importance weights', 'improper prior', 'imputation step', 'independence map', 'independent variables', 'independent', 'induced factorization', 'inequality constraint', 'inference', 'information criterion', 'information geometry', 'information theory', 'input-output hidden markov model', 'intrinsic dimensionality', 'invariance', 'inverse gamma distribution', 'inverse problem', 'ip algorithm', 'irls', 'ising model', 'iterated conditional modes', 'jacobian matrix', 'join tree', 'junction tree algorithm', 'k-means clustering algorithm', 'k-medoids algorithm', 'kalman ﬁlter', 'kalman gain matrix', 'kalman smoother', 'kernel density estimator', 'kernel function', 'kernel regression', 'kernel substitution', 'kernel trick', 'kinetic energy', 'kkt', 'kl divergence', 'kriging', 'kullback-leibler divergence', 'lagrange multiplier', 'lagrange', 'lagrangian', 'laplace approximation', 'laplace', 'large margin', 'lasso', 'latent class analysis', 'latent variable', 'lattice diagram', 'lds', 'leapfrog discretization', 'learning', 'learning rate parameter', 'leave-one-out', 'likelihood function', 'linear discriminant', 'linear dynamical system', 'linear regression', 'linear smoother', 'linear-gaussian model', 'linearly separable', 'link', 'link function', 'lle', 'lms algorithm', 'local minimum', 'local receptive ﬁeld', 'location parameter', 'log odds', 'logistic regression', 'logistic sigmoid', 'logit function', 'loopy belief propagation', 'loss function', 'loss matrix', 'lossless data compression', 'lossy data compression', 'lower bound', 'machine learning', 'macrostate', 'mahalanobis distance', 'manifold', 'map', 'margin', 'marginal likelihood', 'marginal probability', 'markov blanket', 'markov chain', 'markov chain monte carlo', 'markov model', 'markov network', 'markov random ﬁeld', 'max-sum algorithm', 'maximal clique', 'maximal spanning tree', 'maximization step', 'maximum likelihood', 'maximum margin', 'maximum posterior', 'mcmc', 'mean', 'mean ﬁeld theory', 'mean value theorem', 'measure theory', 'memory-based methods', 'message passing', 'metropolis algorithm', 'metropolis-hastings algorithm', 'microstate', 'minimum risk', 'minkowski loss', 'mixing coefﬁcient', 'mixture component', 'mixture density network', 'mixture distribution', 'mixture model', 'mlp', 'model comparison', 'model evidence', 'model selection', 'moment matching', 'momentum variable', 'monte carlo em algorithm', 'moore-penrose pseudo-inverse', 'moralization', 'multilayer perceptron', 'multimodality', 'multinomial distribution', 'multiplicity', 'mutual information', 'nadaraya-watson', 'naive bayes model', 'nats', 'natural language modelling', 'natural parameters', 'nearest-neighbour methods', 'neural network', 'newton-raphson', 'node', 'noiseless coding theorem', 'nonidentiﬁability', 'noninformative prior', 'nonparametric methods', 'normal distribution', 'normal equations', 'normal-gamma distribution', 'normalized exponential', 'novelty detection', 'ν-svm', 'object recognition', 'observed variable', 'occam factor', 'oil ﬂow data', 'old faithful data', 'on-line learning', 'one-versus-one classiﬁer', 'one-versus-the-rest classiﬁer', 'ordered over-relaxation', 'ornstein-uhlenbeck process', 'orthogonal least squares', 'outlier', 'outliers', 'over-ﬁtting', 'over-relaxation', 'pac learning', 'pac-bayesian framework', 'parameter shrinkage', 'parent node', 'particle ﬁlter', 'partition function', 'parzen estimator', 'parzen window', 'pattern recognition', 'pca', 'pending message', 'perceptron', 'perceptron criterion', 'perfect map', 'periodic variable', 'phase space', 'plate', 'polynomial curve ﬁtting', 'polytree', 'position variable', 'positive deﬁnite matrix', 'positive semideﬁnite matrix', 'posterior probability', 'posterior step', 'potential energy', 'potential function', 'power ep', 'power method', 'precision matrix', 'precision parameter', 'predictive distribution', 'principal component analysis', 'prior', 'probabilistic graphical model', 'probabilistic pca', 'probability', 'probit function', 'probit regression', 'proposal distribution', 'protected conjugate gradients', 'pseudo-inverse', 'pseudo-random numbers', 'quadratic discriminant', 'radial basis function', 'regression', 'regression function', 'regularization', 'regularized least squares', 'reinforcement learning', 'reject option', 'rejection sampling', 'relative entropy', 'relevance vector', 'relevance vector machine', 'responsibility', 'rms error', 'robbins-monro algorithm', 'robot arm', 'robustness', 'root node', 'root-mean-square error', 'rosenblatt', 'rvm', 'sample mean', 'sample variance', 'sampling-importance-resampling', 'scale invariance', 'scale parameter', 'scaling factor', 'schwarz criterion', 'sequential data', 'sequential estimation', 'sequential gradient descent', 'sequential learning', 'sequential minimal optimization', 'shannon', 'shrinkage', 'sigmoid', 'simplex', 'single-class support vector machine', 'singular value decomposition', 'sinusoidal data', 'sir', 'skip-layer connection', 'slack variable', 'slice sampling', 'smo', 'smoother matrix', 'smoothing parameter', 'soft margin', 'softmax function', 'som', 'sparsity', 'speech recognition', 'sphereing', 'standard deviation', 'standardizing', 'state space model', 'stationary kernel', 'statistical learning theory', 'steepest descent', 'stochastic', 'stochastic em', 'stochastic gradient descent', 'stochastic process', 'subsampling', 'sufﬁcient statistics', 'sum-of-squares error', 'sum-product algorithm', 'supervised learning', 'support vector', 'support vector machine', 'svd', 'svm', 'synthetic data sets', 'tail-to-tail path', 'tangent distance', 'tangent propagation', 'tapped delay line', 'target vector', 'test set', 'threshold parameter', 'tikhonov regularization', 'training', 'training set', 'transition probability', 'translation invariance', 'tree-reweighted message passing', 'treewidth', 'trellis diagram', 'triangulated graph', 'undirected graph', 'uniform distribution', 'uniform sampling', 'uniquenesses', 'unobserved variable', 'unsupervised learning', 'utility function', 'validation set', 'vapnik-chervonenkis dimension', 'variance', 'variational inference', 'vc dimension', 'soft']\n"
     ]
    }
   ],
   "source": [
    "print(matched_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Parent and Sub Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "between-class covariance\n",
      "within-class covariance\n",
      "partitioned covariance matrix\n",
      "conditional entropy\n",
      "differential entropy\n",
      "relative entropy\n",
      "functional derivative\n",
      "conditional gaussian\n",
      "gaussian marginal\n",
      "gaussian mixture\n",
      "directed graphical model\n",
      "undirected graphical model\n",
      "autoregressive hidden markov model\n",
      "factorial hidden markov model\n",
      "input-output hidden markov model\n",
      "left-to-right hidden markov model\n",
      "extended kalman ﬁlter\n",
      "gaussian kernel function\n",
      "fisher linear discriminant\n",
      "linear regression problem\n",
      "variational linear regression\n",
      "bayesian logistic regression\n",
      "logistic regression mixture model\n",
      "multiclass logistic regression\n",
      "margin error\n",
      "soft margin\n",
      "homogeneous markov chain\n",
      "message passing schedule\n",
      "variational message passing\n",
      "conditional mixture model\n",
      "logistic regression mixture model\n",
      "neural network input imag convolutional\n",
      "perceptron convergence theorem\n",
      "perceptron hardware\n",
      "conjugate prior\n",
      "consistent gaussian prior\n",
      "improper prior\n",
      "noninformative prior\n",
      "bayesian probability\n",
      "probability density\n",
      "probability mass function\n",
      "prior probability\n",
      "probability sum rule\n",
      "probability theory\n",
      "tikhonov regularization\n"
     ]
    }
   ],
   "source": [
    "def find_best_string(all_strings):\n",
    "    return max(set(all_strings), key = all_strings.count)\n",
    "\n",
    "\n",
    "def matching_pattern(keyword1, keyword2, phrase):\n",
    "#     phrase = clean_phrase(phrase)\n",
    "    stem1 = clean_phrase(keyword1)\n",
    "    stem2 = clean_phrase(keyword2)\n",
    "    if stem1 in phrase and stem2 in phrase:\n",
    "        len1 = phrase.index(stem1)\n",
    "        len2 = phrase.index(stem2)\n",
    "        \n",
    "        if len1 > len2:\n",
    "            start = len2 + len(stem2)\n",
    "            end = len1\n",
    "            string = keyword2 + phrase[start:end] + keyword1\n",
    "        else:\n",
    "            start = len1 + len(stem1)\n",
    "            end = len2\n",
    "            string = keyword1 + phrase[start:end] + keyword2\n",
    "        return 1, string\n",
    "    else: return 0, \"\"\n",
    "\n",
    "count = 0\n",
    "successful_phrases = []\n",
    "unsuccessful_phrases = []\n",
    "\n",
    "\n",
    "for pair in different_terms:\n",
    "    match_count = 0\n",
    "    possible_strings = []\n",
    "    for phrase in filtered_keywords:\n",
    "        result, string = matching_pattern(pair[0], pair[1], phrase)\n",
    "        if result != 0:\n",
    "            possible_strings.append(string)\n",
    "            match_count += 1\n",
    "    if match_count > 0:\n",
    "        main_keyword = find_best_string(possible_strings)\n",
    "        successful_phrases.append(main_keyword)\n",
    "        count += 1\n",
    "        print(main_keyword)\n",
    "    else:\n",
    "        unsuccessful_phrases.append(pair)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "print(len(successful_phrases))\n",
    "print(len(unsuccessful_phrases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bayesian analysis', 'hierarchical']\n",
      "['bayesian analysis', 'model averaging']\n",
      "['bernoulli distribution', 'mixture model']\n",
      "['covariance matrix', 'diagonal']\n",
      "['covariance matrix', 'isotropic']\n",
      "['covariance matrix', 'positive deﬁnite']\n",
      "['expectation maximization', 'gaussian mixture']\n",
      "['expectation maximization', 'generalized']\n",
      "['expectation maximization', 'sampling methods']\n",
      "['factor analysis', 'mixture model']\n",
      "['gaussian', 'maximum likelihood']\n",
      "['gaussian', 'sequential estimation']\n",
      "['gaussian', 'sufﬁcient statistics']\n",
      "['gaussian', 'wrapped']\n",
      "['generative topographic mapping', 'directional curvature']\n",
      "['generative topographic mapping', 'magniﬁcation factor']\n",
      "['gibbs sampling', 'blocking']\n",
      "['graphical model', 'bipartite']\n",
      "['graphical model', 'factorization']\n",
      "['graphical model', 'fully connected']\n",
      "['graphical model', 'inference']\n",
      "['graphical model', 'tree']\n",
      "['graphical model', 'treewidth']\n",
      "['graphical model', 'triangulated']\n",
      "['hessian matrix', 'diagonal approximation']\n",
      "['hessian matrix', 'exact evaluation']\n",
      "['hessian matrix', 'fast multiplication']\n",
      "['hessian matrix', 'ﬁnite differences']\n",
      "['hessian matrix', 'inverse']\n",
      "['hessian matrix', 'outer product approximation']\n",
      "['hidden markov model', 'forward-backward algorithm']\n",
      "['hidden markov model', 'maximum likelihood']\n",
      "['hidden markov model', 'scaling factor']\n",
      "['hidden markov model', 'sum-product algorithm']\n",
      "['hidden markov model', 'switching']\n",
      "['hidden markov model', 'variational inference']\n",
      "['kernel function', 'fisher']\n",
      "['kernel function', 'homogeneous']\n",
      "['kernel function', 'nonvectorial inputs']\n",
      "['kernel function', 'stationary']\n",
      "['linear dynamical system', 'inference']\n",
      "['linear regression', 'mixture model']\n",
      "['markov chain', 'ﬁrst order']\n",
      "['markov chain', 'second order']\n",
      "['markov model', 'homogeneous']\n",
      "['maximum likelihood', 'gaussian mixture']\n",
      "['maximum likelihood', 'singularities']\n",
      "['maximum likelihood', 'type 2']\n",
      "['message passing', 'pending message']\n",
      "['mixture model', 'linear regression']\n",
      "['mixture model', 'symmetries']\n",
      "['neural network', 'regularization']\n",
      "['neural network', 'relation to gaussian process']\n",
      "['principal component analysis', 'bayesian']\n",
      "['principal component analysis', 'em algorithm']\n",
      "['principal component analysis', 'gibbs sampling']\n",
      "['principal component analysis', 'mixture distribution']\n",
      "['principal component analysis', 'physical analogy']\n",
      "['probability', 'classical']\n",
      "['probability', 'frequentist']\n",
      "['probability', 'product rule']\n",
      "['state space model', 'switching']\n",
      "['sum-product algorithm', 'for hidden markov model']\n",
      "['support vector machine', 'for regression']\n",
      "['support vector machine', 'multiclass']\n",
      "['variational inference', 'for gaussian mixture']\n",
      "['variational inference', 'for hidden markov model']\n",
      "['variational inference', 'local']\n",
      "['vc dimension', 'vector quantization']\n",
      "['vc dimension', 'vertex']\n",
      "['vc dimension', 'visualization']\n",
      "['vc dimension', 'viterbi algorithm']\n",
      "['vc dimension', 'von mises distribution']\n",
      "['vc dimension', 'wavelets']\n",
      "['vc dimension', 'weak learner']\n",
      "['vc dimension', 'weight decay']\n",
      "['vc dimension', 'weight parameter']\n",
      "['vc dimension', 'weight sharing']\n",
      "['soft', 'weight vector']\n",
      "['soft', 'weight-space symmetry']\n",
      "['soft', 'weighted least squares']\n",
      "['soft', 'well-determined parameters']\n",
      "['soft', 'whitening']\n",
      "['soft', 'wishart distribution']\n",
      "['soft', 'within-class covariance']\n",
      "['soft', 'woodbury identity']\n",
      "['soft', 'wrapped distribution']\n",
      "['soft', 'yellowstone national park']\n"
     ]
    }
   ],
   "source": [
    "for x in unsuccessful_phrases:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Wikipedia Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Parent Class', 'Sub Class', 'Reference'])\n",
    "df = extract_index_data(index_file, df)\n",
    "\n",
    "parent_class = df[[\"Parent Class\"]]\n",
    "sub_class = df[[\"Sub Class\"]]\n",
    "reference = df[[\"Reference\"]]\n",
    "index_length = df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_abb_acr(x1, x2):\n",
    "    if (len(x1.split(\" \")) == 1 and len(x2.split(\" \")) > 1):\n",
    "        small = x1\n",
    "        large = x2\n",
    "        return (small, large, 1)\n",
    "    elif (len(x1.split(\" \")) > 1 and len(x2.split(\" \")) == 1):\n",
    "        small = x2\n",
    "        large = x1\n",
    "        return (small, large, 1)\n",
    "    else:\n",
    "        return (\"\", \"\", 0)\n",
    "\n",
    "def abbr_matching(x1, x2):\n",
    "    small, large, state = find_abb_acr(x1, x2)\n",
    "    if state == 0:\n",
    "        return (\"\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singular_terms = []\n",
    "different_terms = []\n",
    "\n",
    "for i in range(index_length):\n",
    "    x1 = parent_class.iloc[i].values[0]\n",
    "    x2 = sub_class.iloc[i].values[0]\n",
    "    x3 = reference.iloc[i].values[0]\n",
    "    if x1 == x2:\n",
    "        if x3!= \"\":\n",
    "            x1 = abbr_matching(x1, x3)\n",
    "        singular_terms.append(x1)\n",
    "    else:\n",
    "        terms = [x1, x2]\n",
    "        different_terms.append(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(singular_terms))\n",
    "print(len(different_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n"
     ]
    }
   ],
   "source": [
    "print(len(singular_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_phrase(phrase):\n",
    "    phrase = phrase.replace(\"-\", \" \")\n",
    "    phrase = phrase.lower()\n",
    "    new_string = \"\"\n",
    "    for word in phrase.split(\" \"):\n",
    "        word = porter.stem(word)\n",
    "        new_string += word + \" \"\n",
    "    return new_string[:-1]\n",
    "\n",
    "def match_phrase(phrase1, phrase2):\n",
    "    phrase1 = clean_phrase(phrase1)\n",
    "    phrase2 = clean_phrase(phrase2)\n",
    "    if phrase1 in phrase2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Laplace's method\",\n",
       " 'Pierre-Simon Laplace',\n",
       " \"Stirling's approximation\",\n",
       " 'Heaviside step function',\n",
       " 'LaplacesDemon',\n",
       " 'Least squares',\n",
       " 'Finite difference method',\n",
       " 'Marginal likelihood',\n",
       " 'Discrete Laplace operator',\n",
       " 'Binomial distribution']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.search(\"laplace approximation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_wiki = []\n",
    "phrase_non_wiki = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance criterion\n",
      "active constraint\n",
      "adaptive rejection sampling\n",
      "aic\n",
      "ancestral sampling\n",
      "annular ﬂow\n",
      "ar model\n",
      "assumed density ﬁltering\n",
      "autoassociative networks\n",
      "automatic relevance determination\n",
      "autoregressive hidden markov model\n",
      "autoregressive moving average\n",
      "back-tracking\n",
      "batch training\n",
      "baum-welch algorithm\n",
      "bayes’ theorem\n",
      "bayesian analysis\n",
      "bayesian model comparison\n",
      "beta recursion\n",
      "between-class covariance\n",
      "bias parameter\n",
      "bias-variance trade-off\n",
      "biological sequence\n",
      "blind source separation\n",
      "blocked path\n",
      "boolean logic\n",
      "bootstrap ﬁlter\n",
      "box constraints\n",
      "box-muller method\n",
      "canonical correlation analysis\n",
      "canonical link function\n",
      "central differences\n",
      "chain graph\n",
      "chapman-kolmogorov equations\n",
      "child node\n",
      "circular normal\n",
      "classical probability\n",
      "classiﬁcation\n",
      "classiﬁcation and regression trees\n",
      "clutter problem\n",
      "co-parents\n",
      "code-book vectors\n",
      "combining models\n",
      "complete data set\n",
      "conditional mixture model\n",
      "convex duality\n",
      "correlation matrix\n",
      "cox’s axioms\n",
      "credit assignment\n",
      "cross-entropy error function\n",
      "curve ﬁtting\n",
      "dagsvm\n",
      "data augmentation\n",
      "decision region\n",
      "decision surface\n",
      "degrees-of-freedom parameter\n",
      "density network\n",
      "dependency map\n",
      "descendant node\n",
      "directed cycle\n",
      "directed factorization\n",
      "discriminant function\n",
      "distortion measure\n",
      "distributive law of multiplication\n",
      "dual-energy gamma densitometry\n",
      "effective number of observations\n",
      "effective number of parameters\n",
      "elliptical k-means\n",
      "emission probability\n",
      "energy function\n",
      "equality constraint\n",
      "equivalent kernel\n",
      "erf function\n",
      "error backpropagation\n",
      "error-correcting output codes\n",
      "euler-lagrange equations\n",
      "evidence approximation\n",
      "evidence function\n",
      "expectation conditional maximization\n",
      "expectation maximization\n",
      "expectation step\n",
      "explaining away\n",
      "extensive variables\n",
      "face tracking\n",
      "factor loading\n",
      "factorial hidden markov model\n",
      "factorized distribution\n",
      "feature map\n",
      "feature space\n",
      "fisher information matrix\n",
      "fisher’s linear discriminant\n",
      "forward problem\n",
      "forward propagation\n",
      "forward-backward algorithm\n",
      "fractional belief propagation\n",
      "function interpolation\n",
      "gamma densitometry\n",
      "gating function\n",
      "gaussian kernel\n",
      "gaussian random ﬁeld\n",
      "gaussian-gamma distribution\n",
      "gaussian-wishart distribution\n",
      "generalized maximum likelihood\n",
      "geodesic distance\n",
      "gini index\n",
      "global minimum\n",
      "gram matrix\n",
      "graph-cut algorithm\n",
      "green’s function\n",
      "hamiltonian dynamics\n",
      "hamiltonian function\n",
      "hammersley-clifford theorem\n",
      "handwritten digit\n",
      "head-to-head path\n",
      "head-to-tail path\n",
      "hidden unit\n",
      "hierarchical bayesian model\n",
      "hierarchical mixture of experts\n",
      "hinge error function\n",
      "hinton diagram\n",
      "histogram density estimation\n",
      "hold-out set\n",
      "homogeneous ﬂow\n",
      "homogeneous kernel\n",
      "homogeneous markov chain\n",
      "hooke’s law\n",
      "hybrid monte carlo\n",
      "i.i.d.\n",
      "identiﬁability\n",
      "image de-noising\n",
      "importance weights\n",
      "improper prior\n",
      "imputation step\n",
      "imputation-posterior algorithm\n",
      "inactive constraint\n",
      "incomplete data set\n",
      "independence map\n",
      "independent factor analysis\n",
      "independent identically distributed\n",
      "induced factorization\n",
      "inequality constraint\n",
      "input-output hidden markov model\n",
      "intensive variables\n",
      "intrinsic dimensionality\n",
      "ip algorithm\n",
      "irls\n",
      "isometric feature map\n",
      "jensen’s inequality\n",
      "join tree\n",
      "k nearest neighbours\n",
      "k-means clustering algorithm\n",
      "k-medoids algorithm\n",
      "kalman ﬁlter\n",
      "kalman gain matrix\n",
      "kalman smoother\n",
      "karhunen-lo`eve transform\n",
      "karush-kuhn-tucker conditions\n",
      "kernel function\n",
      "kernel pca\n",
      "kernel substitution\n",
      "kernel trick\n",
      "kkt\n",
      "kl divergence\n",
      "kullback-leibler divergence\n",
      "laminar ﬂow\n",
      "laplace approximation\n",
      "latent class analysis\n",
      "latent trait model\n",
      "lattice diagram\n",
      "leapfrog discretization\n",
      "learning rate parameter\n",
      "least-mean-squares algorithm\n",
      "likelihood weighted sampling\n",
      "linear smoother\n",
      "linear-gaussian model\n",
      "linearly separable\n",
      "link function\n",
      "liouville’s theorem\n",
      "lle\n",
      "lms algorithm\n",
      "local minimum\n",
      "local receptive ﬁeld\n",
      "locally linear embedding\n",
      "log odds\n",
      "logic sampling\n",
      "logistic sigmoid\n",
      "logit function\n",
      "loopy belief propagation\n",
      "loss matrix\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-961514643017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingular_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwiki_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch_phrase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiki_search\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mphrase_wiki\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, results, suggestion)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0msearch_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srinfo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'suggestion'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mraw_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wiki_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m_wiki_request\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mRATE_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# Reset the timeout for the recv() on the socket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1227\u001b[0m                 encode_chunked=False):\n\u001b[1;32m   1228\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1273\u001b[0m             \u001b[0;31m# default charset of iso-8859-1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     def request(self, method, url, body=None, headers={}, *,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\\r\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_body\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotConnected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketTimeout\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for phrase in singular_terms:\n",
    "    wiki_search = wikipedia.search(phrase)\n",
    "    match = match_phrase(phrase, wiki_search[0])\n",
    "    if match:\n",
    "        phrase_wiki.append(phrase)\n",
    "    else:\n",
    "        phrase_non_wiki.append(phrase)\n",
    "        print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akaik inform criterion\n"
     ]
    }
   ],
   "source": [
    "print(clean_phrase(\"akaike information criterion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Akaike information criterion', 'Bayesian information criterion', 'Watanabe–Akaike information criterion', 'Hirotugu Akaike', 'Deviance information criterion', 'Stepwise regression', 'Hannan–Quinn information criterion', 'Focused information criterion', 'Model selection', \"Mallows's Cp\"]\n"
     ]
    }
   ],
   "source": [
    "print(wikipedia.search(\"akaike information criterion\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acceptance criterion\n",
      "activation function\n",
      "active constraint\n",
      "adaboost\n",
      "adaline\n",
      "adaptive rejection sampling\n",
      "adf\n",
      "aic\n",
      "akaike information criterion\n",
      "ancestral sampling\n",
      "annular ﬂow\n",
      "ar model\n",
      "arc\n",
      "ard\n",
      "arma\n",
      "assumed density ﬁltering\n",
      "autoassociative networks\n",
      "automatic relevance determination\n",
      "autoregressive hidden markov model\n",
      "autoregressive model\n",
      "autoregressive moving average\n",
      "back-tracking\n",
      "backgammon\n",
      "backpropagation\n",
      "bagging\n",
      "basis function\n",
      "batch training\n",
      "baum-welch algorithm\n",
      "bayes’ theorem\n",
      "bayes\n",
      "bayesian analysis\n",
      "bayesian information criterion\n",
      "bayesian model comparison\n",
      "bayesian network\n",
      "bayesian probability\n",
      "belief propagation\n",
      "bernoulli distribution\n",
      "bernoulli\n",
      "beta distribution\n",
      "beta recursion\n",
      "between-class covariance\n",
      "bias\n",
      "bias parameter\n",
      "bias-variance trade-off\n",
      "bic\n",
      "binary entropy\n",
      "binomial distribution\n",
      "biological sequence\n",
      "bipartite graph\n",
      "bits\n",
      "blind source separation\n",
      "blocked path\n",
      "boltzmann distribution\n",
      "boltzmann\n",
      "boolean logic\n",
      "boosting\n",
      "bootstrap\n",
      "bootstrap ﬁlter\n",
      "box constraints\n",
      "box-muller method\n",
      "calculus of variations\n",
      "canonical correlation analysis\n",
      "canonical link function\n",
      "cart\n",
      "cauchy distribution\n",
      "causality\n",
      "cca\n",
      "central differences\n",
      "central limit theorem\n",
      "chain graph\n",
      "chaining\n",
      "chapman-kolmogorov equations\n",
      "child node\n",
      "cholesky decomposition\n",
      "chunking\n",
      "circular normal\n",
      "classical probability\n",
      "classiﬁcation\n",
      "classiﬁcation and regression trees\n",
      "clique\n",
      "clustering\n",
      "clutter problem\n",
      "co-parents\n",
      "code-book vectors\n",
      "combining models\n",
      "committee\n",
      "complete data set\n",
      "completing the square\n",
      "computational learning theory\n",
      "concave function\n",
      "concentration parameter\n",
      "condensation algorithm\n",
      "conditional entropy\n",
      "conditional expectation\n",
      "conditional independence\n",
      "conditional mixture model\n",
      "conditional probability\n",
      "conjugate prior\n",
      "convex duality\n",
      "convex function\n",
      "convolutional neural network\n",
      "correlation matrix\n",
      "cost function\n",
      "covariance\n",
      "covariance matrix\n",
      "cox’s axioms\n",
      "credit assignment\n",
      "cross-entropy error function\n",
      "cross-validation\n",
      "cumulative distribution function\n",
      "curse of dimensionality\n",
      "curve ﬁtting\n",
      "dag\n",
      "dagsvm\n",
      "data augmentation\n",
      "data compression\n",
      "decision boundary\n",
      "decision region\n",
      "decision surface\n",
      "decision theory\n",
      "decision tree\n",
      "decomposition methods\n",
      "degrees of freedom\n",
      "degrees-of-freedom parameter\n",
      "density estimation\n",
      "density network\n",
      "dependency map\n",
      "descendant node\n",
      "design matrix\n",
      "differential entropy\n",
      "digamma function\n",
      "directed acyclic graph\n",
      "directed cycle\n",
      "directed factorization\n",
      "dirichlet distribution\n",
      "dirichlet\n",
      "discriminant function\n",
      "discriminative model\n",
      "distortion measure\n",
      "distributive law of multiplication\n",
      "dna\n",
      "document retrieval\n",
      "dual representation\n",
      "dual-energy gamma densitometry\n",
      "dynamic programming\n",
      "dynamical system\n",
      "early stopping\n",
      "ecm\n",
      "edge\n",
      "effective number of observations\n",
      "effective number of parameters\n",
      "elliptical k-means\n",
      "em\n",
      "emission probability\n",
      "empirical bayes\n",
      "energy function\n",
      "entropy\n",
      "ep\n",
      "equality constraint\n",
      "equivalent kernel\n",
      "erf function\n",
      "error backpropagation\n",
      "error function\n",
      "error-correcting output codes\n",
      "euler\n",
      "euler-lagrange equations\n",
      "evidence approximation\n",
      "evidence function\n",
      "expectation\n",
      "expectation conditional maximization\n",
      "expectation maximization\n",
      "expectation propagation\n",
      "expectation step\n",
      "explaining away\n",
      "exploitation\n",
      "exploration\n",
      "exponential distribution\n",
      "exponential family\n",
      "extensive variables\n",
      "face detection\n",
      "face tracking\n",
      "factor analysis\n",
      "factor graph\n",
      "factor loading\n",
      "factorial hidden markov model\n",
      "factorized distribution\n",
      "feature extraction\n",
      "feature map\n",
      "feature space\n",
      "fisher information matrix\n",
      "fisher kernel\n",
      "fisher’s linear discriminant\n",
      "forward kinematics\n",
      "forward problem\n",
      "forward propagation\n",
      "forward-backward algorithm\n",
      "fractional belief propagation\n",
      "frequentist probability\n",
      "fuel system\n",
      "function interpolation\n",
      "functional\n",
      "gamma densitometry\n",
      "gamma distribution\n",
      "gamma function\n",
      "gating function\n",
      "gauss\n",
      "gaussian\n",
      "gaussian kernel\n",
      "gaussian process\n",
      "gaussian random ﬁeld\n",
      "gaussian-gamma distribution\n",
      "gaussian-wishart distribution\n",
      "gem\n",
      "generalization\n",
      "generalized linear model\n",
      "generalized maximum likelihood\n",
      "generative model\n",
      "generative topographic mapping\n",
      "geodesic distance\n",
      "gibbs sampling\n",
      "gibbs\n",
      "gini index\n",
      "global minimum\n",
      "gradient descent\n",
      "gram matrix\n",
      "graph-cut algorithm\n",
      "graphical model\n",
      "green’s function\n",
      "gtm\n",
      "hamilton\n",
      "hamiltonian dynamics\n",
      "hamiltonian function\n",
      "hammersley-clifford theorem\n",
      "handwriting recognition\n",
      "handwritten digit\n",
      "head-to-head path\n",
      "head-to-tail path\n",
      "heaviside step function\n",
      "hellinger distance\n",
      "hessian matrix\n",
      "heteroscedastic\n",
      "hidden markov model\n",
      "hidden unit\n",
      "hidden variable\n",
      "hierarchical bayesian model\n",
      "hierarchical mixture of experts\n",
      "hinge error function\n",
      "hinton diagram\n",
      "histogram density estimation\n",
      "hme\n",
      "hold-out set\n",
      "homogeneous ﬂow\n",
      "homogeneous kernel\n",
      "homogeneous markov chain\n",
      "hooke’s law\n",
      "hybrid monte carlo\n",
      "hyperparameter\n",
      "hyperprior\n",
      "i.i.d.\n",
      "ica\n",
      "icm\n",
      "id3\n",
      "identiﬁability\n",
      "image de-noising\n",
      "importance sampling\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-bb69b917e014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingular_terms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mphrase\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/util.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, results, suggestion)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0msearch_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'srinfo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'suggestion'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mraw_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wiki_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/wikipedia/wikipedia.py\u001b[0m in \u001b[0;36m_wiki_request\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m   \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_URL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mRATE_LIMIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for phrase in singular_terms:\n",
    "    results = wikipedia.search(phrase)\n",
    "    if phrase != results[0]:\n",
    "        print(phrase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
